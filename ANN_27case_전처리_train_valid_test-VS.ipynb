{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.random.set_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sb\n",
    "import scipy.stats       as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스케일러 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mold Temperature</th>\n",
       "      <th>Melt Temperature</th>\n",
       "      <th>Packing Pressure</th>\n",
       "      <th>VS</th>\n",
       "      <th>VMS</th>\n",
       "      <th>VS(min)</th>\n",
       "      <th>VS(max)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>195</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2021</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.4713</td>\n",
       "      <td>0.6734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>195</td>\n",
       "      <td>70</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.4681</td>\n",
       "      <td>0.6725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>195</td>\n",
       "      <td>90</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>0.4670</td>\n",
       "      <td>0.6710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>210</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2122</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.4744</td>\n",
       "      <td>0.6866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "      <td>0.2147</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.4696</td>\n",
       "      <td>0.6843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>210</td>\n",
       "      <td>90</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>0.4653</td>\n",
       "      <td>0.6825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>225</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>0.4741</td>\n",
       "      <td>0.7016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>225</td>\n",
       "      <td>70</td>\n",
       "      <td>0.2295</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.4707</td>\n",
       "      <td>0.7002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>225</td>\n",
       "      <td>90</td>\n",
       "      <td>0.2297</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.4695</td>\n",
       "      <td>0.6992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40</td>\n",
       "      <td>195</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>1.1680</td>\n",
       "      <td>1.3580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "      <td>195</td>\n",
       "      <td>70</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>1.1650</td>\n",
       "      <td>1.3570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40</td>\n",
       "      <td>195</td>\n",
       "      <td>90</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>1.1620</td>\n",
       "      <td>1.3550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>40</td>\n",
       "      <td>210</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>1.1640</td>\n",
       "      <td>1.3720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>1.1590</td>\n",
       "      <td>1.3690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>40</td>\n",
       "      <td>210</td>\n",
       "      <td>90</td>\n",
       "      <td>0.2120</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>1.1550</td>\n",
       "      <td>1.3670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40</td>\n",
       "      <td>225</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>1.1630</td>\n",
       "      <td>1.3860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>40</td>\n",
       "      <td>225</td>\n",
       "      <td>70</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>1.1600</td>\n",
       "      <td>1.3850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40</td>\n",
       "      <td>225</td>\n",
       "      <td>90</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>1.1590</td>\n",
       "      <td>1.3830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50</td>\n",
       "      <td>195</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>1.8520</td>\n",
       "      <td>2.0380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>50</td>\n",
       "      <td>195</td>\n",
       "      <td>70</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.003734</td>\n",
       "      <td>1.8490</td>\n",
       "      <td>2.0370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50</td>\n",
       "      <td>195</td>\n",
       "      <td>90</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.8450</td>\n",
       "      <td>2.0340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50</td>\n",
       "      <td>210</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>1.8480</td>\n",
       "      <td>2.0510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>1.8420</td>\n",
       "      <td>2.0480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50</td>\n",
       "      <td>210</td>\n",
       "      <td>90</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>1.8390</td>\n",
       "      <td>2.0460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50</td>\n",
       "      <td>225</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>1.8470</td>\n",
       "      <td>2.0660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50</td>\n",
       "      <td>225</td>\n",
       "      <td>70</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>1.8450</td>\n",
       "      <td>2.0650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50</td>\n",
       "      <td>225</td>\n",
       "      <td>90</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>1.8440</td>\n",
       "      <td>2.0640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mold Temperature  Melt Temperature  Packing Pressure      VS       VMS  \\\n",
       "0                 30               195                50  0.2021  0.002430   \n",
       "1                 30               195                70  0.2044  0.003249   \n",
       "2                 30               195                90  0.2040  0.004261   \n",
       "3                 30               210                50  0.2122  0.002418   \n",
       "4                 30               210                70  0.2147  0.002738   \n",
       "5                 30               210                90  0.2172  0.003034   \n",
       "6                 30               225                50  0.2275  0.002377   \n",
       "7                 30               225                70  0.2295  0.002443   \n",
       "8                 30               225                90  0.2297  0.002480   \n",
       "9                 40               195                50  0.1900  0.002432   \n",
       "10                40               195                70  0.1920  0.003289   \n",
       "11                40               195                90  0.1930  0.004361   \n",
       "12                40               210                50  0.2080  0.002317   \n",
       "13                40               210                70  0.2100  0.002619   \n",
       "14                40               210                90  0.2120  0.002928   \n",
       "15                40               225                50  0.2230  0.002251   \n",
       "16                40               225                70  0.2250  0.002301   \n",
       "17                40               225                90  0.2240  0.002333   \n",
       "18                50               195                50  0.1860  0.002638   \n",
       "19                50               195                70  0.1880  0.003734   \n",
       "20                50               195                90  0.1890  0.005100   \n",
       "21                50               210                50  0.2030  0.002278   \n",
       "22                50               210                70  0.2060  0.002652   \n",
       "23                50               210                90  0.2070  0.003057   \n",
       "24                50               225                50  0.2190  0.002094   \n",
       "25                50               225                70  0.2200  0.002138   \n",
       "26                50               225                90  0.2200  0.002172   \n",
       "\n",
       "    VS(min)  VS(max)  \n",
       "0    0.4713   0.6734  \n",
       "1    0.4681   0.6725  \n",
       "2    0.4670   0.6710  \n",
       "3    0.4744   0.6866  \n",
       "4    0.4696   0.6843  \n",
       "5    0.4653   0.6825  \n",
       "6    0.4741   0.7016  \n",
       "7    0.4707   0.7002  \n",
       "8    0.4695   0.6992  \n",
       "9    1.1680   1.3580  \n",
       "10   1.1650   1.3570  \n",
       "11   1.1620   1.3550  \n",
       "12   1.1640   1.3720  \n",
       "13   1.1590   1.3690  \n",
       "14   1.1550   1.3670  \n",
       "15   1.1630   1.3860  \n",
       "16   1.1600   1.3850  \n",
       "17   1.1590   1.3830  \n",
       "18   1.8520   2.0380  \n",
       "19   1.8490   2.0370  \n",
       "20   1.8450   2.0340  \n",
       "21   1.8480   2.0510  \n",
       "22   1.8420   2.0480  \n",
       "23   1.8390   2.0460  \n",
       "24   1.8470   2.0660  \n",
       "25   1.8450   2.0650  \n",
       "26   1.8440   2.0640  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#설정값 불러오기\n",
    "inputdataRaw = pd.read_excel('./VS&VMS_27case_PRESM.xlsx')\n",
    "inputdataRaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(inputdataRaw)\n",
    "# inputdata = pd.DataFrame(scaler.transform(inputdataRaw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inputdata2_Raw = pd.read_excel('./VS&VMS_20case.xlsx')\n",
    "# inputdata2_Raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training, label 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdata = inputdataRaw.iloc[:,:-4]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(inputdata)\n",
    "TrainData = pd.DataFrame(scaler.transform(inputdata))\n",
    "TrainLabel = pd.DataFrame(inputdataRaw.iloc[:,3]) # VS 예측\n",
    "# TrainLabel = pd.DataFrame(inputdataRaw.iloc[:,4]) # VMS 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2\n",
       "0   0.0  0.0  0.0\n",
       "1   0.0  0.0  0.5\n",
       "2   0.0  0.0  1.0\n",
       "3   0.0  0.5  0.0\n",
       "4   0.0  0.5  0.5\n",
       "5   0.0  0.5  1.0\n",
       "6   0.0  1.0  0.0\n",
       "7   0.0  1.0  0.5\n",
       "8   0.0  1.0  1.0\n",
       "9   0.5  0.0  0.0\n",
       "10  0.5  0.0  0.5\n",
       "11  0.5  0.0  1.0\n",
       "12  0.5  0.5  0.0\n",
       "13  0.5  0.5  0.5\n",
       "14  0.5  0.5  1.0\n",
       "15  0.5  1.0  0.0\n",
       "16  0.5  1.0  0.5\n",
       "17  0.5  1.0  1.0\n",
       "18  1.0  0.0  0.0\n",
       "19  1.0  0.0  0.5\n",
       "20  1.0  0.0  1.0\n",
       "21  1.0  0.5  0.0\n",
       "22  1.0  0.5  0.5\n",
       "23  1.0  0.5  1.0\n",
       "24  1.0  1.0  0.0\n",
       "25  1.0  1.0  0.5\n",
       "26  1.0  1.0  1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.2080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.2120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.1880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.2190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.2200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        VS\n",
       "0   0.2021\n",
       "1   0.2044\n",
       "2   0.2040\n",
       "3   0.2122\n",
       "4   0.2147\n",
       "5   0.2172\n",
       "6   0.2275\n",
       "7   0.2295\n",
       "8   0.2297\n",
       "9   0.1900\n",
       "10  0.1920\n",
       "11  0.1930\n",
       "12  0.2080\n",
       "13  0.2100\n",
       "14  0.2120\n",
       "15  0.2230\n",
       "16  0.2250\n",
       "17  0.2240\n",
       "18  0.1860\n",
       "19  0.1880\n",
       "20  0.1890\n",
       "21  0.2030\n",
       "22  0.2060\n",
       "23  0.2070\n",
       "24  0.2190\n",
       "25  0.2200\n",
       "26  0.2200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows',10)\n",
    "# TrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainLabel_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainLabel = TrainLabel_before.add(0.5)\n",
    "# TrainLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mold Temperature</th>\n",
       "      <th>Melt Temperature</th>\n",
       "      <th>Packing Pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>195</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>195</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>195</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>210</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>210</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>225</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>225</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>225</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40</td>\n",
       "      <td>195</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "      <td>195</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40</td>\n",
       "      <td>195</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>40</td>\n",
       "      <td>210</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>40</td>\n",
       "      <td>210</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40</td>\n",
       "      <td>225</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>40</td>\n",
       "      <td>225</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40</td>\n",
       "      <td>225</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50</td>\n",
       "      <td>195</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>50</td>\n",
       "      <td>195</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50</td>\n",
       "      <td>195</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50</td>\n",
       "      <td>210</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50</td>\n",
       "      <td>210</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50</td>\n",
       "      <td>225</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50</td>\n",
       "      <td>225</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50</td>\n",
       "      <td>225</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mold Temperature  Melt Temperature  Packing Pressure\n",
       "0                 30               195                50\n",
       "1                 30               195                70\n",
       "2                 30               195                90\n",
       "3                 30               210                50\n",
       "4                 30               210                70\n",
       "5                 30               210                90\n",
       "6                 30               225                50\n",
       "7                 30               225                70\n",
       "8                 30               225                90\n",
       "9                 40               195                50\n",
       "10                40               195                70\n",
       "11                40               195                90\n",
       "12                40               210                50\n",
       "13                40               210                70\n",
       "14                40               210                90\n",
       "15                40               225                50\n",
       "16                40               225                70\n",
       "17                40               225                90\n",
       "18                50               195                50\n",
       "19                50               195                70\n",
       "20                50               195                90\n",
       "21                50               210                50\n",
       "22                50               210                70\n",
       "23                50               210                90\n",
       "24                50               225                50\n",
       "25                50               225                70\n",
       "26                50               225                90"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestData_Raw = inputdataRaw.iloc[:,:-4]\n",
    "TestData_Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 50 195 225 50 90 0.18599999999999972 0.22970000000000007 0.002094 0.0051\n"
     ]
    }
   ],
   "source": [
    "min_MoldTemperature = inputdataRaw[\"Mold Temperature\"].min()\n",
    "max_MoldTemperature = inputdataRaw[\"Mold Temperature\"].max()\n",
    "min_MeltTemperature = inputdataRaw[\"Melt Temperature\"].min()\n",
    "max_MeltTemperature = inputdataRaw[\"Melt Temperature\"].max()\n",
    "min_PackingPressure = inputdataRaw[\"Packing Pressure\"].min()\n",
    "max_PackingPressure = inputdataRaw[\"Packing Pressure\"].max()\n",
    "min_VS = inputdataRaw[\"VS\"].min()\n",
    "max_VS = inputdataRaw[\"VS\"].max()\n",
    "min_VMS = inputdataRaw[\"VMS\"].min()\n",
    "max_VMS = inputdataRaw[\"VMS\"].max()\n",
    "\n",
    "print(min_MoldTemperature,\n",
    "max_MoldTemperature,\n",
    "min_MeltTemperature,\n",
    "max_MeltTemperature,\n",
    "min_PackingPressure,\n",
    "max_PackingPressure,\n",
    "min_VS,\n",
    "max_VS,\n",
    "min_VMS,\n",
    "max_VMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mold Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mold Temperature\n",
       "0                0.0\n",
       "1                0.0\n",
       "2                0.0\n",
       "3                0.0\n",
       "4                0.0\n",
       "5                0.0\n",
       "6                0.0\n",
       "7                0.0\n",
       "8                0.0\n",
       "9                0.5\n",
       "10               0.5\n",
       "11               0.5\n",
       "12               0.5\n",
       "13               0.5\n",
       "14               0.5\n",
       "15               0.5\n",
       "16               0.5\n",
       "17               0.5\n",
       "18               1.0\n",
       "19               1.0\n",
       "20               1.0\n",
       "21               1.0\n",
       "22               1.0\n",
       "23               1.0\n",
       "24               1.0\n",
       "25               1.0\n",
       "26               1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "TestData_MoldTemperature = inputdataRaw.iloc[:,:1]\n",
    "TestData_MoldTemperature2 = TestData_MoldTemperature.sub(min_MoldTemperature)\n",
    "TestData_MoldTemperature3 = TestData_MoldTemperature2.div(max_MoldTemperature-min_MoldTemperature)\n",
    "TestData_MoldTemperature3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Melt Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Melt Temperature\n",
       "0                0.0\n",
       "1                0.0\n",
       "2                0.0\n",
       "3                0.5\n",
       "4                0.5\n",
       "5                0.5\n",
       "6                1.0\n",
       "7                1.0\n",
       "8                1.0\n",
       "9                0.0\n",
       "10               0.0\n",
       "11               0.0\n",
       "12               0.5\n",
       "13               0.5\n",
       "14               0.5\n",
       "15               1.0\n",
       "16               1.0\n",
       "17               1.0\n",
       "18               0.0\n",
       "19               0.0\n",
       "20               0.0\n",
       "21               0.5\n",
       "22               0.5\n",
       "23               0.5\n",
       "24               1.0\n",
       "25               1.0\n",
       "26               1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "TestData_MeltTemperature = inputdataRaw.iloc[:,1:2]\n",
    "TestData_MeltTemperature2 = TestData_MeltTemperature.sub(min_MeltTemperature)\n",
    "TestData_MeltTemperature3 = TestData_MeltTemperature2.div(max_MeltTemperature-min_MeltTemperature)\n",
    "TestData_MeltTemperature3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Packing Pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Packing Pressure\n",
       "0                0.0\n",
       "1                0.5\n",
       "2                1.0\n",
       "3                0.0\n",
       "4                0.5\n",
       "5                1.0\n",
       "6                0.0\n",
       "7                0.5\n",
       "8                1.0\n",
       "9                0.0\n",
       "10               0.5\n",
       "11               1.0\n",
       "12               0.0\n",
       "13               0.5\n",
       "14               1.0\n",
       "15               0.0\n",
       "16               0.5\n",
       "17               1.0\n",
       "18               0.0\n",
       "19               0.5\n",
       "20               1.0\n",
       "21               0.0\n",
       "22               0.5\n",
       "23               1.0\n",
       "24               0.0\n",
       "25               0.5\n",
       "26               1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestData_PackingPressure = inputdataRaw.iloc[:,2:3]\n",
    "TestData_PackingPressure2 = TestData_PackingPressure.sub(min_PackingPressure)\n",
    "TestData_PackingPressure3 = TestData_PackingPressure2.div(max_PackingPressure-min_PackingPressure)\n",
    "TestData_PackingPressure3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mold Temperature</th>\n",
       "      <th>Melt Temperature</th>\n",
       "      <th>Packing Pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mold Temperature  Melt Temperature  Packing Pressure\n",
       "0                0.0               0.0               0.0\n",
       "1                0.0               0.0               0.5\n",
       "2                0.0               0.0               1.0\n",
       "3                0.0               0.5               0.0\n",
       "4                0.0               0.5               0.5\n",
       "5                0.0               0.5               1.0\n",
       "6                0.0               1.0               0.0\n",
       "7                0.0               1.0               0.5\n",
       "8                0.0               1.0               1.0\n",
       "9                0.5               0.0               0.0\n",
       "10               0.5               0.0               0.5\n",
       "11               0.5               0.0               1.0\n",
       "12               0.5               0.5               0.0\n",
       "13               0.5               0.5               0.5\n",
       "14               0.5               0.5               1.0\n",
       "15               0.5               1.0               0.0\n",
       "16               0.5               1.0               0.5\n",
       "17               0.5               1.0               1.0\n",
       "18               1.0               0.0               0.0\n",
       "19               1.0               0.0               0.5\n",
       "20               1.0               0.0               1.0\n",
       "21               1.0               0.5               0.0\n",
       "22               1.0               0.5               0.5\n",
       "23               1.0               0.5               1.0\n",
       "24               1.0               1.0               0.0\n",
       "25               1.0               1.0               0.5\n",
       "26               1.0               1.0               1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestData = pd.concat([TestData_MoldTemperature3, TestData_MeltTemperature3, TestData_PackingPressure3], axis=1)\n",
    "TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.2080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.2120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.1880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.2190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.2200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        VS\n",
       "0   0.2021\n",
       "1   0.2044\n",
       "2   0.2040\n",
       "3   0.2122\n",
       "4   0.2147\n",
       "5   0.2172\n",
       "6   0.2275\n",
       "7   0.2295\n",
       "8   0.2297\n",
       "9   0.1900\n",
       "10  0.1920\n",
       "11  0.1930\n",
       "12  0.2080\n",
       "13  0.2100\n",
       "14  0.2120\n",
       "15  0.2230\n",
       "16  0.2250\n",
       "17  0.2240\n",
       "18  0.1860\n",
       "19  0.1880\n",
       "20  0.1890\n",
       "21  0.2030\n",
       "22  0.2060\n",
       "23  0.2070\n",
       "24  0.2190\n",
       "25  0.2200\n",
       "26  0.2200"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestLabel = pd.DataFrame(inputdataRaw.iloc[:,3])\n",
    "TestLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN hyperparameter 조절에 따른 학습성능 확인 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 지정 iteration마다 학습과정 확인 함수(Class) 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "EpochForPrint = 100\n",
    "\n",
    "class AccuracyPerEpoch(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keras.callbacks.Callback()\n",
    "        if epoch%EpochForPrint == 0:\n",
    "            print(\"[{} Epochs]    RMSE:{:.5f},   MAE: {:.5f},  MAPE: {:.2f}%\"\n",
    "                  .format(epoch, np.sqrt(logs['mse']), logs['mae'], logs['mape']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter 조합 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of case : 168\n"
     ]
    }
   ],
   "source": [
    "# 조정 하이퍼파라미터 : 학습율, 은닉층 뉴런 수\n",
    "Lr = [0.001, 0.005, 0.01]   # Learning Rates\n",
    "N1 = [60, 70, 80, 90, 100, 110, 120, 130]   # Number of Neurons on Hidden Layer 1\n",
    "N2 = [50, 60, 70, 80, 90, 100, 110]           # Number of Neurons on Hidden Layer 2\n",
    "\n",
    "Model = ['VS']\n",
    "\n",
    "# 고정 하이퍼파라미터 : 입력/출력층 뉴런 수, 학습 Epoch 수\n",
    "noOfNeuron_in  = 50\n",
    "noOfNeuron_out = 1\n",
    "Epoch          = 2000\n",
    "\n",
    "print('Number of case : %d'%(len(Lr)*len(N1)*len(N2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적의 hyperparameter 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "################## Model 1 (Predict :VS) ##################\n",
      "\n",
      "\n",
      "Trial No.1\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.21593,   MAE: 0.21366,  MAPE: 101.88%\n",
      "[100 Epochs]    RMSE:0.00226,   MAE: 0.00168,  MAPE: 0.80%\n",
      "[200 Epochs]    RMSE:0.00105,   MAE: 0.00067,  MAPE: 0.33%\n",
      "[300 Epochs]    RMSE:0.00539,   MAE: 0.00508,  MAPE: 2.41%\n",
      "[400 Epochs]    RMSE:0.00205,   MAE: 0.00172,  MAPE: 0.82%\n",
      "[500 Epochs]    RMSE:0.00129,   MAE: 0.00098,  MAPE: 0.48%\n",
      "[600 Epochs]    RMSE:0.00197,   MAE: 0.00158,  MAPE: 0.73%\n",
      "[700 Epochs]    RMSE:0.00540,   MAE: 0.00531,  MAPE: 2.54%\n",
      "[800 Epochs]    RMSE:0.00140,   MAE: 0.00109,  MAPE: 0.51%\n",
      "[900 Epochs]    RMSE:0.00115,   MAE: 0.00096,  MAPE: 0.47%\n",
      "[1000 Epochs]    RMSE:0.00124,   MAE: 0.00101,  MAPE: 0.49%\n",
      "[1100 Epochs]    RMSE:0.00172,   MAE: 0.00142,  MAPE: 0.70%\n",
      "[1200 Epochs]    RMSE:0.00127,   MAE: 0.00111,  MAPE: 0.53%\n",
      "[1300 Epochs]    RMSE:0.00063,   MAE: 0.00054,  MAPE: 0.25%\n",
      "[1400 Epochs]    RMSE:0.00250,   MAE: 0.00230,  MAPE: 1.10%\n",
      "[1500 Epochs]    RMSE:0.00175,   MAE: 0.00148,  MAPE: 0.70%\n",
      "[1600 Epochs]    RMSE:0.00072,   MAE: 0.00057,  MAPE: 0.28%\n",
      "[1700 Epochs]    RMSE:0.00131,   MAE: 0.00102,  MAPE: 0.48%\n",
      "[1800 Epochs]    RMSE:0.00146,   MAE: 0.00118,  MAPE: 0.57%\n",
      "[1900 Epochs]    RMSE:0.00150,   MAE: 0.00128,  MAPE: 0.63%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00243,   MAE: 0.00235,  MAPE: 1.11%\n",
      "\n",
      "\n",
      "Trial No.2\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.19167,   MAE: 0.18922,  MAPE: 89.94%\n",
      "[100 Epochs]    RMSE:0.00151,   MAE: 0.00137,  MAPE: 0.66%\n",
      "[200 Epochs]    RMSE:0.00111,   MAE: 0.00098,  MAPE: 0.48%\n",
      "[300 Epochs]    RMSE:0.00281,   MAE: 0.00265,  MAPE: 1.26%\n",
      "[400 Epochs]    RMSE:0.00467,   MAE: 0.00435,  MAPE: 2.07%\n",
      "[500 Epochs]    RMSE:0.00162,   MAE: 0.00143,  MAPE: 0.68%\n",
      "[600 Epochs]    RMSE:0.00172,   MAE: 0.00152,  MAPE: 0.72%\n",
      "[700 Epochs]    RMSE:0.00139,   MAE: 0.00116,  MAPE: 0.56%\n",
      "[800 Epochs]    RMSE:0.00225,   MAE: 0.00207,  MAPE: 0.98%\n",
      "[900 Epochs]    RMSE:0.00281,   MAE: 0.00247,  MAPE: 1.20%\n",
      "[1000 Epochs]    RMSE:0.00074,   MAE: 0.00059,  MAPE: 0.29%\n",
      "[1100 Epochs]    RMSE:0.00083,   MAE: 0.00071,  MAPE: 0.34%\n",
      "[1200 Epochs]    RMSE:0.00103,   MAE: 0.00076,  MAPE: 0.35%\n",
      "[1300 Epochs]    RMSE:0.00079,   MAE: 0.00068,  MAPE: 0.32%\n",
      "[1400 Epochs]    RMSE:0.00076,   MAE: 0.00065,  MAPE: 0.32%\n",
      "[1500 Epochs]    RMSE:0.00129,   MAE: 0.00113,  MAPE: 0.54%\n",
      "[1600 Epochs]    RMSE:0.00057,   MAE: 0.00046,  MAPE: 0.22%\n",
      "[1700 Epochs]    RMSE:0.00220,   MAE: 0.00210,  MAPE: 1.00%\n",
      "[1800 Epochs]    RMSE:0.00161,   MAE: 0.00143,  MAPE: 0.68%\n",
      "[1900 Epochs]    RMSE:0.00166,   MAE: 0.00145,  MAPE: 0.70%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00119,   MAE: 0.00096,  MAPE: 0.46%\n",
      "\n",
      "\n",
      "Trial No.3\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.25241,   MAE: 0.25014,  MAPE: 119.19%\n",
      "[100 Epochs]    RMSE:0.00279,   MAE: 0.00227,  MAPE: 1.08%\n",
      "[200 Epochs]    RMSE:0.00418,   MAE: 0.00374,  MAPE: 1.78%\n",
      "[300 Epochs]    RMSE:0.00414,   MAE: 0.00392,  MAPE: 1.86%\n",
      "[400 Epochs]    RMSE:0.00177,   MAE: 0.00152,  MAPE: 0.72%\n",
      "[500 Epochs]    RMSE:0.00183,   MAE: 0.00159,  MAPE: 0.76%\n",
      "[600 Epochs]    RMSE:0.00363,   MAE: 0.00331,  MAPE: 1.55%\n",
      "[700 Epochs]    RMSE:0.00185,   MAE: 0.00146,  MAPE: 0.69%\n",
      "[800 Epochs]    RMSE:0.00218,   MAE: 0.00198,  MAPE: 0.94%\n",
      "[900 Epochs]    RMSE:0.00328,   MAE: 0.00312,  MAPE: 1.48%\n",
      "[1000 Epochs]    RMSE:0.00099,   MAE: 0.00074,  MAPE: 0.37%\n",
      "[1100 Epochs]    RMSE:0.00093,   MAE: 0.00076,  MAPE: 0.36%\n",
      "[1200 Epochs]    RMSE:0.00068,   MAE: 0.00057,  MAPE: 0.27%\n",
      "[1300 Epochs]    RMSE:0.00163,   MAE: 0.00134,  MAPE: 0.63%\n",
      "[1400 Epochs]    RMSE:0.00099,   MAE: 0.00082,  MAPE: 0.39%\n",
      "[1500 Epochs]    RMSE:0.00193,   MAE: 0.00176,  MAPE: 0.83%\n",
      "[1600 Epochs]    RMSE:0.00155,   MAE: 0.00139,  MAPE: 0.66%\n",
      "[1700 Epochs]    RMSE:0.00077,   MAE: 0.00067,  MAPE: 0.33%\n",
      "[1800 Epochs]    RMSE:0.00109,   MAE: 0.00093,  MAPE: 0.44%\n",
      "[1900 Epochs]    RMSE:0.00128,   MAE: 0.00104,  MAPE: 0.51%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00145,   MAE: 0.00128,  MAPE: 0.60%\n",
      "\n",
      "\n",
      "Trial No.4\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.16909,   MAE: 0.16627,  MAPE: 79.56%\n",
      "[100 Epochs]    RMSE:0.00458,   MAE: 0.00386,  MAPE: 1.89%\n",
      "[200 Epochs]    RMSE:0.00268,   MAE: 0.00219,  MAPE: 1.02%\n",
      "[300 Epochs]    RMSE:0.00102,   MAE: 0.00079,  MAPE: 0.38%\n",
      "[400 Epochs]    RMSE:0.00164,   MAE: 0.00133,  MAPE: 0.65%\n",
      "[500 Epochs]    RMSE:0.00147,   MAE: 0.00121,  MAPE: 0.58%\n",
      "[600 Epochs]    RMSE:0.00093,   MAE: 0.00073,  MAPE: 0.35%\n",
      "[700 Epochs]    RMSE:0.00191,   MAE: 0.00153,  MAPE: 0.73%\n",
      "[800 Epochs]    RMSE:0.00223,   MAE: 0.00191,  MAPE: 0.89%\n",
      "[900 Epochs]    RMSE:0.00124,   MAE: 0.00108,  MAPE: 0.51%\n",
      "[1000 Epochs]    RMSE:0.00102,   MAE: 0.00082,  MAPE: 0.39%\n",
      "[1100 Epochs]    RMSE:0.00338,   MAE: 0.00322,  MAPE: 1.53%\n",
      "[1200 Epochs]    RMSE:0.00226,   MAE: 0.00207,  MAPE: 1.00%\n",
      "[1300 Epochs]    RMSE:0.00168,   MAE: 0.00141,  MAPE: 0.68%\n",
      "[1400 Epochs]    RMSE:0.00102,   MAE: 0.00079,  MAPE: 0.38%\n",
      "[1500 Epochs]    RMSE:0.00239,   MAE: 0.00218,  MAPE: 1.04%\n",
      "[1600 Epochs]    RMSE:0.00104,   MAE: 0.00091,  MAPE: 0.43%\n",
      "[1700 Epochs]    RMSE:0.00054,   MAE: 0.00043,  MAPE: 0.21%\n",
      "[1800 Epochs]    RMSE:0.00197,   MAE: 0.00155,  MAPE: 0.77%\n",
      "[1900 Epochs]    RMSE:0.00108,   MAE: 0.00085,  MAPE: 0.42%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00091,   MAE: 0.00065,  MAPE: 0.32%\n",
      "\n",
      "\n",
      "Trial No.5\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.30550,   MAE: 0.29994,  MAPE: 142.51%\n",
      "[100 Epochs]    RMSE:0.00399,   MAE: 0.00342,  MAPE: 1.62%\n",
      "[200 Epochs]    RMSE:0.00215,   MAE: 0.00171,  MAPE: 0.84%\n",
      "[300 Epochs]    RMSE:0.00201,   MAE: 0.00159,  MAPE: 0.75%\n",
      "[400 Epochs]    RMSE:0.00345,   MAE: 0.00302,  MAPE: 1.44%\n",
      "[500 Epochs]    RMSE:0.00316,   MAE: 0.00294,  MAPE: 1.38%\n",
      "[600 Epochs]    RMSE:0.00198,   MAE: 0.00168,  MAPE: 0.79%\n",
      "[700 Epochs]    RMSE:0.00161,   MAE: 0.00139,  MAPE: 0.66%\n",
      "[800 Epochs]    RMSE:0.00104,   MAE: 0.00086,  MAPE: 0.43%\n",
      "[900 Epochs]    RMSE:0.00101,   MAE: 0.00080,  MAPE: 0.38%\n",
      "[1000 Epochs]    RMSE:0.00122,   MAE: 0.00105,  MAPE: 0.50%\n",
      "[1100 Epochs]    RMSE:0.00232,   MAE: 0.00206,  MAPE: 1.01%\n",
      "[1200 Epochs]    RMSE:0.00096,   MAE: 0.00071,  MAPE: 0.34%\n",
      "[1300 Epochs]    RMSE:0.00132,   MAE: 0.00121,  MAPE: 0.58%\n",
      "[1400 Epochs]    RMSE:0.00078,   MAE: 0.00059,  MAPE: 0.28%\n",
      "[1500 Epochs]    RMSE:0.00198,   MAE: 0.00172,  MAPE: 0.83%\n",
      "[1600 Epochs]    RMSE:0.00158,   MAE: 0.00124,  MAPE: 0.59%\n",
      "[1700 Epochs]    RMSE:0.00217,   MAE: 0.00191,  MAPE: 0.91%\n",
      "[1800 Epochs]    RMSE:0.00338,   MAE: 0.00289,  MAPE: 1.40%\n",
      "[1900 Epochs]    RMSE:0.00100,   MAE: 0.00084,  MAPE: 0.40%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00241,   MAE: 0.00193,  MAPE: 0.91%\n",
      "\n",
      "\n",
      "Trial No.6\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.27974,   MAE: 0.27478,  MAPE: 130.27%\n",
      "[100 Epochs]    RMSE:0.00334,   MAE: 0.00264,  MAPE: 1.24%\n",
      "[200 Epochs]    RMSE:0.00249,   MAE: 0.00185,  MAPE: 0.92%\n",
      "[300 Epochs]    RMSE:0.00161,   MAE: 0.00123,  MAPE: 0.62%\n",
      "[400 Epochs]    RMSE:0.00087,   MAE: 0.00065,  MAPE: 0.30%\n",
      "[500 Epochs]    RMSE:0.00087,   MAE: 0.00073,  MAPE: 0.35%\n",
      "[600 Epochs]    RMSE:0.00099,   MAE: 0.00089,  MAPE: 0.43%\n",
      "[700 Epochs]    RMSE:0.00092,   MAE: 0.00075,  MAPE: 0.37%\n",
      "[800 Epochs]    RMSE:0.00071,   MAE: 0.00057,  MAPE: 0.27%\n",
      "[900 Epochs]    RMSE:0.00144,   MAE: 0.00122,  MAPE: 0.59%\n",
      "[1000 Epochs]    RMSE:0.00112,   MAE: 0.00093,  MAPE: 0.44%\n",
      "[1100 Epochs]    RMSE:0.00128,   MAE: 0.00108,  MAPE: 0.53%\n",
      "[1200 Epochs]    RMSE:0.00176,   MAE: 0.00145,  MAPE: 0.72%\n",
      "[1300 Epochs]    RMSE:0.00089,   MAE: 0.00071,  MAPE: 0.34%\n",
      "[1400 Epochs]    RMSE:0.00095,   MAE: 0.00079,  MAPE: 0.38%\n",
      "[1500 Epochs]    RMSE:0.00178,   MAE: 0.00155,  MAPE: 0.74%\n",
      "[1600 Epochs]    RMSE:0.00042,   MAE: 0.00036,  MAPE: 0.17%\n",
      "[1700 Epochs]    RMSE:0.00112,   MAE: 0.00094,  MAPE: 0.45%\n",
      "[1800 Epochs]    RMSE:0.00140,   MAE: 0.00118,  MAPE: 0.57%\n",
      "[1900 Epochs]    RMSE:0.00185,   MAE: 0.00169,  MAPE: 0.82%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00197,   MAE: 0.00192,  MAPE: 0.91%\n",
      "\n",
      "\n",
      "Trial No.7\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 Epochs]    RMSE:0.27116,   MAE: 0.26808,  MAPE: 128.00%\n",
      "[100 Epochs]    RMSE:0.00427,   MAE: 0.00358,  MAPE: 1.70%\n",
      "[200 Epochs]    RMSE:0.00273,   MAE: 0.00223,  MAPE: 1.08%\n",
      "[300 Epochs]    RMSE:0.00191,   MAE: 0.00178,  MAPE: 0.85%\n",
      "[400 Epochs]    RMSE:0.00062,   MAE: 0.00053,  MAPE: 0.25%\n",
      "[500 Epochs]    RMSE:0.00086,   MAE: 0.00060,  MAPE: 0.28%\n",
      "[600 Epochs]    RMSE:0.00174,   MAE: 0.00151,  MAPE: 0.73%\n",
      "[700 Epochs]    RMSE:0.00189,   MAE: 0.00155,  MAPE: 0.77%\n",
      "[800 Epochs]    RMSE:0.00147,   MAE: 0.00123,  MAPE: 0.58%\n",
      "[900 Epochs]    RMSE:0.00145,   MAE: 0.00108,  MAPE: 0.54%\n",
      "[1000 Epochs]    RMSE:0.00252,   MAE: 0.00228,  MAPE: 1.08%\n",
      "[1100 Epochs]    RMSE:0.00334,   MAE: 0.00311,  MAPE: 1.47%\n",
      "[1200 Epochs]    RMSE:0.00131,   MAE: 0.00109,  MAPE: 0.52%\n",
      "[1300 Epochs]    RMSE:0.00246,   MAE: 0.00216,  MAPE: 1.01%\n",
      "[1400 Epochs]    RMSE:0.00143,   MAE: 0.00121,  MAPE: 0.57%\n",
      "[1500 Epochs]    RMSE:0.00136,   MAE: 0.00113,  MAPE: 0.56%\n",
      "[1600 Epochs]    RMSE:0.00112,   MAE: 0.00090,  MAPE: 0.42%\n",
      "[1700 Epochs]    RMSE:0.00239,   MAE: 0.00226,  MAPE: 1.08%\n",
      "[1800 Epochs]    RMSE:0.00107,   MAE: 0.00084,  MAPE: 0.40%\n",
      "[1900 Epochs]    RMSE:0.00094,   MAE: 0.00076,  MAPE: 0.35%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00284,   MAE: 0.00269,  MAPE: 1.28%\n",
      "\n",
      "\n",
      "Trial No.8\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.12899,   MAE: 0.12155,  MAPE: 57.77%\n",
      "[100 Epochs]    RMSE:0.00236,   MAE: 0.00200,  MAPE: 0.94%\n",
      "[200 Epochs]    RMSE:0.00389,   MAE: 0.00355,  MAPE: 1.70%\n",
      "[300 Epochs]    RMSE:0.00346,   MAE: 0.00270,  MAPE: 1.27%\n",
      "[400 Epochs]    RMSE:0.00557,   MAE: 0.00535,  MAPE: 2.55%\n",
      "[500 Epochs]    RMSE:0.00214,   MAE: 0.00179,  MAPE: 0.87%\n",
      "[600 Epochs]    RMSE:0.00134,   MAE: 0.00106,  MAPE: 0.50%\n",
      "[700 Epochs]    RMSE:0.00261,   MAE: 0.00217,  MAPE: 1.01%\n",
      "[800 Epochs]    RMSE:0.00119,   MAE: 0.00085,  MAPE: 0.40%\n",
      "[900 Epochs]    RMSE:0.00114,   MAE: 0.00097,  MAPE: 0.46%\n",
      "[1000 Epochs]    RMSE:0.00410,   MAE: 0.00346,  MAPE: 1.61%\n",
      "[1100 Epochs]    RMSE:0.00136,   MAE: 0.00101,  MAPE: 0.49%\n",
      "[1200 Epochs]    RMSE:0.00209,   MAE: 0.00170,  MAPE: 0.81%\n",
      "[1300 Epochs]    RMSE:0.00185,   MAE: 0.00141,  MAPE: 0.65%\n",
      "[1400 Epochs]    RMSE:0.00403,   MAE: 0.00351,  MAPE: 1.66%\n",
      "[1500 Epochs]    RMSE:0.00135,   MAE: 0.00095,  MAPE: 0.45%\n",
      "[1600 Epochs]    RMSE:0.00249,   MAE: 0.00204,  MAPE: 0.98%\n",
      "[1700 Epochs]    RMSE:0.00240,   MAE: 0.00196,  MAPE: 0.94%\n",
      "[1800 Epochs]    RMSE:0.00119,   MAE: 0.00091,  MAPE: 0.43%\n",
      "[1900 Epochs]    RMSE:0.00121,   MAE: 0.00087,  MAPE: 0.40%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00094,   MAE: 0.00078,  MAPE: 0.38%\n",
      "\n",
      "\n",
      "Trial No.9\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.14730,   MAE: 0.13808,  MAPE: 67.50%\n",
      "[100 Epochs]    RMSE:0.00270,   MAE: 0.00232,  MAPE: 1.10%\n",
      "[200 Epochs]    RMSE:0.00407,   MAE: 0.00373,  MAPE: 1.77%\n",
      "[300 Epochs]    RMSE:0.00215,   MAE: 0.00178,  MAPE: 0.83%\n",
      "[400 Epochs]    RMSE:0.00214,   MAE: 0.00184,  MAPE: 0.87%\n",
      "[500 Epochs]    RMSE:0.00306,   MAE: 0.00249,  MAPE: 1.20%\n",
      "[600 Epochs]    RMSE:0.00201,   MAE: 0.00180,  MAPE: 0.86%\n",
      "[700 Epochs]    RMSE:0.00191,   MAE: 0.00141,  MAPE: 0.66%\n",
      "[800 Epochs]    RMSE:0.00379,   MAE: 0.00313,  MAPE: 1.53%\n",
      "[900 Epochs]    RMSE:0.00302,   MAE: 0.00260,  MAPE: 1.26%\n",
      "[1000 Epochs]    RMSE:0.00172,   MAE: 0.00139,  MAPE: 0.66%\n",
      "[1100 Epochs]    RMSE:0.00230,   MAE: 0.00180,  MAPE: 0.84%\n",
      "[1200 Epochs]    RMSE:0.00187,   MAE: 0.00148,  MAPE: 0.69%\n",
      "[1300 Epochs]    RMSE:0.00186,   MAE: 0.00167,  MAPE: 0.79%\n",
      "[1400 Epochs]    RMSE:0.00088,   MAE: 0.00072,  MAPE: 0.34%\n",
      "[1500 Epochs]    RMSE:0.00095,   MAE: 0.00082,  MAPE: 0.39%\n",
      "[1600 Epochs]    RMSE:0.00069,   MAE: 0.00058,  MAPE: 0.27%\n",
      "[1700 Epochs]    RMSE:0.00221,   MAE: 0.00213,  MAPE: 1.02%\n",
      "[1800 Epochs]    RMSE:0.00147,   MAE: 0.00109,  MAPE: 0.51%\n",
      "[1900 Epochs]    RMSE:0.00260,   MAE: 0.00226,  MAPE: 1.08%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00075,   MAE: 0.00057,  MAPE: 0.27%\n",
      "\n",
      "\n",
      "Trial No.10\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.32012,   MAE: 0.31032,  MAPE: 147.21%\n",
      "[100 Epochs]    RMSE:0.00483,   MAE: 0.00415,  MAPE: 1.97%\n",
      "[200 Epochs]    RMSE:0.00205,   MAE: 0.00146,  MAPE: 0.73%\n",
      "[300 Epochs]    RMSE:0.00123,   MAE: 0.00099,  MAPE: 0.48%\n",
      "[400 Epochs]    RMSE:0.00272,   MAE: 0.00206,  MAPE: 0.95%\n",
      "[500 Epochs]    RMSE:0.00146,   MAE: 0.00110,  MAPE: 0.51%\n",
      "[600 Epochs]    RMSE:0.00291,   MAE: 0.00258,  MAPE: 1.26%\n",
      "[700 Epochs]    RMSE:0.00247,   MAE: 0.00214,  MAPE: 1.03%\n",
      "[800 Epochs]    RMSE:0.00167,   MAE: 0.00131,  MAPE: 0.63%\n",
      "[900 Epochs]    RMSE:0.00236,   MAE: 0.00204,  MAPE: 0.96%\n",
      "[1000 Epochs]    RMSE:0.00195,   MAE: 0.00166,  MAPE: 0.80%\n",
      "[1100 Epochs]    RMSE:0.00238,   MAE: 0.00212,  MAPE: 0.99%\n",
      "[1200 Epochs]    RMSE:0.00216,   MAE: 0.00183,  MAPE: 0.91%\n",
      "[1300 Epochs]    RMSE:0.00278,   MAE: 0.00200,  MAPE: 0.94%\n",
      "[1400 Epochs]    RMSE:0.00162,   MAE: 0.00130,  MAPE: 0.62%\n",
      "[1500 Epochs]    RMSE:0.00093,   MAE: 0.00070,  MAPE: 0.33%\n",
      "[1600 Epochs]    RMSE:0.00118,   MAE: 0.00090,  MAPE: 0.43%\n",
      "[1700 Epochs]    RMSE:0.00102,   MAE: 0.00076,  MAPE: 0.36%\n",
      "[1800 Epochs]    RMSE:0.00133,   MAE: 0.00112,  MAPE: 0.54%\n",
      "[1900 Epochs]    RMSE:0.00109,   MAE: 0.00087,  MAPE: 0.42%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00103,   MAE: 0.00087,  MAPE: 0.42%\n",
      "\n",
      "\n",
      "Trial No.11\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.11001,   MAE: 0.09125,  MAPE: 45.40%\n",
      "[100 Epochs]    RMSE:0.00607,   MAE: 0.00564,  MAPE: 2.68%\n",
      "[200 Epochs]    RMSE:0.00431,   MAE: 0.00379,  MAPE: 1.84%\n",
      "[300 Epochs]    RMSE:0.00258,   MAE: 0.00205,  MAPE: 0.98%\n",
      "[400 Epochs]    RMSE:0.00221,   MAE: 0.00193,  MAPE: 0.93%\n",
      "[500 Epochs]    RMSE:0.00294,   MAE: 0.00257,  MAPE: 1.21%\n",
      "[600 Epochs]    RMSE:0.00242,   MAE: 0.00212,  MAPE: 1.01%\n",
      "[700 Epochs]    RMSE:0.00311,   MAE: 0.00265,  MAPE: 1.28%\n",
      "[800 Epochs]    RMSE:0.00214,   MAE: 0.00179,  MAPE: 0.86%\n",
      "[900 Epochs]    RMSE:0.00246,   MAE: 0.00230,  MAPE: 1.10%\n",
      "[1000 Epochs]    RMSE:0.00419,   MAE: 0.00404,  MAPE: 1.93%\n",
      "[1100 Epochs]    RMSE:0.00182,   MAE: 0.00170,  MAPE: 0.80%\n",
      "[1200 Epochs]    RMSE:0.00258,   MAE: 0.00246,  MAPE: 1.17%\n",
      "[1300 Epochs]    RMSE:0.00318,   MAE: 0.00305,  MAPE: 1.45%\n",
      "[1400 Epochs]    RMSE:0.00204,   MAE: 0.00180,  MAPE: 0.86%\n",
      "[1500 Epochs]    RMSE:0.00081,   MAE: 0.00070,  MAPE: 0.33%\n",
      "[1600 Epochs]    RMSE:0.00150,   MAE: 0.00120,  MAPE: 0.56%\n",
      "[1700 Epochs]    RMSE:0.00350,   MAE: 0.00343,  MAPE: 1.64%\n",
      "[1800 Epochs]    RMSE:0.00104,   MAE: 0.00082,  MAPE: 0.38%\n",
      "[1900 Epochs]    RMSE:0.00104,   MAE: 0.00084,  MAPE: 0.39%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00078,   MAE: 0.00065,  MAPE: 0.31%\n",
      "\n",
      "\n",
      "Trial No.12\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.09467,   MAE: 0.08128,  MAPE: 39.59%\n",
      "[100 Epochs]    RMSE:0.00481,   MAE: 0.00424,  MAPE: 2.01%\n",
      "[200 Epochs]    RMSE:0.00357,   MAE: 0.00247,  MAPE: 1.16%\n",
      "[300 Epochs]    RMSE:0.00164,   MAE: 0.00130,  MAPE: 0.64%\n",
      "[400 Epochs]    RMSE:0.00208,   MAE: 0.00154,  MAPE: 0.76%\n",
      "[500 Epochs]    RMSE:0.00956,   MAE: 0.00916,  MAPE: 4.33%\n",
      "[600 Epochs]    RMSE:0.00675,   MAE: 0.00631,  MAPE: 3.01%\n",
      "[700 Epochs]    RMSE:0.00295,   MAE: 0.00254,  MAPE: 1.25%\n",
      "[800 Epochs]    RMSE:0.00183,   MAE: 0.00138,  MAPE: 0.66%\n",
      "[900 Epochs]    RMSE:0.00221,   MAE: 0.00149,  MAPE: 0.69%\n",
      "[1000 Epochs]    RMSE:0.00170,   MAE: 0.00150,  MAPE: 0.70%\n",
      "[1100 Epochs]    RMSE:0.00261,   MAE: 0.00227,  MAPE: 1.06%\n",
      "[1200 Epochs]    RMSE:0.00149,   MAE: 0.00130,  MAPE: 0.63%\n",
      "[1300 Epochs]    RMSE:0.00115,   MAE: 0.00099,  MAPE: 0.47%\n",
      "[1400 Epochs]    RMSE:0.00362,   MAE: 0.00331,  MAPE: 1.56%\n",
      "[1500 Epochs]    RMSE:0.00154,   MAE: 0.00121,  MAPE: 0.59%\n",
      "[1600 Epochs]    RMSE:0.00091,   MAE: 0.00078,  MAPE: 0.38%\n",
      "[1700 Epochs]    RMSE:0.00118,   MAE: 0.00095,  MAPE: 0.46%\n",
      "[1800 Epochs]    RMSE:0.00190,   MAE: 0.00154,  MAPE: 0.75%\n",
      "[1900 Epochs]    RMSE:0.00096,   MAE: 0.00077,  MAPE: 0.36%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00065,   MAE: 0.00055,  MAPE: 0.26%\n",
      "\n",
      "\n",
      "Trial No.13\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.09933,   MAE: 0.08423,  MAPE: 40.69%\n",
      "[100 Epochs]    RMSE:0.00255,   MAE: 0.00217,  MAPE: 1.03%\n",
      "[200 Epochs]    RMSE:0.00285,   MAE: 0.00265,  MAPE: 1.26%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300 Epochs]    RMSE:0.00479,   MAE: 0.00410,  MAPE: 1.96%\n",
      "[400 Epochs]    RMSE:0.00222,   MAE: 0.00200,  MAPE: 0.95%\n",
      "[500 Epochs]    RMSE:0.00391,   MAE: 0.00340,  MAPE: 1.64%\n",
      "[600 Epochs]    RMSE:0.00528,   MAE: 0.00482,  MAPE: 2.29%\n",
      "[700 Epochs]    RMSE:0.00407,   MAE: 0.00394,  MAPE: 1.87%\n",
      "[800 Epochs]    RMSE:0.00182,   MAE: 0.00151,  MAPE: 0.73%\n",
      "[900 Epochs]    RMSE:0.00332,   MAE: 0.00323,  MAPE: 1.56%\n",
      "[1000 Epochs]    RMSE:0.00167,   MAE: 0.00150,  MAPE: 0.73%\n",
      "[1100 Epochs]    RMSE:0.00232,   MAE: 0.00211,  MAPE: 0.99%\n",
      "[1200 Epochs]    RMSE:0.00245,   MAE: 0.00201,  MAPE: 0.92%\n",
      "[1300 Epochs]    RMSE:0.00203,   MAE: 0.00192,  MAPE: 0.92%\n",
      "[1400 Epochs]    RMSE:0.00319,   MAE: 0.00306,  MAPE: 1.46%\n",
      "[1500 Epochs]    RMSE:0.00072,   MAE: 0.00064,  MAPE: 0.31%\n",
      "[1600 Epochs]    RMSE:0.00122,   MAE: 0.00103,  MAPE: 0.50%\n",
      "[1700 Epochs]    RMSE:0.00117,   MAE: 0.00097,  MAPE: 0.47%\n",
      "[1800 Epochs]    RMSE:0.00216,   MAE: 0.00197,  MAPE: 0.93%\n",
      "[1900 Epochs]    RMSE:0.00191,   MAE: 0.00165,  MAPE: 0.79%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00128,   MAE: 0.00105,  MAPE: 0.51%\n",
      "\n",
      "\n",
      "Trial No.14\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.30147,   MAE: 0.29696,  MAPE: 140.98%\n",
      "[100 Epochs]    RMSE:0.00138,   MAE: 0.00114,  MAPE: 0.54%\n",
      "[200 Epochs]    RMSE:0.00245,   MAE: 0.00183,  MAPE: 0.89%\n",
      "[300 Epochs]    RMSE:0.00166,   MAE: 0.00144,  MAPE: 0.68%\n",
      "[400 Epochs]    RMSE:0.00310,   MAE: 0.00291,  MAPE: 1.41%\n",
      "[500 Epochs]    RMSE:0.00142,   MAE: 0.00123,  MAPE: 0.60%\n",
      "[600 Epochs]    RMSE:0.00187,   MAE: 0.00170,  MAPE: 0.82%\n",
      "[700 Epochs]    RMSE:0.00205,   MAE: 0.00189,  MAPE: 0.90%\n",
      "[800 Epochs]    RMSE:0.00311,   MAE: 0.00290,  MAPE: 1.38%\n",
      "[900 Epochs]    RMSE:0.00087,   MAE: 0.00070,  MAPE: 0.34%\n",
      "[1000 Epochs]    RMSE:0.00085,   MAE: 0.00070,  MAPE: 0.33%\n",
      "[1100 Epochs]    RMSE:0.00116,   MAE: 0.00098,  MAPE: 0.48%\n",
      "[1200 Epochs]    RMSE:0.00087,   MAE: 0.00068,  MAPE: 0.32%\n",
      "[1300 Epochs]    RMSE:0.00133,   MAE: 0.00106,  MAPE: 0.49%\n",
      "[1400 Epochs]    RMSE:0.00076,   MAE: 0.00069,  MAPE: 0.33%\n",
      "[1500 Epochs]    RMSE:0.00132,   MAE: 0.00118,  MAPE: 0.56%\n",
      "[1600 Epochs]    RMSE:0.00233,   MAE: 0.00227,  MAPE: 1.09%\n",
      "[1700 Epochs]    RMSE:0.00131,   MAE: 0.00126,  MAPE: 0.61%\n",
      "[1800 Epochs]    RMSE:0.00089,   MAE: 0.00078,  MAPE: 0.37%\n",
      "[1900 Epochs]    RMSE:0.00057,   MAE: 0.00046,  MAPE: 0.23%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00093,   MAE: 0.00073,  MAPE: 0.35%\n",
      "\n",
      "\n",
      "Trial No.15\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.32814,   MAE: 0.32333,  MAPE: 154.41%\n",
      "[100 Epochs]    RMSE:0.00347,   MAE: 0.00281,  MAPE: 1.37%\n",
      "[200 Epochs]    RMSE:0.00357,   MAE: 0.00324,  MAPE: 1.52%\n",
      "[300 Epochs]    RMSE:0.00359,   MAE: 0.00337,  MAPE: 1.59%\n",
      "[400 Epochs]    RMSE:0.00203,   MAE: 0.00186,  MAPE: 0.88%\n",
      "[500 Epochs]    RMSE:0.00068,   MAE: 0.00049,  MAPE: 0.23%\n",
      "[600 Epochs]    RMSE:0.00240,   MAE: 0.00202,  MAPE: 0.94%\n",
      "[700 Epochs]    RMSE:0.00272,   MAE: 0.00263,  MAPE: 1.26%\n",
      "[800 Epochs]    RMSE:0.00112,   MAE: 0.00099,  MAPE: 0.48%\n",
      "[900 Epochs]    RMSE:0.00225,   MAE: 0.00219,  MAPE: 1.05%\n",
      "[1000 Epochs]    RMSE:0.00305,   MAE: 0.00267,  MAPE: 1.29%\n",
      "[1100 Epochs]    RMSE:0.00122,   MAE: 0.00097,  MAPE: 0.48%\n",
      "[1200 Epochs]    RMSE:0.00204,   MAE: 0.00193,  MAPE: 0.91%\n",
      "[1300 Epochs]    RMSE:0.00228,   MAE: 0.00212,  MAPE: 1.00%\n",
      "[1400 Epochs]    RMSE:0.00253,   MAE: 0.00249,  MAPE: 1.20%\n",
      "[1500 Epochs]    RMSE:0.00127,   MAE: 0.00106,  MAPE: 0.51%\n",
      "[1600 Epochs]    RMSE:0.00253,   MAE: 0.00249,  MAPE: 1.20%\n",
      "[1700 Epochs]    RMSE:0.00165,   MAE: 0.00149,  MAPE: 0.70%\n",
      "[1800 Epochs]    RMSE:0.00129,   MAE: 0.00111,  MAPE: 0.54%\n",
      "[1900 Epochs]    RMSE:0.00076,   MAE: 0.00058,  MAPE: 0.27%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00060,   MAE: 0.00048,  MAPE: 0.22%\n",
      "\n",
      "\n",
      "Trial No.16\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.09625,   MAE: 0.07863,  MAPE: 37.32%\n",
      "[100 Epochs]    RMSE:0.00430,   MAE: 0.00398,  MAPE: 1.91%\n",
      "[200 Epochs]    RMSE:0.00174,   MAE: 0.00145,  MAPE: 0.70%\n",
      "[300 Epochs]    RMSE:0.00178,   MAE: 0.00138,  MAPE: 0.65%\n",
      "[400 Epochs]    RMSE:0.00281,   MAE: 0.00236,  MAPE: 1.12%\n",
      "[500 Epochs]    RMSE:0.00444,   MAE: 0.00369,  MAPE: 1.80%\n",
      "[600 Epochs]    RMSE:0.00184,   MAE: 0.00144,  MAPE: 0.67%\n",
      "[700 Epochs]    RMSE:0.00154,   MAE: 0.00124,  MAPE: 0.59%\n",
      "[800 Epochs]    RMSE:0.00705,   MAE: 0.00638,  MAPE: 3.00%\n",
      "[900 Epochs]    RMSE:0.00109,   MAE: 0.00085,  MAPE: 0.41%\n",
      "[1000 Epochs]    RMSE:0.00187,   MAE: 0.00176,  MAPE: 0.83%\n",
      "[1100 Epochs]    RMSE:0.00278,   MAE: 0.00241,  MAPE: 1.13%\n",
      "[1200 Epochs]    RMSE:0.00214,   MAE: 0.00174,  MAPE: 0.85%\n",
      "[1300 Epochs]    RMSE:0.00088,   MAE: 0.00072,  MAPE: 0.34%\n",
      "[1400 Epochs]    RMSE:0.00312,   MAE: 0.00256,  MAPE: 1.18%\n",
      "[1500 Epochs]    RMSE:0.00096,   MAE: 0.00084,  MAPE: 0.40%\n",
      "[1600 Epochs]    RMSE:0.00125,   MAE: 0.00089,  MAPE: 0.42%\n",
      "[1700 Epochs]    RMSE:0.00165,   MAE: 0.00139,  MAPE: 0.67%\n",
      "[1800 Epochs]    RMSE:0.00066,   MAE: 0.00051,  MAPE: 0.24%\n",
      "[1900 Epochs]    RMSE:0.00095,   MAE: 0.00075,  MAPE: 0.36%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00268,   MAE: 0.00250,  MAPE: 1.19%\n",
      "\n",
      "\n",
      "Trial No.17\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.30891,   MAE: 0.30148,  MAPE: 142.89%\n",
      "[100 Epochs]    RMSE:0.00555,   MAE: 0.00510,  MAPE: 2.43%\n",
      "[200 Epochs]    RMSE:0.00379,   MAE: 0.00337,  MAPE: 1.59%\n",
      "[300 Epochs]    RMSE:0.00187,   MAE: 0.00141,  MAPE: 0.66%\n",
      "[400 Epochs]    RMSE:0.00195,   MAE: 0.00171,  MAPE: 0.82%\n",
      "[500 Epochs]    RMSE:0.00335,   MAE: 0.00307,  MAPE: 1.47%\n",
      "[600 Epochs]    RMSE:0.00104,   MAE: 0.00087,  MAPE: 0.42%\n",
      "[700 Epochs]    RMSE:0.00243,   MAE: 0.00218,  MAPE: 1.05%\n",
      "[800 Epochs]    RMSE:0.00191,   MAE: 0.00154,  MAPE: 0.74%\n",
      "[900 Epochs]    RMSE:0.00135,   MAE: 0.00117,  MAPE: 0.56%\n",
      "[1000 Epochs]    RMSE:0.00098,   MAE: 0.00077,  MAPE: 0.37%\n",
      "[1100 Epochs]    RMSE:0.00052,   MAE: 0.00041,  MAPE: 0.20%\n",
      "[1200 Epochs]    RMSE:0.00129,   MAE: 0.00103,  MAPE: 0.49%\n",
      "[1300 Epochs]    RMSE:0.00091,   MAE: 0.00081,  MAPE: 0.39%\n",
      "[1400 Epochs]    RMSE:0.00105,   MAE: 0.00091,  MAPE: 0.44%\n",
      "[1500 Epochs]    RMSE:0.00171,   MAE: 0.00153,  MAPE: 0.71%\n",
      "[1600 Epochs]    RMSE:0.00075,   MAE: 0.00062,  MAPE: 0.29%\n",
      "[1700 Epochs]    RMSE:0.00093,   MAE: 0.00080,  MAPE: 0.38%\n",
      "[1800 Epochs]    RMSE:0.00078,   MAE: 0.00063,  MAPE: 0.30%\n",
      "[1900 Epochs]    RMSE:0.00218,   MAE: 0.00210,  MAPE: 1.00%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00093,   MAE: 0.00074,  MAPE: 0.35%\n",
      "\n",
      "\n",
      "Trial No.18\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.28010,   MAE: 0.27688,  MAPE: 132.61%\n",
      "[100 Epochs]    RMSE:0.00226,   MAE: 0.00158,  MAPE: 0.74%\n",
      "[200 Epochs]    RMSE:0.00141,   MAE: 0.00104,  MAPE: 0.51%\n",
      "[300 Epochs]    RMSE:0.00168,   MAE: 0.00147,  MAPE: 0.70%\n",
      "[400 Epochs]    RMSE:0.00196,   MAE: 0.00152,  MAPE: 0.73%\n",
      "[500 Epochs]    RMSE:0.00084,   MAE: 0.00067,  MAPE: 0.32%\n",
      "[600 Epochs]    RMSE:0.00170,   MAE: 0.00145,  MAPE: 0.69%\n",
      "[700 Epochs]    RMSE:0.00181,   MAE: 0.00143,  MAPE: 0.67%\n",
      "[800 Epochs]    RMSE:0.00082,   MAE: 0.00065,  MAPE: 0.31%\n",
      "[900 Epochs]    RMSE:0.00092,   MAE: 0.00073,  MAPE: 0.35%\n",
      "[1000 Epochs]    RMSE:0.00105,   MAE: 0.00096,  MAPE: 0.46%\n",
      "[1100 Epochs]    RMSE:0.00118,   MAE: 0.00090,  MAPE: 0.42%\n",
      "[1200 Epochs]    RMSE:0.00147,   MAE: 0.00111,  MAPE: 0.54%\n",
      "[1300 Epochs]    RMSE:0.00164,   MAE: 0.00136,  MAPE: 0.66%\n",
      "[1400 Epochs]    RMSE:0.00068,   MAE: 0.00050,  MAPE: 0.24%\n",
      "[1500 Epochs]    RMSE:0.00095,   MAE: 0.00078,  MAPE: 0.38%\n",
      "[1600 Epochs]    RMSE:0.00101,   MAE: 0.00093,  MAPE: 0.44%\n",
      "[1700 Epochs]    RMSE:0.00190,   MAE: 0.00165,  MAPE: 0.79%\n",
      "[1800 Epochs]    RMSE:0.00130,   MAE: 0.00094,  MAPE: 0.45%\n",
      "[1900 Epochs]    RMSE:0.00129,   MAE: 0.00118,  MAPE: 0.56%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00122,   MAE: 0.00093,  MAPE: 0.45%\n",
      "\n",
      "\n",
      "Trial No.19\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.22861,   MAE: 0.22458,  MAPE: 107.76%\n",
      "[100 Epochs]    RMSE:0.00348,   MAE: 0.00287,  MAPE: 1.40%\n",
      "[200 Epochs]    RMSE:0.00255,   MAE: 0.00211,  MAPE: 1.01%\n",
      "[300 Epochs]    RMSE:0.00251,   MAE: 0.00185,  MAPE: 0.87%\n",
      "[400 Epochs]    RMSE:0.00696,   MAE: 0.00606,  MAPE: 2.95%\n",
      "[500 Epochs]    RMSE:0.00181,   MAE: 0.00158,  MAPE: 0.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600 Epochs]    RMSE:0.00148,   MAE: 0.00114,  MAPE: 0.55%\n",
      "[700 Epochs]    RMSE:0.00101,   MAE: 0.00074,  MAPE: 0.36%\n",
      "[800 Epochs]    RMSE:0.00090,   MAE: 0.00074,  MAPE: 0.37%\n",
      "[900 Epochs]    RMSE:0.00074,   MAE: 0.00054,  MAPE: 0.26%\n",
      "[1000 Epochs]    RMSE:0.00091,   MAE: 0.00075,  MAPE: 0.36%\n",
      "[1100 Epochs]    RMSE:0.00130,   MAE: 0.00101,  MAPE: 0.50%\n",
      "[1200 Epochs]    RMSE:0.00217,   MAE: 0.00198,  MAPE: 0.95%\n",
      "[1300 Epochs]    RMSE:0.00148,   MAE: 0.00117,  MAPE: 0.55%\n",
      "[1400 Epochs]    RMSE:0.00202,   MAE: 0.00181,  MAPE: 0.85%\n",
      "[1500 Epochs]    RMSE:0.00095,   MAE: 0.00067,  MAPE: 0.32%\n",
      "[1600 Epochs]    RMSE:0.00101,   MAE: 0.00086,  MAPE: 0.41%\n",
      "[1700 Epochs]    RMSE:0.00076,   MAE: 0.00059,  MAPE: 0.29%\n",
      "[1800 Epochs]    RMSE:0.00096,   MAE: 0.00074,  MAPE: 0.36%\n",
      "[1900 Epochs]    RMSE:0.00087,   MAE: 0.00069,  MAPE: 0.33%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00148,   MAE: 0.00114,  MAPE: 0.55%\n",
      "\n",
      "\n",
      "Trial No.20\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.21826,   MAE: 0.21615,  MAPE: 103.05%\n",
      "[100 Epochs]    RMSE:0.00261,   MAE: 0.00209,  MAPE: 1.00%\n",
      "[200 Epochs]    RMSE:0.00205,   MAE: 0.00148,  MAPE: 0.69%\n",
      "[300 Epochs]    RMSE:0.00356,   MAE: 0.00315,  MAPE: 1.52%\n",
      "[400 Epochs]    RMSE:0.00666,   MAE: 0.00648,  MAPE: 3.10%\n",
      "[500 Epochs]    RMSE:0.00538,   MAE: 0.00509,  MAPE: 2.42%\n",
      "[600 Epochs]    RMSE:0.00103,   MAE: 0.00094,  MAPE: 0.45%\n",
      "[700 Epochs]    RMSE:0.00159,   MAE: 0.00141,  MAPE: 0.66%\n",
      "[800 Epochs]    RMSE:0.00288,   MAE: 0.00241,  MAPE: 1.12%\n",
      "[900 Epochs]    RMSE:0.00198,   MAE: 0.00179,  MAPE: 0.85%\n",
      "[1000 Epochs]    RMSE:0.00113,   MAE: 0.00097,  MAPE: 0.46%\n",
      "[1100 Epochs]    RMSE:0.00142,   MAE: 0.00118,  MAPE: 0.55%\n",
      "[1200 Epochs]    RMSE:0.00138,   MAE: 0.00126,  MAPE: 0.60%\n",
      "[1300 Epochs]    RMSE:0.00158,   MAE: 0.00122,  MAPE: 0.58%\n",
      "[1400 Epochs]    RMSE:0.00070,   MAE: 0.00053,  MAPE: 0.25%\n",
      "[1500 Epochs]    RMSE:0.00116,   MAE: 0.00089,  MAPE: 0.42%\n",
      "[1600 Epochs]    RMSE:0.00094,   MAE: 0.00071,  MAPE: 0.34%\n",
      "[1700 Epochs]    RMSE:0.00158,   MAE: 0.00144,  MAPE: 0.69%\n",
      "[1800 Epochs]    RMSE:0.00251,   MAE: 0.00238,  MAPE: 1.13%\n",
      "[1900 Epochs]    RMSE:0.00186,   MAE: 0.00171,  MAPE: 0.82%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00076,   MAE: 0.00060,  MAPE: 0.29%\n",
      "\n",
      "\n",
      "Trial No.21\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.34722,   MAE: 0.33994,  MAPE: 161.55%\n",
      "[100 Epochs]    RMSE:0.00233,   MAE: 0.00193,  MAPE: 0.91%\n",
      "[200 Epochs]    RMSE:0.00114,   MAE: 0.00090,  MAPE: 0.43%\n",
      "[300 Epochs]    RMSE:0.00182,   MAE: 0.00160,  MAPE: 0.78%\n",
      "[400 Epochs]    RMSE:0.00172,   MAE: 0.00138,  MAPE: 0.66%\n",
      "[500 Epochs]    RMSE:0.00234,   MAE: 0.00168,  MAPE: 0.82%\n",
      "[600 Epochs]    RMSE:0.00254,   MAE: 0.00214,  MAPE: 1.02%\n",
      "[700 Epochs]    RMSE:0.00082,   MAE: 0.00065,  MAPE: 0.31%\n",
      "[800 Epochs]    RMSE:0.00386,   MAE: 0.00368,  MAPE: 1.77%\n",
      "[900 Epochs]    RMSE:0.00089,   MAE: 0.00072,  MAPE: 0.34%\n",
      "[1000 Epochs]    RMSE:0.00203,   MAE: 0.00157,  MAPE: 0.74%\n",
      "[1100 Epochs]    RMSE:0.00094,   MAE: 0.00078,  MAPE: 0.38%\n",
      "[1200 Epochs]    RMSE:0.00167,   MAE: 0.00140,  MAPE: 0.67%\n",
      "[1300 Epochs]    RMSE:0.00157,   MAE: 0.00144,  MAPE: 0.69%\n",
      "[1400 Epochs]    RMSE:0.00075,   MAE: 0.00063,  MAPE: 0.30%\n",
      "[1500 Epochs]    RMSE:0.00101,   MAE: 0.00089,  MAPE: 0.42%\n",
      "[1600 Epochs]    RMSE:0.00124,   MAE: 0.00107,  MAPE: 0.51%\n",
      "[1700 Epochs]    RMSE:0.00233,   MAE: 0.00208,  MAPE: 0.99%\n",
      "[1800 Epochs]    RMSE:0.00071,   MAE: 0.00053,  MAPE: 0.25%\n",
      "[1900 Epochs]    RMSE:0.00060,   MAE: 0.00053,  MAPE: 0.25%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00175,   MAE: 0.00159,  MAPE: 0.75%\n",
      "\n",
      "\n",
      "Trial No.22\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.22373,   MAE: 0.22221,  MAPE: 105.95%\n",
      "[100 Epochs]    RMSE:0.00556,   MAE: 0.00483,  MAPE: 2.30%\n",
      "[200 Epochs]    RMSE:0.00213,   MAE: 0.00187,  MAPE: 0.90%\n",
      "[300 Epochs]    RMSE:0.00332,   MAE: 0.00296,  MAPE: 1.39%\n",
      "[400 Epochs]    RMSE:0.00122,   MAE: 0.00101,  MAPE: 0.48%\n",
      "[500 Epochs]    RMSE:0.00244,   MAE: 0.00215,  MAPE: 1.04%\n",
      "[600 Epochs]    RMSE:0.00127,   MAE: 0.00100,  MAPE: 0.47%\n",
      "[700 Epochs]    RMSE:0.00271,   MAE: 0.00253,  MAPE: 1.22%\n",
      "[800 Epochs]    RMSE:0.00254,   MAE: 0.00212,  MAPE: 1.02%\n",
      "[900 Epochs]    RMSE:0.00141,   MAE: 0.00118,  MAPE: 0.56%\n",
      "[1000 Epochs]    RMSE:0.00111,   MAE: 0.00081,  MAPE: 0.39%\n",
      "[1100 Epochs]    RMSE:0.00212,   MAE: 0.00202,  MAPE: 0.96%\n",
      "[1200 Epochs]    RMSE:0.00193,   MAE: 0.00172,  MAPE: 0.83%\n",
      "[1300 Epochs]    RMSE:0.00153,   MAE: 0.00133,  MAPE: 0.62%\n",
      "[1400 Epochs]    RMSE:0.00154,   MAE: 0.00123,  MAPE: 0.59%\n",
      "[1500 Epochs]    RMSE:0.00127,   MAE: 0.00101,  MAPE: 0.49%\n",
      "[1600 Epochs]    RMSE:0.00088,   MAE: 0.00071,  MAPE: 0.34%\n",
      "[1700 Epochs]    RMSE:0.00127,   MAE: 0.00115,  MAPE: 0.55%\n",
      "[1800 Epochs]    RMSE:0.00201,   MAE: 0.00184,  MAPE: 0.89%\n",
      "[1900 Epochs]    RMSE:0.00140,   MAE: 0.00135,  MAPE: 0.65%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00058,   MAE: 0.00044,  MAPE: 0.22%\n",
      "\n",
      "\n",
      "Trial No.23\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.19739,   MAE: 0.19371,  MAPE: 92.18%\n",
      "[100 Epochs]    RMSE:0.00197,   MAE: 0.00155,  MAPE: 0.75%\n",
      "[200 Epochs]    RMSE:0.00207,   MAE: 0.00159,  MAPE: 0.76%\n",
      "[300 Epochs]    RMSE:0.00146,   MAE: 0.00127,  MAPE: 0.60%\n",
      "[400 Epochs]    RMSE:0.00275,   MAE: 0.00238,  MAPE: 1.11%\n",
      "[500 Epochs]    RMSE:0.00397,   MAE: 0.00381,  MAPE: 1.83%\n",
      "[600 Epochs]    RMSE:0.00142,   MAE: 0.00122,  MAPE: 0.58%\n",
      "[700 Epochs]    RMSE:0.00086,   MAE: 0.00075,  MAPE: 0.36%\n",
      "[800 Epochs]    RMSE:0.00177,   MAE: 0.00144,  MAPE: 0.69%\n",
      "[900 Epochs]    RMSE:0.00174,   MAE: 0.00149,  MAPE: 0.70%\n",
      "[1000 Epochs]    RMSE:0.00224,   MAE: 0.00208,  MAPE: 0.99%\n",
      "[1100 Epochs]    RMSE:0.00128,   MAE: 0.00111,  MAPE: 0.54%\n",
      "[1200 Epochs]    RMSE:0.00091,   MAE: 0.00075,  MAPE: 0.36%\n",
      "[1300 Epochs]    RMSE:0.00068,   MAE: 0.00058,  MAPE: 0.28%\n",
      "[1400 Epochs]    RMSE:0.00169,   MAE: 0.00159,  MAPE: 0.75%\n",
      "[1500 Epochs]    RMSE:0.00078,   MAE: 0.00059,  MAPE: 0.28%\n",
      "[1600 Epochs]    RMSE:0.00091,   MAE: 0.00068,  MAPE: 0.33%\n",
      "[1700 Epochs]    RMSE:0.00063,   MAE: 0.00051,  MAPE: 0.24%\n",
      "[1800 Epochs]    RMSE:0.00070,   MAE: 0.00054,  MAPE: 0.25%\n",
      "[1900 Epochs]    RMSE:0.00107,   MAE: 0.00096,  MAPE: 0.46%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00091,   MAE: 0.00076,  MAPE: 0.36%\n",
      "\n",
      "\n",
      "Trial No.24\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.16987,   MAE: 0.15257,  MAPE: 71.42%\n",
      "[100 Epochs]    RMSE:0.00581,   MAE: 0.00552,  MAPE: 2.61%\n",
      "[200 Epochs]    RMSE:0.00221,   MAE: 0.00173,  MAPE: 0.81%\n",
      "[300 Epochs]    RMSE:0.00184,   MAE: 0.00160,  MAPE: 0.76%\n",
      "[400 Epochs]    RMSE:0.00198,   MAE: 0.00143,  MAPE: 0.69%\n",
      "[500 Epochs]    RMSE:0.00417,   MAE: 0.00386,  MAPE: 1.85%\n",
      "[600 Epochs]    RMSE:0.00232,   MAE: 0.00196,  MAPE: 0.91%\n",
      "[700 Epochs]    RMSE:0.00108,   MAE: 0.00082,  MAPE: 0.38%\n",
      "[800 Epochs]    RMSE:0.00115,   MAE: 0.00098,  MAPE: 0.48%\n",
      "[900 Epochs]    RMSE:0.00259,   MAE: 0.00224,  MAPE: 1.05%\n",
      "[1000 Epochs]    RMSE:0.00127,   MAE: 0.00101,  MAPE: 0.49%\n",
      "[1100 Epochs]    RMSE:0.00235,   MAE: 0.00210,  MAPE: 0.99%\n",
      "[1200 Epochs]    RMSE:0.00244,   MAE: 0.00212,  MAPE: 1.03%\n",
      "[1300 Epochs]    RMSE:0.00082,   MAE: 0.00058,  MAPE: 0.28%\n",
      "[1400 Epochs]    RMSE:0.00127,   MAE: 0.00115,  MAPE: 0.55%\n",
      "[1500 Epochs]    RMSE:0.00093,   MAE: 0.00069,  MAPE: 0.33%\n",
      "[1600 Epochs]    RMSE:0.00055,   MAE: 0.00047,  MAPE: 0.22%\n",
      "[1700 Epochs]    RMSE:0.00093,   MAE: 0.00074,  MAPE: 0.35%\n",
      "[1800 Epochs]    RMSE:0.00129,   MAE: 0.00105,  MAPE: 0.51%\n",
      "[1900 Epochs]    RMSE:0.00108,   MAE: 0.00088,  MAPE: 0.43%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00136,   MAE: 0.00117,  MAPE: 0.56%\n",
      "\n",
      "\n",
      "Trial No.25\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.19591,   MAE: 0.18392,  MAPE: 86.53%\n",
      "[100 Epochs]    RMSE:0.00624,   MAE: 0.00566,  MAPE: 2.68%\n",
      "[200 Epochs]    RMSE:0.00509,   MAE: 0.00467,  MAPE: 2.21%\n",
      "[300 Epochs]    RMSE:0.00426,   MAE: 0.00361,  MAPE: 1.68%\n",
      "[400 Epochs]    RMSE:0.00181,   MAE: 0.00134,  MAPE: 0.66%\n",
      "[500 Epochs]    RMSE:0.00864,   MAE: 0.00806,  MAPE: 3.82%\n",
      "[600 Epochs]    RMSE:0.00134,   MAE: 0.00103,  MAPE: 0.49%\n",
      "[700 Epochs]    RMSE:0.00696,   MAE: 0.00645,  MAPE: 3.05%\n",
      "[800 Epochs]    RMSE:0.00610,   MAE: 0.00582,  MAPE: 2.78%\n",
      "[900 Epochs]    RMSE:0.00607,   MAE: 0.00580,  MAPE: 2.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000 Epochs]    RMSE:0.00456,   MAE: 0.00428,  MAPE: 2.03%\n",
      "[1100 Epochs]    RMSE:0.00391,   MAE: 0.00334,  MAPE: 1.58%\n",
      "[1200 Epochs]    RMSE:0.00146,   MAE: 0.00124,  MAPE: 0.58%\n",
      "[1300 Epochs]    RMSE:0.00137,   MAE: 0.00117,  MAPE: 0.56%\n",
      "[1400 Epochs]    RMSE:0.00478,   MAE: 0.00446,  MAPE: 2.11%\n",
      "[1500 Epochs]    RMSE:0.00474,   MAE: 0.00437,  MAPE: 2.06%\n",
      "[1600 Epochs]    RMSE:0.00172,   MAE: 0.00143,  MAPE: 0.67%\n",
      "[1700 Epochs]    RMSE:0.00534,   MAE: 0.00517,  MAPE: 2.46%\n",
      "[1800 Epochs]    RMSE:0.00150,   MAE: 0.00121,  MAPE: 0.60%\n",
      "[1900 Epochs]    RMSE:0.00213,   MAE: 0.00188,  MAPE: 0.91%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00395,   MAE: 0.00383,  MAPE: 1.83%\n",
      "\n",
      "\n",
      "Trial No.26\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.21709,   MAE: 0.21342,  MAPE: 102.10%\n",
      "[100 Epochs]    RMSE:0.00275,   MAE: 0.00242,  MAPE: 1.16%\n",
      "[200 Epochs]    RMSE:0.00167,   MAE: 0.00138,  MAPE: 0.67%\n",
      "[300 Epochs]    RMSE:0.00243,   MAE: 0.00225,  MAPE: 1.08%\n",
      "[400 Epochs]    RMSE:0.00302,   MAE: 0.00268,  MAPE: 1.29%\n",
      "[500 Epochs]    RMSE:0.00341,   MAE: 0.00326,  MAPE: 1.56%\n",
      "[600 Epochs]    RMSE:0.00194,   MAE: 0.00169,  MAPE: 0.83%\n",
      "[700 Epochs]    RMSE:0.00163,   MAE: 0.00140,  MAPE: 0.67%\n",
      "[800 Epochs]    RMSE:0.00120,   MAE: 0.00106,  MAPE: 0.50%\n",
      "[900 Epochs]    RMSE:0.00102,   MAE: 0.00080,  MAPE: 0.39%\n",
      "[1000 Epochs]    RMSE:0.00164,   MAE: 0.00134,  MAPE: 0.63%\n",
      "[1100 Epochs]    RMSE:0.00111,   MAE: 0.00090,  MAPE: 0.42%\n",
      "[1200 Epochs]    RMSE:0.00130,   MAE: 0.00109,  MAPE: 0.53%\n",
      "[1300 Epochs]    RMSE:0.00258,   MAE: 0.00225,  MAPE: 1.10%\n",
      "[1400 Epochs]    RMSE:0.00137,   MAE: 0.00122,  MAPE: 0.59%\n",
      "[1500 Epochs]    RMSE:0.00219,   MAE: 0.00207,  MAPE: 1.00%\n",
      "[1600 Epochs]    RMSE:0.00068,   MAE: 0.00053,  MAPE: 0.25%\n",
      "[1700 Epochs]    RMSE:0.00209,   MAE: 0.00157,  MAPE: 0.72%\n",
      "[1800 Epochs]    RMSE:0.00081,   MAE: 0.00068,  MAPE: 0.33%\n",
      "[1900 Epochs]    RMSE:0.00100,   MAE: 0.00089,  MAPE: 0.44%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00522,   MAE: 0.00509,  MAPE: 2.42%\n",
      "\n",
      "\n",
      "Trial No.27\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.20399,   MAE: 0.20176,  MAPE: 97.24%\n",
      "[100 Epochs]    RMSE:0.00496,   MAE: 0.00432,  MAPE: 2.03%\n",
      "[200 Epochs]    RMSE:0.00117,   MAE: 0.00092,  MAPE: 0.44%\n",
      "[300 Epochs]    RMSE:0.00607,   MAE: 0.00578,  MAPE: 2.76%\n",
      "[400 Epochs]    RMSE:0.00192,   MAE: 0.00152,  MAPE: 0.71%\n",
      "[500 Epochs]    RMSE:0.00481,   MAE: 0.00457,  MAPE: 2.17%\n",
      "[600 Epochs]    RMSE:0.00647,   MAE: 0.00566,  MAPE: 2.67%\n",
      "[700 Epochs]    RMSE:0.00475,   MAE: 0.00463,  MAPE: 2.21%\n",
      "[800 Epochs]    RMSE:0.00140,   MAE: 0.00112,  MAPE: 0.52%\n",
      "[900 Epochs]    RMSE:0.00318,   MAE: 0.00282,  MAPE: 1.33%\n",
      "[1000 Epochs]    RMSE:0.00342,   MAE: 0.00312,  MAPE: 1.50%\n",
      "[1100 Epochs]    RMSE:0.00168,   MAE: 0.00125,  MAPE: 0.58%\n",
      "[1200 Epochs]    RMSE:0.00115,   MAE: 0.00103,  MAPE: 0.48%\n",
      "[1300 Epochs]    RMSE:0.00183,   MAE: 0.00171,  MAPE: 0.81%\n",
      "[1400 Epochs]    RMSE:0.00075,   MAE: 0.00067,  MAPE: 0.32%\n",
      "[1500 Epochs]    RMSE:0.00194,   MAE: 0.00150,  MAPE: 0.69%\n",
      "[1600 Epochs]    RMSE:0.00111,   MAE: 0.00097,  MAPE: 0.46%\n",
      "[1700 Epochs]    RMSE:0.00099,   MAE: 0.00085,  MAPE: 0.40%\n",
      "[1800 Epochs]    RMSE:0.00153,   MAE: 0.00130,  MAPE: 0.62%\n",
      "[1900 Epochs]    RMSE:0.00115,   MAE: 0.00102,  MAPE: 0.49%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00123,   MAE: 0.00111,  MAPE: 0.52%\n",
      "\n",
      "\n",
      "Trial No.28\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.30435,   MAE: 0.29986,  MAPE: 143.47%\n",
      "[100 Epochs]    RMSE:0.00597,   MAE: 0.00544,  MAPE: 2.57%\n",
      "[200 Epochs]    RMSE:0.00294,   MAE: 0.00254,  MAPE: 1.18%\n",
      "[300 Epochs]    RMSE:0.00160,   MAE: 0.00127,  MAPE: 0.59%\n",
      "[400 Epochs]    RMSE:0.00303,   MAE: 0.00262,  MAPE: 1.28%\n",
      "[500 Epochs]    RMSE:0.00350,   MAE: 0.00318,  MAPE: 1.54%\n",
      "[600 Epochs]    RMSE:0.00369,   MAE: 0.00325,  MAPE: 1.52%\n",
      "[700 Epochs]    RMSE:0.00096,   MAE: 0.00075,  MAPE: 0.36%\n",
      "[800 Epochs]    RMSE:0.00106,   MAE: 0.00089,  MAPE: 0.43%\n",
      "[900 Epochs]    RMSE:0.00083,   MAE: 0.00063,  MAPE: 0.30%\n",
      "[1000 Epochs]    RMSE:0.00289,   MAE: 0.00239,  MAPE: 1.18%\n",
      "[1100 Epochs]    RMSE:0.00083,   MAE: 0.00070,  MAPE: 0.33%\n",
      "[1200 Epochs]    RMSE:0.00118,   MAE: 0.00097,  MAPE: 0.45%\n",
      "[1300 Epochs]    RMSE:0.00089,   MAE: 0.00079,  MAPE: 0.37%\n",
      "[1400 Epochs]    RMSE:0.00086,   MAE: 0.00073,  MAPE: 0.35%\n",
      "[1500 Epochs]    RMSE:0.00168,   MAE: 0.00150,  MAPE: 0.70%\n",
      "[1600 Epochs]    RMSE:0.00113,   MAE: 0.00088,  MAPE: 0.44%\n",
      "[1700 Epochs]    RMSE:0.00111,   MAE: 0.00075,  MAPE: 0.35%\n",
      "[1800 Epochs]    RMSE:0.00260,   MAE: 0.00226,  MAPE: 1.08%\n",
      "[1900 Epochs]    RMSE:0.00084,   MAE: 0.00070,  MAPE: 0.33%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00094,   MAE: 0.00074,  MAPE: 0.37%\n",
      "\n",
      "\n",
      "Trial No.29\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.22305,   MAE: 0.22141,  MAPE: 105.63%\n",
      "[100 Epochs]    RMSE:0.00384,   MAE: 0.00306,  MAPE: 1.46%\n",
      "[200 Epochs]    RMSE:0.00322,   MAE: 0.00274,  MAPE: 1.30%\n",
      "[300 Epochs]    RMSE:0.00224,   MAE: 0.00180,  MAPE: 0.89%\n",
      "[400 Epochs]    RMSE:0.00253,   MAE: 0.00209,  MAPE: 0.99%\n",
      "[500 Epochs]    RMSE:0.00315,   MAE: 0.00283,  MAPE: 1.34%\n",
      "[600 Epochs]    RMSE:0.00264,   MAE: 0.00239,  MAPE: 1.14%\n",
      "[700 Epochs]    RMSE:0.00137,   MAE: 0.00121,  MAPE: 0.59%\n",
      "[800 Epochs]    RMSE:0.00266,   MAE: 0.00235,  MAPE: 1.11%\n",
      "[900 Epochs]    RMSE:0.00123,   MAE: 0.00097,  MAPE: 0.45%\n",
      "[1000 Epochs]    RMSE:0.00085,   MAE: 0.00070,  MAPE: 0.33%\n",
      "[1100 Epochs]    RMSE:0.00109,   MAE: 0.00094,  MAPE: 0.46%\n",
      "[1200 Epochs]    RMSE:0.00378,   MAE: 0.00350,  MAPE: 1.69%\n",
      "[1300 Epochs]    RMSE:0.00157,   MAE: 0.00135,  MAPE: 0.63%\n",
      "[1400 Epochs]    RMSE:0.00208,   MAE: 0.00181,  MAPE: 0.85%\n",
      "[1500 Epochs]    RMSE:0.00125,   MAE: 0.00087,  MAPE: 0.41%\n",
      "[1600 Epochs]    RMSE:0.00099,   MAE: 0.00080,  MAPE: 0.38%\n",
      "[1700 Epochs]    RMSE:0.00077,   MAE: 0.00057,  MAPE: 0.27%\n",
      "[1800 Epochs]    RMSE:0.00092,   MAE: 0.00083,  MAPE: 0.40%\n",
      "[1900 Epochs]    RMSE:0.00137,   MAE: 0.00109,  MAPE: 0.52%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00220,   MAE: 0.00188,  MAPE: 0.90%\n",
      "\n",
      "\n",
      "Trial No.30\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.33152,   MAE: 0.32526,  MAPE: 154.54%\n",
      "[100 Epochs]    RMSE:0.00548,   MAE: 0.00513,  MAPE: 2.43%\n",
      "[200 Epochs]    RMSE:0.00286,   MAE: 0.00244,  MAPE: 1.16%\n",
      "[300 Epochs]    RMSE:0.00121,   MAE: 0.00103,  MAPE: 0.50%\n",
      "[400 Epochs]    RMSE:0.00066,   MAE: 0.00058,  MAPE: 0.28%\n",
      "[500 Epochs]    RMSE:0.00399,   MAE: 0.00375,  MAPE: 1.78%\n",
      "[600 Epochs]    RMSE:0.00195,   MAE: 0.00181,  MAPE: 0.87%\n",
      "[700 Epochs]    RMSE:0.00063,   MAE: 0.00051,  MAPE: 0.25%\n",
      "[800 Epochs]    RMSE:0.00121,   MAE: 0.00103,  MAPE: 0.49%\n",
      "[900 Epochs]    RMSE:0.00141,   MAE: 0.00114,  MAPE: 0.55%\n",
      "[1000 Epochs]    RMSE:0.00121,   MAE: 0.00103,  MAPE: 0.48%\n",
      "[1100 Epochs]    RMSE:0.00173,   MAE: 0.00144,  MAPE: 0.67%\n",
      "[1200 Epochs]    RMSE:0.00267,   MAE: 0.00257,  MAPE: 1.23%\n",
      "[1300 Epochs]    RMSE:0.00081,   MAE: 0.00071,  MAPE: 0.34%\n",
      "[1400 Epochs]    RMSE:0.00070,   MAE: 0.00051,  MAPE: 0.25%\n",
      "[1500 Epochs]    RMSE:0.00107,   MAE: 0.00082,  MAPE: 0.40%\n",
      "[1600 Epochs]    RMSE:0.00071,   MAE: 0.00060,  MAPE: 0.29%\n",
      "[1700 Epochs]    RMSE:0.00166,   MAE: 0.00132,  MAPE: 0.63%\n",
      "[1800 Epochs]    RMSE:0.00227,   MAE: 0.00208,  MAPE: 1.01%\n",
      "[1900 Epochs]    RMSE:0.00067,   MAE: 0.00052,  MAPE: 0.26%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00127,   MAE: 0.00090,  MAPE: 0.41%\n",
      "\n",
      "\n",
      "Trial No.31\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.27676,   MAE: 0.26900,  MAPE: 127.11%\n",
      "[100 Epochs]    RMSE:0.00324,   MAE: 0.00252,  MAPE: 1.18%\n",
      "[200 Epochs]    RMSE:0.00412,   MAE: 0.00375,  MAPE: 1.78%\n",
      "[300 Epochs]    RMSE:0.00405,   MAE: 0.00345,  MAPE: 1.60%\n",
      "[400 Epochs]    RMSE:0.00574,   MAE: 0.00473,  MAPE: 2.19%\n",
      "[500 Epochs]    RMSE:0.00417,   MAE: 0.00371,  MAPE: 1.78%\n",
      "[600 Epochs]    RMSE:0.00364,   MAE: 0.00325,  MAPE: 1.53%\n",
      "[700 Epochs]    RMSE:0.00097,   MAE: 0.00074,  MAPE: 0.35%\n",
      "[800 Epochs]    RMSE:0.00304,   MAE: 0.00274,  MAPE: 1.28%\n",
      "[900 Epochs]    RMSE:0.00240,   MAE: 0.00190,  MAPE: 0.89%\n",
      "[1000 Epochs]    RMSE:0.00143,   MAE: 0.00122,  MAPE: 0.59%\n",
      "[1100 Epochs]    RMSE:0.00170,   MAE: 0.00157,  MAPE: 0.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200 Epochs]    RMSE:0.00126,   MAE: 0.00115,  MAPE: 0.55%\n",
      "[1300 Epochs]    RMSE:0.00245,   MAE: 0.00205,  MAPE: 1.01%\n",
      "[1400 Epochs]    RMSE:0.00170,   MAE: 0.00145,  MAPE: 0.72%\n",
      "[1500 Epochs]    RMSE:0.00141,   MAE: 0.00115,  MAPE: 0.54%\n",
      "[1600 Epochs]    RMSE:0.00179,   MAE: 0.00164,  MAPE: 0.78%\n",
      "[1700 Epochs]    RMSE:0.00169,   MAE: 0.00146,  MAPE: 0.72%\n",
      "[1800 Epochs]    RMSE:0.00042,   MAE: 0.00032,  MAPE: 0.16%\n",
      "[1900 Epochs]    RMSE:0.00211,   MAE: 0.00196,  MAPE: 0.93%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00049,   MAE: 0.00041,  MAPE: 0.20%\n",
      "\n",
      "\n",
      "Trial No.32\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.50249,   MAE: 0.47673,  MAPE: 227.55%\n",
      "[100 Epochs]    RMSE:0.00473,   MAE: 0.00343,  MAPE: 1.62%\n",
      "[200 Epochs]    RMSE:0.00215,   MAE: 0.00164,  MAPE: 0.78%\n",
      "[300 Epochs]    RMSE:0.00247,   MAE: 0.00188,  MAPE: 0.90%\n",
      "[400 Epochs]    RMSE:0.00193,   MAE: 0.00152,  MAPE: 0.71%\n",
      "[500 Epochs]    RMSE:0.00185,   MAE: 0.00158,  MAPE: 0.75%\n",
      "[600 Epochs]    RMSE:0.00157,   MAE: 0.00128,  MAPE: 0.62%\n",
      "[700 Epochs]    RMSE:0.00159,   MAE: 0.00131,  MAPE: 0.62%\n",
      "[800 Epochs]    RMSE:0.00148,   MAE: 0.00117,  MAPE: 0.57%\n",
      "[900 Epochs]    RMSE:0.00307,   MAE: 0.00276,  MAPE: 1.30%\n",
      "[1000 Epochs]    RMSE:0.00210,   MAE: 0.00190,  MAPE: 0.90%\n",
      "[1100 Epochs]    RMSE:0.00115,   MAE: 0.00091,  MAPE: 0.44%\n",
      "[1200 Epochs]    RMSE:0.00183,   MAE: 0.00146,  MAPE: 0.71%\n",
      "[1300 Epochs]    RMSE:0.00184,   MAE: 0.00143,  MAPE: 0.68%\n",
      "[1400 Epochs]    RMSE:0.00497,   MAE: 0.00425,  MAPE: 2.04%\n",
      "[1500 Epochs]    RMSE:0.00143,   MAE: 0.00119,  MAPE: 0.57%\n",
      "[1600 Epochs]    RMSE:0.00155,   MAE: 0.00132,  MAPE: 0.62%\n",
      "[1700 Epochs]    RMSE:0.00131,   MAE: 0.00107,  MAPE: 0.51%\n",
      "[1800 Epochs]    RMSE:0.00201,   MAE: 0.00166,  MAPE: 0.81%\n",
      "[1900 Epochs]    RMSE:0.00252,   MAE: 0.00197,  MAPE: 0.96%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00321,   MAE: 0.00289,  MAPE: 1.37%\n",
      "\n",
      "\n",
      "Trial No.33\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.25355,   MAE: 0.24884,  MAPE: 117.88%\n",
      "[100 Epochs]    RMSE:0.00336,   MAE: 0.00262,  MAPE: 1.27%\n",
      "[200 Epochs]    RMSE:0.00191,   MAE: 0.00138,  MAPE: 0.65%\n",
      "[300 Epochs]    RMSE:0.00303,   MAE: 0.00249,  MAPE: 1.21%\n",
      "[400 Epochs]    RMSE:0.00273,   MAE: 0.00211,  MAPE: 0.98%\n",
      "[500 Epochs]    RMSE:0.00401,   MAE: 0.00380,  MAPE: 1.81%\n",
      "[600 Epochs]    RMSE:0.00411,   MAE: 0.00379,  MAPE: 1.79%\n",
      "[700 Epochs]    RMSE:0.00128,   MAE: 0.00104,  MAPE: 0.50%\n",
      "[800 Epochs]    RMSE:0.00221,   MAE: 0.00215,  MAPE: 1.02%\n",
      "[900 Epochs]    RMSE:0.00130,   MAE: 0.00106,  MAPE: 0.50%\n",
      "[1000 Epochs]    RMSE:0.00147,   MAE: 0.00122,  MAPE: 0.56%\n",
      "[1100 Epochs]    RMSE:0.00156,   MAE: 0.00110,  MAPE: 0.51%\n",
      "[1200 Epochs]    RMSE:0.00126,   MAE: 0.00115,  MAPE: 0.54%\n",
      "[1300 Epochs]    RMSE:0.00106,   MAE: 0.00086,  MAPE: 0.42%\n",
      "[1400 Epochs]    RMSE:0.00166,   MAE: 0.00141,  MAPE: 0.67%\n",
      "[1500 Epochs]    RMSE:0.00172,   MAE: 0.00137,  MAPE: 0.63%\n",
      "[1600 Epochs]    RMSE:0.00229,   MAE: 0.00176,  MAPE: 0.81%\n",
      "[1700 Epochs]    RMSE:0.00235,   MAE: 0.00203,  MAPE: 0.95%\n",
      "[1800 Epochs]    RMSE:0.00275,   MAE: 0.00266,  MAPE: 1.28%\n",
      "[1900 Epochs]    RMSE:0.00167,   MAE: 0.00156,  MAPE: 0.74%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00073,   MAE: 0.00056,  MAPE: 0.27%\n",
      "\n",
      "\n",
      "Trial No.34\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.20772,   MAE: 0.20678,  MAPE: 98.93%\n",
      "[100 Epochs]    RMSE:0.00144,   MAE: 0.00113,  MAPE: 0.54%\n",
      "[200 Epochs]    RMSE:0.00279,   MAE: 0.00245,  MAPE: 1.20%\n",
      "[300 Epochs]    RMSE:0.00320,   MAE: 0.00294,  MAPE: 1.39%\n",
      "[400 Epochs]    RMSE:0.00469,   MAE: 0.00445,  MAPE: 2.10%\n",
      "[500 Epochs]    RMSE:0.00093,   MAE: 0.00074,  MAPE: 0.35%\n",
      "[600 Epochs]    RMSE:0.00117,   MAE: 0.00097,  MAPE: 0.45%\n",
      "[700 Epochs]    RMSE:0.00173,   MAE: 0.00150,  MAPE: 0.71%\n",
      "[800 Epochs]    RMSE:0.00080,   MAE: 0.00071,  MAPE: 0.33%\n",
      "[900 Epochs]    RMSE:0.00243,   MAE: 0.00229,  MAPE: 1.09%\n",
      "[1000 Epochs]    RMSE:0.00169,   MAE: 0.00142,  MAPE: 0.68%\n",
      "[1100 Epochs]    RMSE:0.00177,   MAE: 0.00158,  MAPE: 0.75%\n",
      "[1200 Epochs]    RMSE:0.00131,   MAE: 0.00107,  MAPE: 0.52%\n",
      "[1300 Epochs]    RMSE:0.00136,   MAE: 0.00123,  MAPE: 0.58%\n",
      "[1400 Epochs]    RMSE:0.00152,   MAE: 0.00134,  MAPE: 0.65%\n",
      "[1500 Epochs]    RMSE:0.00069,   MAE: 0.00054,  MAPE: 0.26%\n",
      "[1600 Epochs]    RMSE:0.00067,   MAE: 0.00055,  MAPE: 0.27%\n",
      "[1700 Epochs]    RMSE:0.00169,   MAE: 0.00159,  MAPE: 0.75%\n",
      "[1800 Epochs]    RMSE:0.00291,   MAE: 0.00279,  MAPE: 1.33%\n",
      "[1900 Epochs]    RMSE:0.00087,   MAE: 0.00073,  MAPE: 0.34%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00116,   MAE: 0.00098,  MAPE: 0.47%\n",
      "\n",
      "\n",
      "Trial No.35\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.20761,   MAE: 0.20440,  MAPE: 97.46%\n",
      "[100 Epochs]    RMSE:0.00400,   MAE: 0.00275,  MAPE: 1.34%\n",
      "[200 Epochs]    RMSE:0.00297,   MAE: 0.00262,  MAPE: 1.26%\n",
      "[300 Epochs]    RMSE:0.00314,   MAE: 0.00270,  MAPE: 1.28%\n",
      "[400 Epochs]    RMSE:0.00208,   MAE: 0.00182,  MAPE: 0.87%\n",
      "[500 Epochs]    RMSE:0.00393,   MAE: 0.00379,  MAPE: 1.81%\n",
      "[600 Epochs]    RMSE:0.00478,   MAE: 0.00430,  MAPE: 2.05%\n",
      "[700 Epochs]    RMSE:0.00115,   MAE: 0.00094,  MAPE: 0.44%\n",
      "[800 Epochs]    RMSE:0.00112,   MAE: 0.00101,  MAPE: 0.48%\n",
      "[900 Epochs]    RMSE:0.00278,   MAE: 0.00255,  MAPE: 1.21%\n",
      "[1000 Epochs]    RMSE:0.00078,   MAE: 0.00063,  MAPE: 0.30%\n",
      "[1100 Epochs]    RMSE:0.00070,   MAE: 0.00055,  MAPE: 0.27%\n",
      "[1200 Epochs]    RMSE:0.00265,   MAE: 0.00247,  MAPE: 1.17%\n",
      "[1300 Epochs]    RMSE:0.00136,   MAE: 0.00091,  MAPE: 0.43%\n",
      "[1400 Epochs]    RMSE:0.00217,   MAE: 0.00192,  MAPE: 0.90%\n",
      "[1500 Epochs]    RMSE:0.00145,   MAE: 0.00120,  MAPE: 0.56%\n",
      "[1600 Epochs]    RMSE:0.00345,   MAE: 0.00321,  MAPE: 1.52%\n",
      "[1700 Epochs]    RMSE:0.00078,   MAE: 0.00067,  MAPE: 0.32%\n",
      "[1800 Epochs]    RMSE:0.00150,   MAE: 0.00139,  MAPE: 0.66%\n",
      "[1900 Epochs]    RMSE:0.00114,   MAE: 0.00099,  MAPE: 0.47%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00102,   MAE: 0.00084,  MAPE: 0.40%\n",
      "\n",
      "\n",
      "Trial No.36\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.16986,   MAE: 0.16490,  MAPE: 78.22%\n",
      "[100 Epochs]    RMSE:0.00298,   MAE: 0.00258,  MAPE: 1.25%\n",
      "[200 Epochs]    RMSE:0.00116,   MAE: 0.00091,  MAPE: 0.44%\n",
      "[300 Epochs]    RMSE:0.00444,   MAE: 0.00398,  MAPE: 1.90%\n",
      "[400 Epochs]    RMSE:0.00330,   MAE: 0.00285,  MAPE: 1.37%\n",
      "[500 Epochs]    RMSE:0.00262,   MAE: 0.00215,  MAPE: 1.03%\n",
      "[600 Epochs]    RMSE:0.00241,   MAE: 0.00173,  MAPE: 0.81%\n",
      "[700 Epochs]    RMSE:0.00203,   MAE: 0.00167,  MAPE: 0.78%\n",
      "[800 Epochs]    RMSE:0.00107,   MAE: 0.00095,  MAPE: 0.45%\n",
      "[900 Epochs]    RMSE:0.00406,   MAE: 0.00356,  MAPE: 1.68%\n",
      "[1000 Epochs]    RMSE:0.00134,   MAE: 0.00116,  MAPE: 0.56%\n",
      "[1100 Epochs]    RMSE:0.00067,   MAE: 0.00053,  MAPE: 0.25%\n",
      "[1200 Epochs]    RMSE:0.00343,   MAE: 0.00290,  MAPE: 1.38%\n",
      "[1300 Epochs]    RMSE:0.00090,   MAE: 0.00069,  MAPE: 0.33%\n",
      "[1400 Epochs]    RMSE:0.00202,   MAE: 0.00163,  MAPE: 0.76%\n",
      "[1500 Epochs]    RMSE:0.00159,   MAE: 0.00130,  MAPE: 0.63%\n",
      "[1600 Epochs]    RMSE:0.00155,   MAE: 0.00142,  MAPE: 0.68%\n",
      "[1700 Epochs]    RMSE:0.00109,   MAE: 0.00093,  MAPE: 0.45%\n",
      "[1800 Epochs]    RMSE:0.00158,   MAE: 0.00130,  MAPE: 0.63%\n",
      "[1900 Epochs]    RMSE:0.00067,   MAE: 0.00053,  MAPE: 0.25%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00096,   MAE: 0.00088,  MAPE: 0.42%\n",
      "\n",
      "\n",
      "Trial No.37\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.21786,   MAE: 0.21464,  MAPE: 102.71%\n",
      "[100 Epochs]    RMSE:0.00271,   MAE: 0.00219,  MAPE: 1.04%\n",
      "[200 Epochs]    RMSE:0.00446,   MAE: 0.00406,  MAPE: 1.91%\n",
      "[300 Epochs]    RMSE:0.00152,   MAE: 0.00120,  MAPE: 0.58%\n",
      "[400 Epochs]    RMSE:0.00430,   MAE: 0.00403,  MAPE: 1.91%\n",
      "[500 Epochs]    RMSE:0.00206,   MAE: 0.00168,  MAPE: 0.81%\n",
      "[600 Epochs]    RMSE:0.00205,   MAE: 0.00161,  MAPE: 0.74%\n",
      "[700 Epochs]    RMSE:0.00208,   MAE: 0.00163,  MAPE: 0.80%\n",
      "[800 Epochs]    RMSE:0.00229,   MAE: 0.00192,  MAPE: 0.90%\n",
      "[900 Epochs]    RMSE:0.00112,   MAE: 0.00089,  MAPE: 0.42%\n",
      "[1000 Epochs]    RMSE:0.00087,   MAE: 0.00068,  MAPE: 0.32%\n",
      "[1100 Epochs]    RMSE:0.00204,   MAE: 0.00155,  MAPE: 0.72%\n",
      "[1200 Epochs]    RMSE:0.00700,   MAE: 0.00640,  MAPE: 3.00%\n",
      "[1300 Epochs]    RMSE:0.00116,   MAE: 0.00093,  MAPE: 0.44%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400 Epochs]    RMSE:0.00199,   MAE: 0.00164,  MAPE: 0.78%\n",
      "[1500 Epochs]    RMSE:0.00177,   MAE: 0.00133,  MAPE: 0.65%\n",
      "[1600 Epochs]    RMSE:0.00058,   MAE: 0.00048,  MAPE: 0.23%\n",
      "[1700 Epochs]    RMSE:0.00146,   MAE: 0.00130,  MAPE: 0.62%\n",
      "[1800 Epochs]    RMSE:0.00083,   MAE: 0.00063,  MAPE: 0.31%\n",
      "[1900 Epochs]    RMSE:0.00122,   MAE: 0.00091,  MAPE: 0.43%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00118,   MAE: 0.00092,  MAPE: 0.42%\n",
      "\n",
      "\n",
      "Trial No.38\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.24967,   MAE: 0.24863,  MAPE: 118.79%\n",
      "[100 Epochs]    RMSE:0.00283,   MAE: 0.00233,  MAPE: 1.11%\n",
      "[200 Epochs]    RMSE:0.00255,   MAE: 0.00221,  MAPE: 1.06%\n",
      "[300 Epochs]    RMSE:0.00224,   MAE: 0.00176,  MAPE: 0.81%\n",
      "[400 Epochs]    RMSE:0.00154,   MAE: 0.00125,  MAPE: 0.58%\n",
      "[500 Epochs]    RMSE:0.00258,   MAE: 0.00221,  MAPE: 1.04%\n",
      "[600 Epochs]    RMSE:0.00141,   MAE: 0.00118,  MAPE: 0.56%\n",
      "[700 Epochs]    RMSE:0.00290,   MAE: 0.00245,  MAPE: 1.17%\n",
      "[800 Epochs]    RMSE:0.00195,   MAE: 0.00159,  MAPE: 0.74%\n",
      "[900 Epochs]    RMSE:0.00244,   MAE: 0.00216,  MAPE: 1.03%\n",
      "[1000 Epochs]    RMSE:0.00080,   MAE: 0.00062,  MAPE: 0.30%\n",
      "[1100 Epochs]    RMSE:0.00131,   MAE: 0.00112,  MAPE: 0.53%\n",
      "[1200 Epochs]    RMSE:0.00114,   MAE: 0.00091,  MAPE: 0.43%\n",
      "[1300 Epochs]    RMSE:0.00130,   MAE: 0.00122,  MAPE: 0.58%\n",
      "[1400 Epochs]    RMSE:0.00367,   MAE: 0.00352,  MAPE: 1.69%\n",
      "[1500 Epochs]    RMSE:0.00079,   MAE: 0.00064,  MAPE: 0.30%\n",
      "[1600 Epochs]    RMSE:0.00145,   MAE: 0.00129,  MAPE: 0.60%\n",
      "[1700 Epochs]    RMSE:0.00170,   MAE: 0.00163,  MAPE: 0.78%\n",
      "[1800 Epochs]    RMSE:0.00131,   MAE: 0.00107,  MAPE: 0.51%\n",
      "[1900 Epochs]    RMSE:0.00140,   MAE: 0.00127,  MAPE: 0.61%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00125,   MAE: 0.00097,  MAPE: 0.45%\n",
      "\n",
      "\n",
      "Trial No.39\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.13084,   MAE: 0.12594,  MAPE: 60.03%\n",
      "[100 Epochs]    RMSE:0.00472,   MAE: 0.00432,  MAPE: 2.06%\n",
      "[200 Epochs]    RMSE:0.00471,   MAE: 0.00392,  MAPE: 1.90%\n",
      "[300 Epochs]    RMSE:0.00248,   MAE: 0.00197,  MAPE: 0.91%\n",
      "[400 Epochs]    RMSE:0.00322,   MAE: 0.00238,  MAPE: 1.19%\n",
      "[500 Epochs]    RMSE:0.00550,   MAE: 0.00522,  MAPE: 2.50%\n",
      "[600 Epochs]    RMSE:0.00202,   MAE: 0.00166,  MAPE: 0.77%\n",
      "[700 Epochs]    RMSE:0.00320,   MAE: 0.00266,  MAPE: 1.28%\n",
      "[800 Epochs]    RMSE:0.00324,   MAE: 0.00290,  MAPE: 1.36%\n",
      "[900 Epochs]    RMSE:0.00170,   MAE: 0.00140,  MAPE: 0.66%\n",
      "[1000 Epochs]    RMSE:0.00071,   MAE: 0.00058,  MAPE: 0.28%\n",
      "[1100 Epochs]    RMSE:0.00239,   MAE: 0.00203,  MAPE: 0.99%\n",
      "[1200 Epochs]    RMSE:0.00188,   MAE: 0.00162,  MAPE: 0.78%\n",
      "[1300 Epochs]    RMSE:0.00148,   MAE: 0.00122,  MAPE: 0.59%\n",
      "[1400 Epochs]    RMSE:0.00098,   MAE: 0.00075,  MAPE: 0.35%\n",
      "[1500 Epochs]    RMSE:0.00229,   MAE: 0.00189,  MAPE: 0.90%\n",
      "[1600 Epochs]    RMSE:0.00292,   MAE: 0.00271,  MAPE: 1.28%\n",
      "[1700 Epochs]    RMSE:0.00086,   MAE: 0.00075,  MAPE: 0.37%\n",
      "[1800 Epochs]    RMSE:0.00080,   MAE: 0.00064,  MAPE: 0.30%\n",
      "[1900 Epochs]    RMSE:0.00211,   MAE: 0.00191,  MAPE: 0.93%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00097,   MAE: 0.00082,  MAPE: 0.39%\n",
      "\n",
      "\n",
      "Trial No.40\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.14364,   MAE: 0.13408,  MAPE: 65.64%\n",
      "[100 Epochs]    RMSE:0.00302,   MAE: 0.00235,  MAPE: 1.12%\n",
      "[200 Epochs]    RMSE:0.00152,   MAE: 0.00110,  MAPE: 0.53%\n",
      "[300 Epochs]    RMSE:0.00183,   MAE: 0.00157,  MAPE: 0.76%\n",
      "[400 Epochs]    RMSE:0.00148,   MAE: 0.00121,  MAPE: 0.58%\n",
      "[500 Epochs]    RMSE:0.00261,   MAE: 0.00236,  MAPE: 1.13%\n",
      "[600 Epochs]    RMSE:0.00185,   MAE: 0.00148,  MAPE: 0.70%\n",
      "[700 Epochs]    RMSE:0.00276,   MAE: 0.00243,  MAPE: 1.14%\n",
      "[800 Epochs]    RMSE:0.00112,   MAE: 0.00094,  MAPE: 0.46%\n",
      "[900 Epochs]    RMSE:0.00167,   MAE: 0.00145,  MAPE: 0.68%\n",
      "[1000 Epochs]    RMSE:0.00284,   MAE: 0.00260,  MAPE: 1.22%\n",
      "[1100 Epochs]    RMSE:0.00299,   MAE: 0.00254,  MAPE: 1.20%\n",
      "[1200 Epochs]    RMSE:0.00151,   MAE: 0.00130,  MAPE: 0.61%\n",
      "[1300 Epochs]    RMSE:0.00106,   MAE: 0.00083,  MAPE: 0.40%\n",
      "[1400 Epochs]    RMSE:0.00278,   MAE: 0.00252,  MAPE: 1.18%\n",
      "[1500 Epochs]    RMSE:0.00158,   MAE: 0.00129,  MAPE: 0.62%\n",
      "[1600 Epochs]    RMSE:0.00105,   MAE: 0.00084,  MAPE: 0.41%\n",
      "[1700 Epochs]    RMSE:0.00237,   MAE: 0.00198,  MAPE: 0.91%\n",
      "[1800 Epochs]    RMSE:0.00235,   MAE: 0.00214,  MAPE: 1.01%\n",
      "[1900 Epochs]    RMSE:0.00206,   MAE: 0.00199,  MAPE: 0.95%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00063,   MAE: 0.00052,  MAPE: 0.26%\n",
      "\n",
      "\n",
      "Trial No.41\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.20178,   MAE: 0.20139,  MAPE: 96.74%\n",
      "[100 Epochs]    RMSE:0.01062,   MAE: 0.01015,  MAPE: 4.80%\n",
      "[200 Epochs]    RMSE:0.00080,   MAE: 0.00066,  MAPE: 0.32%\n",
      "[300 Epochs]    RMSE:0.00410,   MAE: 0.00383,  MAPE: 1.85%\n",
      "[400 Epochs]    RMSE:0.00548,   MAE: 0.00517,  MAPE: 2.45%\n",
      "[500 Epochs]    RMSE:0.00211,   MAE: 0.00196,  MAPE: 0.94%\n",
      "[600 Epochs]    RMSE:0.00133,   MAE: 0.00097,  MAPE: 0.46%\n",
      "[700 Epochs]    RMSE:0.00299,   MAE: 0.00284,  MAPE: 1.35%\n",
      "[800 Epochs]    RMSE:0.00071,   MAE: 0.00059,  MAPE: 0.29%\n",
      "[900 Epochs]    RMSE:0.00182,   MAE: 0.00168,  MAPE: 0.80%\n",
      "[1000 Epochs]    RMSE:0.00330,   MAE: 0.00297,  MAPE: 1.40%\n",
      "[1100 Epochs]    RMSE:0.00456,   MAE: 0.00442,  MAPE: 2.09%\n",
      "[1200 Epochs]    RMSE:0.00259,   MAE: 0.00222,  MAPE: 1.04%\n",
      "[1300 Epochs]    RMSE:0.00105,   MAE: 0.00087,  MAPE: 0.40%\n",
      "[1400 Epochs]    RMSE:0.00180,   MAE: 0.00160,  MAPE: 0.75%\n",
      "[1500 Epochs]    RMSE:0.00162,   MAE: 0.00144,  MAPE: 0.68%\n",
      "[1600 Epochs]    RMSE:0.00043,   MAE: 0.00033,  MAPE: 0.16%\n",
      "[1700 Epochs]    RMSE:0.00053,   MAE: 0.00039,  MAPE: 0.19%\n",
      "[1800 Epochs]    RMSE:0.00065,   MAE: 0.00051,  MAPE: 0.25%\n",
      "[1900 Epochs]    RMSE:0.00038,   MAE: 0.00031,  MAPE: 0.15%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00075,   MAE: 0.00047,  MAPE: 0.23%\n",
      "\n",
      "\n",
      "Trial No.42\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.23161,   MAE: 0.22913,  MAPE: 109.53%\n",
      "[100 Epochs]    RMSE:0.00250,   MAE: 0.00208,  MAPE: 1.00%\n",
      "[200 Epochs]    RMSE:0.00422,   MAE: 0.00370,  MAPE: 1.73%\n",
      "[300 Epochs]    RMSE:0.00251,   MAE: 0.00184,  MAPE: 0.86%\n",
      "[400 Epochs]    RMSE:0.00183,   MAE: 0.00155,  MAPE: 0.73%\n",
      "[500 Epochs]    RMSE:0.00137,   MAE: 0.00117,  MAPE: 0.56%\n",
      "[600 Epochs]    RMSE:0.00261,   MAE: 0.00211,  MAPE: 1.00%\n",
      "[700 Epochs]    RMSE:0.00225,   MAE: 0.00158,  MAPE: 0.74%\n",
      "[800 Epochs]    RMSE:0.00289,   MAE: 0.00274,  MAPE: 1.32%\n",
      "[900 Epochs]    RMSE:0.00059,   MAE: 0.00047,  MAPE: 0.22%\n",
      "[1000 Epochs]    RMSE:0.00122,   MAE: 0.00095,  MAPE: 0.44%\n",
      "[1100 Epochs]    RMSE:0.00228,   MAE: 0.00183,  MAPE: 0.89%\n",
      "[1200 Epochs]    RMSE:0.00150,   MAE: 0.00127,  MAPE: 0.63%\n",
      "[1300 Epochs]    RMSE:0.00114,   MAE: 0.00098,  MAPE: 0.46%\n",
      "[1400 Epochs]    RMSE:0.00118,   MAE: 0.00083,  MAPE: 0.40%\n",
      "[1500 Epochs]    RMSE:0.00141,   MAE: 0.00127,  MAPE: 0.61%\n",
      "[1600 Epochs]    RMSE:0.00082,   MAE: 0.00067,  MAPE: 0.32%\n",
      "[1700 Epochs]    RMSE:0.00183,   MAE: 0.00139,  MAPE: 0.67%\n",
      "[1800 Epochs]    RMSE:0.00088,   MAE: 0.00074,  MAPE: 0.35%\n",
      "[1900 Epochs]    RMSE:0.00121,   MAE: 0.00096,  MAPE: 0.47%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00398,   MAE: 0.00392,  MAPE: 1.88%\n",
      "\n",
      "\n",
      "Trial No.43\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.24273,   MAE: 0.24157,  MAPE: 115.65%\n",
      "[100 Epochs]    RMSE:0.00330,   MAE: 0.00257,  MAPE: 1.26%\n",
      "[200 Epochs]    RMSE:0.00262,   MAE: 0.00231,  MAPE: 1.09%\n",
      "[300 Epochs]    RMSE:0.00398,   MAE: 0.00371,  MAPE: 1.75%\n",
      "[400 Epochs]    RMSE:0.00376,   MAE: 0.00325,  MAPE: 1.55%\n",
      "[500 Epochs]    RMSE:0.00095,   MAE: 0.00074,  MAPE: 0.35%\n",
      "[600 Epochs]    RMSE:0.00173,   MAE: 0.00144,  MAPE: 0.69%\n",
      "[700 Epochs]    RMSE:0.00176,   MAE: 0.00165,  MAPE: 0.79%\n",
      "[800 Epochs]    RMSE:0.00173,   MAE: 0.00147,  MAPE: 0.71%\n",
      "[900 Epochs]    RMSE:0.00099,   MAE: 0.00087,  MAPE: 0.41%\n",
      "[1000 Epochs]    RMSE:0.00085,   MAE: 0.00059,  MAPE: 0.29%\n",
      "[1100 Epochs]    RMSE:0.00088,   MAE: 0.00077,  MAPE: 0.37%\n",
      "[1200 Epochs]    RMSE:0.00109,   MAE: 0.00084,  MAPE: 0.40%\n",
      "[1300 Epochs]    RMSE:0.00120,   MAE: 0.00092,  MAPE: 0.44%\n",
      "[1400 Epochs]    RMSE:0.00075,   MAE: 0.00065,  MAPE: 0.31%\n",
      "[1500 Epochs]    RMSE:0.00094,   MAE: 0.00077,  MAPE: 0.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1600 Epochs]    RMSE:0.00130,   MAE: 0.00106,  MAPE: 0.51%\n",
      "[1700 Epochs]    RMSE:0.00339,   MAE: 0.00324,  MAPE: 1.53%\n",
      "[1800 Epochs]    RMSE:0.00102,   MAE: 0.00090,  MAPE: 0.43%\n",
      "[1900 Epochs]    RMSE:0.00075,   MAE: 0.00058,  MAPE: 0.28%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00094,   MAE: 0.00071,  MAPE: 0.33%\n",
      "\n",
      "\n",
      "Trial No.44\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.26592,   MAE: 0.26326,  MAPE: 125.29%\n",
      "[100 Epochs]    RMSE:0.00268,   MAE: 0.00215,  MAPE: 1.02%\n",
      "[200 Epochs]    RMSE:0.00276,   MAE: 0.00246,  MAPE: 1.19%\n",
      "[300 Epochs]    RMSE:0.00252,   MAE: 0.00231,  MAPE: 1.11%\n",
      "[400 Epochs]    RMSE:0.00075,   MAE: 0.00063,  MAPE: 0.30%\n",
      "[500 Epochs]    RMSE:0.00270,   MAE: 0.00228,  MAPE: 1.09%\n",
      "[600 Epochs]    RMSE:0.00163,   MAE: 0.00147,  MAPE: 0.71%\n",
      "[700 Epochs]    RMSE:0.00157,   MAE: 0.00122,  MAPE: 0.59%\n",
      "[800 Epochs]    RMSE:0.00145,   MAE: 0.00115,  MAPE: 0.54%\n",
      "[900 Epochs]    RMSE:0.00149,   MAE: 0.00103,  MAPE: 0.50%\n",
      "[1000 Epochs]    RMSE:0.00273,   MAE: 0.00238,  MAPE: 1.14%\n",
      "[1100 Epochs]    RMSE:0.00199,   MAE: 0.00160,  MAPE: 0.78%\n",
      "[1200 Epochs]    RMSE:0.00329,   MAE: 0.00309,  MAPE: 1.47%\n",
      "[1300 Epochs]    RMSE:0.00175,   MAE: 0.00146,  MAPE: 0.70%\n",
      "[1400 Epochs]    RMSE:0.00197,   MAE: 0.00175,  MAPE: 0.83%\n",
      "[1500 Epochs]    RMSE:0.00175,   MAE: 0.00152,  MAPE: 0.74%\n",
      "[1600 Epochs]    RMSE:0.00290,   MAE: 0.00237,  MAPE: 1.16%\n",
      "[1700 Epochs]    RMSE:0.00070,   MAE: 0.00055,  MAPE: 0.26%\n",
      "[1800 Epochs]    RMSE:0.00049,   MAE: 0.00041,  MAPE: 0.19%\n",
      "[1900 Epochs]    RMSE:0.00065,   MAE: 0.00057,  MAPE: 0.27%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00109,   MAE: 0.00102,  MAPE: 0.49%\n",
      "\n",
      "\n",
      "Trial No.45\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.26784,   MAE: 0.26367,  MAPE: 125.06%\n",
      "[100 Epochs]    RMSE:0.00265,   MAE: 0.00205,  MAPE: 0.97%\n",
      "[200 Epochs]    RMSE:0.00279,   MAE: 0.00222,  MAPE: 1.03%\n",
      "[300 Epochs]    RMSE:0.00196,   MAE: 0.00177,  MAPE: 0.84%\n",
      "[400 Epochs]    RMSE:0.00150,   MAE: 0.00125,  MAPE: 0.60%\n",
      "[500 Epochs]    RMSE:0.00107,   MAE: 0.00082,  MAPE: 0.40%\n",
      "[600 Epochs]    RMSE:0.00548,   MAE: 0.00497,  MAPE: 2.35%\n",
      "[700 Epochs]    RMSE:0.00195,   MAE: 0.00151,  MAPE: 0.69%\n",
      "[800 Epochs]    RMSE:0.00178,   MAE: 0.00150,  MAPE: 0.71%\n",
      "[900 Epochs]    RMSE:0.00412,   MAE: 0.00384,  MAPE: 1.81%\n",
      "[1000 Epochs]    RMSE:0.00177,   MAE: 0.00161,  MAPE: 0.77%\n",
      "[1100 Epochs]    RMSE:0.00064,   MAE: 0.00052,  MAPE: 0.25%\n",
      "[1200 Epochs]    RMSE:0.00137,   MAE: 0.00126,  MAPE: 0.60%\n",
      "[1300 Epochs]    RMSE:0.00084,   MAE: 0.00066,  MAPE: 0.31%\n",
      "[1400 Epochs]    RMSE:0.00077,   MAE: 0.00058,  MAPE: 0.29%\n",
      "[1500 Epochs]    RMSE:0.00166,   MAE: 0.00140,  MAPE: 0.66%\n",
      "[1600 Epochs]    RMSE:0.00107,   MAE: 0.00087,  MAPE: 0.42%\n",
      "[1700 Epochs]    RMSE:0.00133,   MAE: 0.00106,  MAPE: 0.50%\n",
      "[1800 Epochs]    RMSE:0.00073,   MAE: 0.00055,  MAPE: 0.27%\n",
      "[1900 Epochs]    RMSE:0.00108,   MAE: 0.00093,  MAPE: 0.44%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00388,   MAE: 0.00379,  MAPE: 1.82%\n",
      "\n",
      "\n",
      "Trial No.46\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.29080,   MAE: 0.28809,  MAPE: 137.16%\n",
      "[100 Epochs]    RMSE:0.00463,   MAE: 0.00363,  MAPE: 1.69%\n",
      "[200 Epochs]    RMSE:0.00300,   MAE: 0.00204,  MAPE: 1.02%\n",
      "[300 Epochs]    RMSE:0.00388,   MAE: 0.00307,  MAPE: 1.49%\n",
      "[400 Epochs]    RMSE:0.00206,   MAE: 0.00175,  MAPE: 0.84%\n",
      "[500 Epochs]    RMSE:0.00209,   MAE: 0.00181,  MAPE: 0.86%\n",
      "[600 Epochs]    RMSE:0.00387,   MAE: 0.00364,  MAPE: 1.74%\n",
      "[700 Epochs]    RMSE:0.00152,   MAE: 0.00126,  MAPE: 0.59%\n",
      "[800 Epochs]    RMSE:0.00517,   MAE: 0.00483,  MAPE: 2.27%\n",
      "[900 Epochs]    RMSE:0.00294,   MAE: 0.00244,  MAPE: 1.14%\n",
      "[1000 Epochs]    RMSE:0.00096,   MAE: 0.00079,  MAPE: 0.38%\n",
      "[1100 Epochs]    RMSE:0.00088,   MAE: 0.00076,  MAPE: 0.36%\n",
      "[1200 Epochs]    RMSE:0.00125,   MAE: 0.00113,  MAPE: 0.54%\n",
      "[1300 Epochs]    RMSE:0.00278,   MAE: 0.00232,  MAPE: 1.09%\n",
      "[1400 Epochs]    RMSE:0.00141,   MAE: 0.00111,  MAPE: 0.54%\n",
      "[1500 Epochs]    RMSE:0.00131,   MAE: 0.00117,  MAPE: 0.56%\n",
      "[1600 Epochs]    RMSE:0.00251,   MAE: 0.00224,  MAPE: 1.07%\n",
      "[1700 Epochs]    RMSE:0.00109,   MAE: 0.00087,  MAPE: 0.42%\n",
      "[1800 Epochs]    RMSE:0.00283,   MAE: 0.00261,  MAPE: 1.25%\n",
      "[1900 Epochs]    RMSE:0.00102,   MAE: 0.00084,  MAPE: 0.40%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00062,   MAE: 0.00047,  MAPE: 0.23%\n",
      "\n",
      "\n",
      "Trial No.47\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.18737,   MAE: 0.18636,  MAPE: 88.84%\n",
      "[100 Epochs]    RMSE:0.00316,   MAE: 0.00229,  MAPE: 1.09%\n",
      "[200 Epochs]    RMSE:0.01553,   MAE: 0.01460,  MAPE: 6.96%\n",
      "[300 Epochs]    RMSE:0.00246,   MAE: 0.00209,  MAPE: 1.00%\n",
      "[400 Epochs]    RMSE:0.00143,   MAE: 0.00124,  MAPE: 0.58%\n",
      "[500 Epochs]    RMSE:0.00274,   MAE: 0.00248,  MAPE: 1.19%\n",
      "[600 Epochs]    RMSE:0.00286,   MAE: 0.00267,  MAPE: 1.27%\n",
      "[700 Epochs]    RMSE:0.00350,   MAE: 0.00292,  MAPE: 1.42%\n",
      "[800 Epochs]    RMSE:0.00566,   MAE: 0.00543,  MAPE: 2.59%\n",
      "[900 Epochs]    RMSE:0.00080,   MAE: 0.00063,  MAPE: 0.31%\n",
      "[1000 Epochs]    RMSE:0.00321,   MAE: 0.00303,  MAPE: 1.45%\n",
      "[1100 Epochs]    RMSE:0.00118,   MAE: 0.00091,  MAPE: 0.44%\n",
      "[1200 Epochs]    RMSE:0.00111,   MAE: 0.00088,  MAPE: 0.44%\n",
      "[1300 Epochs]    RMSE:0.00052,   MAE: 0.00040,  MAPE: 0.20%\n",
      "[1400 Epochs]    RMSE:0.00231,   MAE: 0.00192,  MAPE: 0.91%\n",
      "[1500 Epochs]    RMSE:0.00302,   MAE: 0.00293,  MAPE: 1.40%\n",
      "[1600 Epochs]    RMSE:0.00096,   MAE: 0.00067,  MAPE: 0.33%\n",
      "[1700 Epochs]    RMSE:0.00120,   MAE: 0.00106,  MAPE: 0.50%\n",
      "[1800 Epochs]    RMSE:0.00146,   MAE: 0.00135,  MAPE: 0.64%\n",
      "[1900 Epochs]    RMSE:0.00076,   MAE: 0.00060,  MAPE: 0.28%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00249,   MAE: 0.00233,  MAPE: 1.11%\n",
      "\n",
      "\n",
      "Trial No.48\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.19775,   MAE: 0.19581,  MAPE: 93.97%\n",
      "[100 Epochs]    RMSE:0.00443,   MAE: 0.00418,  MAPE: 2.03%\n",
      "[200 Epochs]    RMSE:0.00278,   MAE: 0.00234,  MAPE: 1.11%\n",
      "[300 Epochs]    RMSE:0.00501,   MAE: 0.00441,  MAPE: 2.09%\n",
      "[400 Epochs]    RMSE:0.00519,   MAE: 0.00444,  MAPE: 2.08%\n",
      "[500 Epochs]    RMSE:0.00179,   MAE: 0.00149,  MAPE: 0.71%\n",
      "[600 Epochs]    RMSE:0.00077,   MAE: 0.00064,  MAPE: 0.31%\n",
      "[700 Epochs]    RMSE:0.00125,   MAE: 0.00101,  MAPE: 0.48%\n",
      "[800 Epochs]    RMSE:0.00128,   MAE: 0.00097,  MAPE: 0.47%\n",
      "[900 Epochs]    RMSE:0.00301,   MAE: 0.00251,  MAPE: 1.17%\n",
      "[1000 Epochs]    RMSE:0.00236,   MAE: 0.00214,  MAPE: 1.01%\n",
      "[1100 Epochs]    RMSE:0.00201,   MAE: 0.00170,  MAPE: 0.80%\n",
      "[1200 Epochs]    RMSE:0.00182,   MAE: 0.00161,  MAPE: 0.77%\n",
      "[1300 Epochs]    RMSE:0.00146,   MAE: 0.00125,  MAPE: 0.59%\n",
      "[1400 Epochs]    RMSE:0.00143,   MAE: 0.00128,  MAPE: 0.62%\n",
      "[1500 Epochs]    RMSE:0.00236,   MAE: 0.00195,  MAPE: 0.90%\n",
      "[1600 Epochs]    RMSE:0.00241,   MAE: 0.00203,  MAPE: 0.94%\n",
      "[1700 Epochs]    RMSE:0.00105,   MAE: 0.00083,  MAPE: 0.39%\n",
      "[1800 Epochs]    RMSE:0.00106,   MAE: 0.00087,  MAPE: 0.41%\n",
      "[1900 Epochs]    RMSE:0.00053,   MAE: 0.00041,  MAPE: 0.20%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00112,   MAE: 0.00089,  MAPE: 0.42%\n",
      "\n",
      "\n",
      "Trial No.49\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.24391,   MAE: 0.23987,  MAPE: 113.70%\n",
      "[100 Epochs]    RMSE:0.00410,   MAE: 0.00332,  MAPE: 1.61%\n",
      "[200 Epochs]    RMSE:0.00172,   MAE: 0.00138,  MAPE: 0.68%\n",
      "[300 Epochs]    RMSE:0.00427,   MAE: 0.00382,  MAPE: 1.85%\n",
      "[400 Epochs]    RMSE:0.00112,   MAE: 0.00088,  MAPE: 0.42%\n",
      "[500 Epochs]    RMSE:0.00108,   MAE: 0.00089,  MAPE: 0.43%\n",
      "[600 Epochs]    RMSE:0.00097,   MAE: 0.00073,  MAPE: 0.35%\n",
      "[700 Epochs]    RMSE:0.00336,   MAE: 0.00294,  MAPE: 1.42%\n",
      "[800 Epochs]    RMSE:0.00205,   MAE: 0.00152,  MAPE: 0.71%\n",
      "[900 Epochs]    RMSE:0.00342,   MAE: 0.00255,  MAPE: 1.17%\n",
      "[1000 Epochs]    RMSE:0.00194,   MAE: 0.00157,  MAPE: 0.77%\n",
      "[1100 Epochs]    RMSE:0.00394,   MAE: 0.00366,  MAPE: 1.73%\n",
      "[1200 Epochs]    RMSE:0.00058,   MAE: 0.00051,  MAPE: 0.24%\n",
      "[1300 Epochs]    RMSE:0.00144,   MAE: 0.00133,  MAPE: 0.64%\n",
      "[1400 Epochs]    RMSE:0.00112,   MAE: 0.00095,  MAPE: 0.46%\n",
      "[1500 Epochs]    RMSE:0.00319,   MAE: 0.00299,  MAPE: 1.43%\n",
      "[1600 Epochs]    RMSE:0.00059,   MAE: 0.00046,  MAPE: 0.22%\n",
      "[1700 Epochs]    RMSE:0.00086,   MAE: 0.00068,  MAPE: 0.32%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1800 Epochs]    RMSE:0.00169,   MAE: 0.00167,  MAPE: 0.80%\n",
      "[1900 Epochs]    RMSE:0.00085,   MAE: 0.00063,  MAPE: 0.30%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00068,   MAE: 0.00059,  MAPE: 0.28%\n",
      "\n",
      "\n",
      "Trial No.50\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.18738,   MAE: 0.18026,  MAPE: 87.29%\n",
      "[100 Epochs]    RMSE:0.00473,   MAE: 0.00333,  MAPE: 1.56%\n",
      "[200 Epochs]    RMSE:0.00285,   MAE: 0.00259,  MAPE: 1.25%\n",
      "[300 Epochs]    RMSE:0.00386,   MAE: 0.00330,  MAPE: 1.55%\n",
      "[400 Epochs]    RMSE:0.00224,   MAE: 0.00196,  MAPE: 0.92%\n",
      "[500 Epochs]    RMSE:0.00180,   MAE: 0.00154,  MAPE: 0.73%\n",
      "[600 Epochs]    RMSE:0.00199,   MAE: 0.00162,  MAPE: 0.76%\n",
      "[700 Epochs]    RMSE:0.00152,   MAE: 0.00131,  MAPE: 0.62%\n",
      "[800 Epochs]    RMSE:0.00233,   MAE: 0.00206,  MAPE: 0.98%\n",
      "[900 Epochs]    RMSE:0.00281,   MAE: 0.00265,  MAPE: 1.29%\n",
      "[1000 Epochs]    RMSE:0.00066,   MAE: 0.00052,  MAPE: 0.25%\n",
      "[1100 Epochs]    RMSE:0.00195,   MAE: 0.00180,  MAPE: 0.87%\n",
      "[1200 Epochs]    RMSE:0.00192,   MAE: 0.00177,  MAPE: 0.84%\n",
      "[1300 Epochs]    RMSE:0.00075,   MAE: 0.00060,  MAPE: 0.29%\n",
      "[1400 Epochs]    RMSE:0.00094,   MAE: 0.00069,  MAPE: 0.34%\n",
      "[1500 Epochs]    RMSE:0.00068,   MAE: 0.00052,  MAPE: 0.24%\n",
      "[1600 Epochs]    RMSE:0.00334,   MAE: 0.00282,  MAPE: 1.36%\n",
      "[1700 Epochs]    RMSE:0.00207,   MAE: 0.00182,  MAPE: 0.88%\n",
      "[1800 Epochs]    RMSE:0.00087,   MAE: 0.00069,  MAPE: 0.32%\n",
      "[1900 Epochs]    RMSE:0.00064,   MAE: 0.00053,  MAPE: 0.25%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00048,   MAE: 0.00040,  MAPE: 0.19%\n",
      "\n",
      "\n",
      "Trial No.51\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.25576,   MAE: 0.25109,  MAPE: 119.19%\n",
      "[100 Epochs]    RMSE:0.00490,   MAE: 0.00381,  MAPE: 1.84%\n",
      "[200 Epochs]    RMSE:0.00110,   MAE: 0.00087,  MAPE: 0.41%\n",
      "[300 Epochs]    RMSE:0.00316,   MAE: 0.00304,  MAPE: 1.46%\n",
      "[400 Epochs]    RMSE:0.00113,   MAE: 0.00097,  MAPE: 0.47%\n",
      "[500 Epochs]    RMSE:0.00139,   MAE: 0.00105,  MAPE: 0.48%\n",
      "[600 Epochs]    RMSE:0.00387,   MAE: 0.00367,  MAPE: 1.77%\n",
      "[700 Epochs]    RMSE:0.00090,   MAE: 0.00073,  MAPE: 0.34%\n",
      "[800 Epochs]    RMSE:0.00142,   MAE: 0.00119,  MAPE: 0.56%\n",
      "[900 Epochs]    RMSE:0.00143,   MAE: 0.00132,  MAPE: 0.63%\n",
      "[1000 Epochs]    RMSE:0.00197,   MAE: 0.00185,  MAPE: 0.88%\n",
      "[1100 Epochs]    RMSE:0.00147,   MAE: 0.00123,  MAPE: 0.59%\n",
      "[1200 Epochs]    RMSE:0.00174,   MAE: 0.00148,  MAPE: 0.69%\n",
      "[1300 Epochs]    RMSE:0.00154,   MAE: 0.00140,  MAPE: 0.67%\n",
      "[1400 Epochs]    RMSE:0.00076,   MAE: 0.00059,  MAPE: 0.28%\n",
      "[1500 Epochs]    RMSE:0.00196,   MAE: 0.00181,  MAPE: 0.85%\n",
      "[1600 Epochs]    RMSE:0.00194,   MAE: 0.00182,  MAPE: 0.87%\n",
      "[1700 Epochs]    RMSE:0.00099,   MAE: 0.00087,  MAPE: 0.42%\n",
      "[1800 Epochs]    RMSE:0.00155,   MAE: 0.00131,  MAPE: 0.62%\n",
      "[1900 Epochs]    RMSE:0.00077,   MAE: 0.00064,  MAPE: 0.31%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00128,   MAE: 0.00113,  MAPE: 0.53%\n",
      "\n",
      "\n",
      "Trial No.52\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.11839,   MAE: 0.10334,  MAPE: 48.64%\n",
      "[100 Epochs]    RMSE:0.00402,   MAE: 0.00333,  MAPE: 1.61%\n",
      "[200 Epochs]    RMSE:0.00591,   MAE: 0.00521,  MAPE: 2.51%\n",
      "[300 Epochs]    RMSE:0.00612,   MAE: 0.00542,  MAPE: 2.60%\n",
      "[400 Epochs]    RMSE:0.00323,   MAE: 0.00258,  MAPE: 1.20%\n",
      "[500 Epochs]    RMSE:0.00187,   MAE: 0.00142,  MAPE: 0.70%\n",
      "[600 Epochs]    RMSE:0.00253,   MAE: 0.00205,  MAPE: 0.99%\n",
      "[700 Epochs]    RMSE:0.00385,   MAE: 0.00345,  MAPE: 1.65%\n",
      "[800 Epochs]    RMSE:0.00455,   MAE: 0.00423,  MAPE: 2.01%\n",
      "[900 Epochs]    RMSE:0.00260,   MAE: 0.00193,  MAPE: 0.91%\n",
      "[1000 Epochs]    RMSE:0.00143,   MAE: 0.00117,  MAPE: 0.55%\n",
      "[1100 Epochs]    RMSE:0.00112,   MAE: 0.00094,  MAPE: 0.45%\n",
      "[1200 Epochs]    RMSE:0.00287,   MAE: 0.00268,  MAPE: 1.28%\n",
      "[1300 Epochs]    RMSE:0.00130,   MAE: 0.00105,  MAPE: 0.50%\n",
      "[1400 Epochs]    RMSE:0.00164,   MAE: 0.00150,  MAPE: 0.72%\n",
      "[1500 Epochs]    RMSE:0.00193,   MAE: 0.00150,  MAPE: 0.74%\n",
      "[1600 Epochs]    RMSE:0.00127,   MAE: 0.00110,  MAPE: 0.53%\n",
      "[1700 Epochs]    RMSE:0.00128,   MAE: 0.00103,  MAPE: 0.50%\n",
      "[1800 Epochs]    RMSE:0.00125,   MAE: 0.00103,  MAPE: 0.48%\n",
      "[1900 Epochs]    RMSE:0.00169,   MAE: 0.00135,  MAPE: 0.64%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00157,   MAE: 0.00133,  MAPE: 0.62%\n",
      "\n",
      "\n",
      "Trial No.53\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.28489,   MAE: 0.28114,  MAPE: 133.54%\n",
      "[100 Epochs]    RMSE:0.00202,   MAE: 0.00169,  MAPE: 0.82%\n",
      "[200 Epochs]    RMSE:0.00206,   MAE: 0.00166,  MAPE: 0.80%\n",
      "[300 Epochs]    RMSE:0.00340,   MAE: 0.00277,  MAPE: 1.35%\n",
      "[400 Epochs]    RMSE:0.00229,   MAE: 0.00185,  MAPE: 0.87%\n",
      "[500 Epochs]    RMSE:0.00150,   MAE: 0.00126,  MAPE: 0.60%\n",
      "[600 Epochs]    RMSE:0.00216,   MAE: 0.00165,  MAPE: 0.81%\n",
      "[700 Epochs]    RMSE:0.00310,   MAE: 0.00273,  MAPE: 1.29%\n",
      "[800 Epochs]    RMSE:0.00170,   MAE: 0.00152,  MAPE: 0.74%\n",
      "[900 Epochs]    RMSE:0.00141,   MAE: 0.00116,  MAPE: 0.55%\n",
      "[1000 Epochs]    RMSE:0.00102,   MAE: 0.00086,  MAPE: 0.41%\n",
      "[1100 Epochs]    RMSE:0.00090,   MAE: 0.00070,  MAPE: 0.35%\n",
      "[1200 Epochs]    RMSE:0.00090,   MAE: 0.00063,  MAPE: 0.30%\n",
      "[1300 Epochs]    RMSE:0.00259,   MAE: 0.00233,  MAPE: 1.12%\n",
      "[1400 Epochs]    RMSE:0.00151,   MAE: 0.00125,  MAPE: 0.59%\n",
      "[1500 Epochs]    RMSE:0.00102,   MAE: 0.00084,  MAPE: 0.40%\n",
      "[1600 Epochs]    RMSE:0.00281,   MAE: 0.00254,  MAPE: 1.20%\n",
      "[1700 Epochs]    RMSE:0.00106,   MAE: 0.00080,  MAPE: 0.38%\n",
      "[1800 Epochs]    RMSE:0.00101,   MAE: 0.00078,  MAPE: 0.37%\n",
      "[1900 Epochs]    RMSE:0.00102,   MAE: 0.00085,  MAPE: 0.39%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00054,   MAE: 0.00046,  MAPE: 0.22%\n",
      "\n",
      "\n",
      "Trial No.54\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.18609,   MAE: 0.18102,  MAPE: 86.03%\n",
      "[100 Epochs]    RMSE:0.00277,   MAE: 0.00235,  MAPE: 1.12%\n",
      "[200 Epochs]    RMSE:0.00650,   MAE: 0.00490,  MAPE: 2.25%\n",
      "[300 Epochs]    RMSE:0.00262,   MAE: 0.00209,  MAPE: 0.98%\n",
      "[400 Epochs]    RMSE:0.00455,   MAE: 0.00390,  MAPE: 1.88%\n",
      "[500 Epochs]    RMSE:0.00386,   MAE: 0.00361,  MAPE: 1.75%\n",
      "[600 Epochs]    RMSE:0.00396,   MAE: 0.00332,  MAPE: 1.62%\n",
      "[700 Epochs]    RMSE:0.00311,   MAE: 0.00263,  MAPE: 1.27%\n",
      "[800 Epochs]    RMSE:0.00575,   MAE: 0.00529,  MAPE: 2.56%\n",
      "[900 Epochs]    RMSE:0.00187,   MAE: 0.00168,  MAPE: 0.79%\n",
      "[1000 Epochs]    RMSE:0.00234,   MAE: 0.00203,  MAPE: 0.95%\n",
      "[1100 Epochs]    RMSE:0.00165,   MAE: 0.00151,  MAPE: 0.72%\n",
      "[1200 Epochs]    RMSE:0.00261,   MAE: 0.00253,  MAPE: 1.21%\n",
      "[1300 Epochs]    RMSE:0.00079,   MAE: 0.00067,  MAPE: 0.32%\n",
      "[1400 Epochs]    RMSE:0.00249,   MAE: 0.00240,  MAPE: 1.15%\n",
      "[1500 Epochs]    RMSE:0.00132,   MAE: 0.00099,  MAPE: 0.47%\n",
      "[1600 Epochs]    RMSE:0.00061,   MAE: 0.00053,  MAPE: 0.25%\n",
      "[1700 Epochs]    RMSE:0.00193,   MAE: 0.00163,  MAPE: 0.77%\n",
      "[1800 Epochs]    RMSE:0.00244,   MAE: 0.00230,  MAPE: 1.11%\n",
      "[1900 Epochs]    RMSE:0.00376,   MAE: 0.00363,  MAPE: 1.73%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00232,   MAE: 0.00209,  MAPE: 1.02%\n",
      "\n",
      "\n",
      "Trial No.55\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.29035,   MAE: 0.28694,  MAPE: 137.83%\n",
      "[100 Epochs]    RMSE:0.00273,   MAE: 0.00213,  MAPE: 1.04%\n",
      "[200 Epochs]    RMSE:0.00151,   MAE: 0.00126,  MAPE: 0.60%\n",
      "[300 Epochs]    RMSE:0.00370,   MAE: 0.00324,  MAPE: 1.57%\n",
      "[400 Epochs]    RMSE:0.00124,   MAE: 0.00103,  MAPE: 0.50%\n",
      "[500 Epochs]    RMSE:0.00124,   MAE: 0.00095,  MAPE: 0.46%\n",
      "[600 Epochs]    RMSE:0.00130,   MAE: 0.00111,  MAPE: 0.52%\n",
      "[700 Epochs]    RMSE:0.00066,   MAE: 0.00054,  MAPE: 0.27%\n",
      "[800 Epochs]    RMSE:0.00129,   MAE: 0.00098,  MAPE: 0.45%\n",
      "[900 Epochs]    RMSE:0.00160,   MAE: 0.00131,  MAPE: 0.62%\n",
      "[1000 Epochs]    RMSE:0.00160,   MAE: 0.00139,  MAPE: 0.66%\n",
      "[1100 Epochs]    RMSE:0.00138,   MAE: 0.00128,  MAPE: 0.62%\n",
      "[1200 Epochs]    RMSE:0.00156,   MAE: 0.00140,  MAPE: 0.67%\n",
      "[1300 Epochs]    RMSE:0.00060,   MAE: 0.00050,  MAPE: 0.24%\n",
      "[1400 Epochs]    RMSE:0.00237,   MAE: 0.00179,  MAPE: 0.86%\n",
      "[1500 Epochs]    RMSE:0.00102,   MAE: 0.00096,  MAPE: 0.46%\n",
      "[1600 Epochs]    RMSE:0.00082,   MAE: 0.00066,  MAPE: 0.32%\n",
      "[1700 Epochs]    RMSE:0.00075,   MAE: 0.00057,  MAPE: 0.28%\n",
      "[1800 Epochs]    RMSE:0.00179,   MAE: 0.00158,  MAPE: 0.74%\n",
      "[1900 Epochs]    RMSE:0.00250,   MAE: 0.00243,  MAPE: 1.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Final Epochs]    RMSE:0.00190,   MAE: 0.00177,  MAPE: 0.85%\n",
      "\n",
      "\n",
      "Trial No.56\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.28838,   MAE: 0.28075,  MAPE: 132.71%\n",
      "[100 Epochs]    RMSE:0.00480,   MAE: 0.00426,  MAPE: 2.03%\n",
      "[200 Epochs]    RMSE:0.00229,   MAE: 0.00172,  MAPE: 0.84%\n",
      "[300 Epochs]    RMSE:0.00150,   MAE: 0.00124,  MAPE: 0.60%\n",
      "[400 Epochs]    RMSE:0.00228,   MAE: 0.00194,  MAPE: 0.93%\n",
      "[500 Epochs]    RMSE:0.00287,   MAE: 0.00264,  MAPE: 1.25%\n",
      "[600 Epochs]    RMSE:0.00223,   MAE: 0.00205,  MAPE: 0.99%\n",
      "[700 Epochs]    RMSE:0.00300,   MAE: 0.00281,  MAPE: 1.34%\n",
      "[800 Epochs]    RMSE:0.00175,   MAE: 0.00155,  MAPE: 0.73%\n",
      "[900 Epochs]    RMSE:0.00284,   MAE: 0.00269,  MAPE: 1.30%\n",
      "[1000 Epochs]    RMSE:0.00118,   MAE: 0.00097,  MAPE: 0.47%\n",
      "[1100 Epochs]    RMSE:0.00337,   MAE: 0.00326,  MAPE: 1.56%\n",
      "[1200 Epochs]    RMSE:0.00101,   MAE: 0.00082,  MAPE: 0.40%\n",
      "[1300 Epochs]    RMSE:0.00190,   MAE: 0.00168,  MAPE: 0.80%\n",
      "[1400 Epochs]    RMSE:0.00115,   MAE: 0.00093,  MAPE: 0.43%\n",
      "[1500 Epochs]    RMSE:0.00203,   MAE: 0.00171,  MAPE: 0.81%\n",
      "[1600 Epochs]    RMSE:0.00060,   MAE: 0.00051,  MAPE: 0.25%\n",
      "[1700 Epochs]    RMSE:0.00187,   MAE: 0.00153,  MAPE: 0.72%\n",
      "[1800 Epochs]    RMSE:0.00138,   MAE: 0.00113,  MAPE: 0.53%\n",
      "[1900 Epochs]    RMSE:0.00119,   MAE: 0.00100,  MAPE: 0.47%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00096,   MAE: 0.00083,  MAPE: 0.39%\n",
      "\n",
      "\n",
      "Trial No.57\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.08186,   MAE: 0.06788,  MAPE: 32.90%\n",
      "[100 Epochs]    RMSE:0.00180,   MAE: 0.00153,  MAPE: 0.74%\n",
      "[200 Epochs]    RMSE:0.00123,   MAE: 0.00114,  MAPE: 0.54%\n",
      "[300 Epochs]    RMSE:0.00337,   MAE: 0.00324,  MAPE: 1.54%\n",
      "[400 Epochs]    RMSE:0.00282,   MAE: 0.00267,  MAPE: 1.26%\n",
      "[500 Epochs]    RMSE:0.00232,   MAE: 0.00222,  MAPE: 1.05%\n",
      "[600 Epochs]    RMSE:0.00089,   MAE: 0.00071,  MAPE: 0.34%\n",
      "[700 Epochs]    RMSE:0.00122,   MAE: 0.00115,  MAPE: 0.55%\n",
      "[800 Epochs]    RMSE:0.00050,   MAE: 0.00044,  MAPE: 0.21%\n",
      "[900 Epochs]    RMSE:0.00038,   MAE: 0.00032,  MAPE: 0.15%\n",
      "[1000 Epochs]    RMSE:0.00101,   MAE: 0.00090,  MAPE: 0.43%\n",
      "[1100 Epochs]    RMSE:0.00141,   MAE: 0.00121,  MAPE: 0.59%\n",
      "[1200 Epochs]    RMSE:0.00199,   MAE: 0.00186,  MAPE: 0.91%\n",
      "[1300 Epochs]    RMSE:0.00021,   MAE: 0.00017,  MAPE: 0.08%\n",
      "[1400 Epochs]    RMSE:0.00224,   MAE: 0.00220,  MAPE: 1.05%\n",
      "[1500 Epochs]    RMSE:0.00661,   MAE: 0.00659,  MAPE: 3.16%\n",
      "[1600 Epochs]    RMSE:0.00100,   MAE: 0.00092,  MAPE: 0.44%\n",
      "[1700 Epochs]    RMSE:0.00172,   MAE: 0.00164,  MAPE: 0.80%\n",
      "[1800 Epochs]    RMSE:0.00147,   MAE: 0.00145,  MAPE: 0.69%\n",
      "[1900 Epochs]    RMSE:0.00337,   MAE: 0.00323,  MAPE: 1.52%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00468,   MAE: 0.00462,  MAPE: 2.20%\n",
      "\n",
      "\n",
      "Trial No.58\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.28639,   MAE: 0.28210,  MAPE: 134.40%\n",
      "[100 Epochs]    RMSE:0.00145,   MAE: 0.00112,  MAPE: 0.53%\n",
      "[200 Epochs]    RMSE:0.00919,   MAE: 0.00868,  MAPE: 4.08%\n",
      "[300 Epochs]    RMSE:0.00101,   MAE: 0.00080,  MAPE: 0.37%\n",
      "[400 Epochs]    RMSE:0.00226,   MAE: 0.00205,  MAPE: 0.98%\n",
      "[500 Epochs]    RMSE:0.00096,   MAE: 0.00082,  MAPE: 0.38%\n",
      "[600 Epochs]    RMSE:0.00118,   MAE: 0.00109,  MAPE: 0.52%\n",
      "[700 Epochs]    RMSE:0.00477,   MAE: 0.00465,  MAPE: 2.20%\n",
      "[800 Epochs]    RMSE:0.00072,   MAE: 0.00056,  MAPE: 0.26%\n",
      "[900 Epochs]    RMSE:0.00394,   MAE: 0.00371,  MAPE: 1.75%\n",
      "[1000 Epochs]    RMSE:0.00498,   MAE: 0.00490,  MAPE: 2.32%\n",
      "[1100 Epochs]    RMSE:0.00358,   MAE: 0.00351,  MAPE: 1.68%\n",
      "[1200 Epochs]    RMSE:0.00126,   MAE: 0.00106,  MAPE: 0.49%\n",
      "[1300 Epochs]    RMSE:0.00232,   MAE: 0.00217,  MAPE: 1.02%\n",
      "[1400 Epochs]    RMSE:0.00220,   MAE: 0.00212,  MAPE: 1.00%\n",
      "[1500 Epochs]    RMSE:0.00156,   MAE: 0.00129,  MAPE: 0.60%\n",
      "[1600 Epochs]    RMSE:0.00187,   MAE: 0.00181,  MAPE: 0.88%\n",
      "[1700 Epochs]    RMSE:0.00136,   MAE: 0.00118,  MAPE: 0.55%\n",
      "[1800 Epochs]    RMSE:0.00117,   MAE: 0.00107,  MAPE: 0.51%\n",
      "[1900 Epochs]    RMSE:0.00350,   MAE: 0.00341,  MAPE: 1.61%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00078,   MAE: 0.00068,  MAPE: 0.32%\n",
      "\n",
      "\n",
      "Trial No.59\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.15600,   MAE: 0.15351,  MAPE: 73.48%\n",
      "[100 Epochs]    RMSE:0.00537,   MAE: 0.00495,  MAPE: 2.36%\n",
      "[200 Epochs]    RMSE:0.00745,   MAE: 0.00723,  MAPE: 3.44%\n",
      "[300 Epochs]    RMSE:0.00168,   MAE: 0.00150,  MAPE: 0.73%\n",
      "[400 Epochs]    RMSE:0.00264,   MAE: 0.00252,  MAPE: 1.21%\n",
      "[500 Epochs]    RMSE:0.00194,   MAE: 0.00184,  MAPE: 0.87%\n",
      "[600 Epochs]    RMSE:0.00186,   MAE: 0.00173,  MAPE: 0.82%\n",
      "[700 Epochs]    RMSE:0.00123,   MAE: 0.00096,  MAPE: 0.48%\n",
      "[800 Epochs]    RMSE:0.00305,   MAE: 0.00289,  MAPE: 1.38%\n",
      "[900 Epochs]    RMSE:0.00295,   MAE: 0.00275,  MAPE: 1.30%\n",
      "[1000 Epochs]    RMSE:0.00121,   MAE: 0.00101,  MAPE: 0.48%\n",
      "[1100 Epochs]    RMSE:0.00171,   MAE: 0.00163,  MAPE: 0.78%\n",
      "[1200 Epochs]    RMSE:0.00093,   MAE: 0.00085,  MAPE: 0.40%\n",
      "[1300 Epochs]    RMSE:0.00127,   MAE: 0.00103,  MAPE: 0.48%\n",
      "[1400 Epochs]    RMSE:0.00327,   MAE: 0.00321,  MAPE: 1.54%\n",
      "[1500 Epochs]    RMSE:0.00084,   MAE: 0.00073,  MAPE: 0.35%\n",
      "[1600 Epochs]    RMSE:0.00136,   MAE: 0.00123,  MAPE: 0.60%\n",
      "[1700 Epochs]    RMSE:0.00101,   MAE: 0.00078,  MAPE: 0.36%\n",
      "[1800 Epochs]    RMSE:0.00127,   MAE: 0.00118,  MAPE: 0.56%\n",
      "[1900 Epochs]    RMSE:0.00086,   MAE: 0.00067,  MAPE: 0.31%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00311,   MAE: 0.00300,  MAPE: 1.42%\n",
      "\n",
      "\n",
      "Trial No.60\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.29630,   MAE: 0.29170,  MAPE: 139.82%\n",
      "[100 Epochs]    RMSE:0.00453,   MAE: 0.00405,  MAPE: 1.90%\n",
      "[200 Epochs]    RMSE:0.00159,   MAE: 0.00133,  MAPE: 0.66%\n",
      "[300 Epochs]    RMSE:0.00169,   MAE: 0.00145,  MAPE: 0.70%\n",
      "[400 Epochs]    RMSE:0.00217,   MAE: 0.00208,  MAPE: 1.00%\n",
      "[500 Epochs]    RMSE:0.00187,   MAE: 0.00153,  MAPE: 0.75%\n",
      "[600 Epochs]    RMSE:0.00153,   MAE: 0.00137,  MAPE: 0.64%\n",
      "[700 Epochs]    RMSE:0.00087,   MAE: 0.00072,  MAPE: 0.34%\n",
      "[800 Epochs]    RMSE:0.00103,   MAE: 0.00089,  MAPE: 0.42%\n",
      "[900 Epochs]    RMSE:0.00277,   MAE: 0.00263,  MAPE: 1.28%\n",
      "[1000 Epochs]    RMSE:0.00067,   MAE: 0.00062,  MAPE: 0.30%\n",
      "[1100 Epochs]    RMSE:0.00366,   MAE: 0.00362,  MAPE: 1.72%\n",
      "[1200 Epochs]    RMSE:0.00197,   MAE: 0.00193,  MAPE: 0.93%\n",
      "[1300 Epochs]    RMSE:0.00878,   MAE: 0.00870,  MAPE: 4.14%\n",
      "[1400 Epochs]    RMSE:0.00167,   MAE: 0.00165,  MAPE: 0.79%\n",
      "[1500 Epochs]    RMSE:0.00054,   MAE: 0.00048,  MAPE: 0.22%\n",
      "[1600 Epochs]    RMSE:0.00319,   MAE: 0.00314,  MAPE: 1.50%\n",
      "[1700 Epochs]    RMSE:0.00271,   MAE: 0.00264,  MAPE: 1.25%\n",
      "[1800 Epochs]    RMSE:0.00160,   MAE: 0.00111,  MAPE: 0.50%\n",
      "[1900 Epochs]    RMSE:0.00120,   MAE: 0.00113,  MAPE: 0.55%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00060,   MAE: 0.00050,  MAPE: 0.24%\n",
      "\n",
      "\n",
      "Trial No.61\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.11823,   MAE: 0.11067,  MAPE: 52.54%\n",
      "[100 Epochs]    RMSE:0.00536,   MAE: 0.00458,  MAPE: 2.21%\n",
      "[200 Epochs]    RMSE:0.00291,   MAE: 0.00271,  MAPE: 1.29%\n",
      "[300 Epochs]    RMSE:0.00444,   MAE: 0.00432,  MAPE: 2.05%\n",
      "[400 Epochs]    RMSE:0.00354,   MAE: 0.00335,  MAPE: 1.57%\n",
      "[500 Epochs]    RMSE:0.00087,   MAE: 0.00066,  MAPE: 0.32%\n",
      "[600 Epochs]    RMSE:0.00322,   MAE: 0.00312,  MAPE: 1.48%\n",
      "[700 Epochs]    RMSE:0.00211,   MAE: 0.00191,  MAPE: 0.94%\n",
      "[800 Epochs]    RMSE:0.00232,   MAE: 0.00219,  MAPE: 1.03%\n",
      "[900 Epochs]    RMSE:0.00350,   MAE: 0.00338,  MAPE: 1.60%\n",
      "[1000 Epochs]    RMSE:0.00036,   MAE: 0.00030,  MAPE: 0.14%\n",
      "[1100 Epochs]    RMSE:0.00028,   MAE: 0.00023,  MAPE: 0.11%\n",
      "[1200 Epochs]    RMSE:0.00160,   MAE: 0.00152,  MAPE: 0.72%\n",
      "[1300 Epochs]    RMSE:0.00174,   MAE: 0.00151,  MAPE: 0.70%\n",
      "[1400 Epochs]    RMSE:0.00062,   MAE: 0.00051,  MAPE: 0.24%\n",
      "[1500 Epochs]    RMSE:0.00136,   MAE: 0.00121,  MAPE: 0.59%\n",
      "[1600 Epochs]    RMSE:0.00086,   MAE: 0.00081,  MAPE: 0.38%\n",
      "[1700 Epochs]    RMSE:0.00170,   MAE: 0.00158,  MAPE: 0.74%\n",
      "[1800 Epochs]    RMSE:0.00072,   MAE: 0.00059,  MAPE: 0.28%\n",
      "[1900 Epochs]    RMSE:0.00086,   MAE: 0.00075,  MAPE: 0.36%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00247,   MAE: 0.00243,  MAPE: 1.16%\n",
      "\n",
      "\n",
      "Trial No.62\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 Epochs]    RMSE:0.30318,   MAE: 0.29846,  MAPE: 143.61%\n",
      "[100 Epochs]    RMSE:0.00390,   MAE: 0.00363,  MAPE: 1.74%\n",
      "[200 Epochs]    RMSE:0.00297,   MAE: 0.00243,  MAPE: 1.17%\n",
      "[300 Epochs]    RMSE:0.00600,   MAE: 0.00561,  MAPE: 2.67%\n",
      "[400 Epochs]    RMSE:0.00435,   MAE: 0.00413,  MAPE: 1.98%\n",
      "[500 Epochs]    RMSE:0.00579,   MAE: 0.00560,  MAPE: 2.67%\n",
      "[600 Epochs]    RMSE:0.00197,   MAE: 0.00183,  MAPE: 0.86%\n",
      "[700 Epochs]    RMSE:0.00275,   MAE: 0.00270,  MAPE: 1.29%\n",
      "[800 Epochs]    RMSE:0.00445,   MAE: 0.00436,  MAPE: 2.08%\n",
      "[900 Epochs]    RMSE:0.00146,   MAE: 0.00132,  MAPE: 0.63%\n",
      "[1000 Epochs]    RMSE:0.00293,   MAE: 0.00279,  MAPE: 1.32%\n",
      "[1100 Epochs]    RMSE:0.00127,   MAE: 0.00114,  MAPE: 0.55%\n",
      "[1200 Epochs]    RMSE:0.00086,   MAE: 0.00070,  MAPE: 0.34%\n",
      "[1300 Epochs]    RMSE:0.00151,   MAE: 0.00142,  MAPE: 0.68%\n",
      "[1400 Epochs]    RMSE:0.00291,   MAE: 0.00284,  MAPE: 1.35%\n",
      "[1500 Epochs]    RMSE:0.00108,   MAE: 0.00092,  MAPE: 0.46%\n",
      "[1600 Epochs]    RMSE:0.00051,   MAE: 0.00037,  MAPE: 0.17%\n",
      "[1700 Epochs]    RMSE:0.00491,   MAE: 0.00484,  MAPE: 2.30%\n",
      "[1800 Epochs]    RMSE:0.00107,   MAE: 0.00091,  MAPE: 0.44%\n",
      "[1900 Epochs]    RMSE:0.00200,   MAE: 0.00192,  MAPE: 0.91%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00130,   MAE: 0.00114,  MAPE: 0.53%\n",
      "\n",
      "\n",
      "Trial No.63\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.10817,   MAE: 0.09243,  MAPE: 44.78%\n",
      "[100 Epochs]    RMSE:0.00333,   MAE: 0.00267,  MAPE: 1.27%\n",
      "[200 Epochs]    RMSE:0.00208,   MAE: 0.00172,  MAPE: 0.81%\n",
      "[300 Epochs]    RMSE:0.00261,   MAE: 0.00231,  MAPE: 1.09%\n",
      "[400 Epochs]    RMSE:0.00511,   MAE: 0.00501,  MAPE: 2.38%\n",
      "[500 Epochs]    RMSE:0.00572,   MAE: 0.00560,  MAPE: 2.65%\n",
      "[600 Epochs]    RMSE:0.00187,   MAE: 0.00163,  MAPE: 0.80%\n",
      "[700 Epochs]    RMSE:0.00287,   MAE: 0.00283,  MAPE: 1.36%\n",
      "[800 Epochs]    RMSE:0.00587,   MAE: 0.00576,  MAPE: 2.74%\n",
      "[900 Epochs]    RMSE:0.00146,   MAE: 0.00117,  MAPE: 0.54%\n",
      "[1000 Epochs]    RMSE:0.00109,   MAE: 0.00102,  MAPE: 0.50%\n",
      "[1100 Epochs]    RMSE:0.00048,   MAE: 0.00038,  MAPE: 0.18%\n",
      "[1200 Epochs]    RMSE:0.00215,   MAE: 0.00212,  MAPE: 1.02%\n",
      "[1300 Epochs]    RMSE:0.00099,   MAE: 0.00081,  MAPE: 0.38%\n",
      "[1400 Epochs]    RMSE:0.00400,   MAE: 0.00397,  MAPE: 1.90%\n",
      "[1500 Epochs]    RMSE:0.00166,   MAE: 0.00153,  MAPE: 0.72%\n",
      "[1600 Epochs]    RMSE:0.00083,   MAE: 0.00075,  MAPE: 0.35%\n",
      "[1700 Epochs]    RMSE:0.00142,   MAE: 0.00134,  MAPE: 0.64%\n",
      "[1800 Epochs]    RMSE:0.00064,   MAE: 0.00057,  MAPE: 0.27%\n",
      "[1900 Epochs]    RMSE:0.00175,   MAE: 0.00170,  MAPE: 0.81%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00066,   MAE: 0.00058,  MAPE: 0.28%\n",
      "\n",
      "\n",
      "Trial No.64\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.14255,   MAE: 0.13638,  MAPE: 66.27%\n",
      "[100 Epochs]    RMSE:0.00462,   MAE: 0.00376,  MAPE: 1.80%\n",
      "[200 Epochs]    RMSE:0.00124,   MAE: 0.00100,  MAPE: 0.49%\n",
      "[300 Epochs]    RMSE:0.00551,   MAE: 0.00541,  MAPE: 2.59%\n",
      "[400 Epochs]    RMSE:0.00239,   MAE: 0.00208,  MAPE: 0.99%\n",
      "[500 Epochs]    RMSE:0.00302,   MAE: 0.00289,  MAPE: 1.39%\n",
      "[600 Epochs]    RMSE:0.00370,   MAE: 0.00354,  MAPE: 1.69%\n",
      "[700 Epochs]    RMSE:0.00446,   MAE: 0.00424,  MAPE: 2.03%\n",
      "[800 Epochs]    RMSE:0.00361,   MAE: 0.00335,  MAPE: 1.57%\n",
      "[900 Epochs]    RMSE:0.00176,   MAE: 0.00162,  MAPE: 0.76%\n",
      "[1000 Epochs]    RMSE:0.00217,   MAE: 0.00209,  MAPE: 1.00%\n",
      "[1100 Epochs]    RMSE:0.00112,   MAE: 0.00107,  MAPE: 0.51%\n",
      "[1200 Epochs]    RMSE:0.00310,   MAE: 0.00308,  MAPE: 1.47%\n",
      "[1300 Epochs]    RMSE:0.00390,   MAE: 0.00388,  MAPE: 1.86%\n",
      "[1400 Epochs]    RMSE:0.00055,   MAE: 0.00042,  MAPE: 0.19%\n",
      "[1500 Epochs]    RMSE:0.00114,   MAE: 0.00105,  MAPE: 0.51%\n",
      "[1600 Epochs]    RMSE:0.00291,   MAE: 0.00280,  MAPE: 1.32%\n",
      "[1700 Epochs]    RMSE:0.00143,   MAE: 0.00138,  MAPE: 0.66%\n",
      "[1800 Epochs]    RMSE:0.00157,   MAE: 0.00153,  MAPE: 0.74%\n",
      "[1900 Epochs]    RMSE:0.00145,   MAE: 0.00137,  MAPE: 0.65%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00055,   MAE: 0.00047,  MAPE: 0.23%\n",
      "\n",
      "\n",
      "Trial No.65\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.20018,   MAE: 0.19603,  MAPE: 94.94%\n",
      "[100 Epochs]    RMSE:0.00198,   MAE: 0.00148,  MAPE: 0.71%\n",
      "[200 Epochs]    RMSE:0.00292,   MAE: 0.00261,  MAPE: 1.24%\n",
      "[300 Epochs]    RMSE:0.00205,   MAE: 0.00183,  MAPE: 0.87%\n",
      "[400 Epochs]    RMSE:0.00546,   MAE: 0.00530,  MAPE: 2.55%\n",
      "[500 Epochs]    RMSE:0.00141,   MAE: 0.00124,  MAPE: 0.58%\n",
      "[600 Epochs]    RMSE:0.00134,   MAE: 0.00104,  MAPE: 0.52%\n",
      "[700 Epochs]    RMSE:0.00144,   MAE: 0.00128,  MAPE: 0.60%\n",
      "[800 Epochs]    RMSE:0.00115,   MAE: 0.00094,  MAPE: 0.44%\n",
      "[900 Epochs]    RMSE:0.00160,   MAE: 0.00140,  MAPE: 0.65%\n",
      "[1000 Epochs]    RMSE:0.00366,   MAE: 0.00361,  MAPE: 1.72%\n",
      "[1100 Epochs]    RMSE:0.00588,   MAE: 0.00574,  MAPE: 2.72%\n",
      "[1200 Epochs]    RMSE:0.00356,   MAE: 0.00341,  MAPE: 1.61%\n",
      "[1300 Epochs]    RMSE:0.00091,   MAE: 0.00072,  MAPE: 0.33%\n",
      "[1400 Epochs]    RMSE:0.00098,   MAE: 0.00082,  MAPE: 0.40%\n",
      "[1500 Epochs]    RMSE:0.00122,   MAE: 0.00118,  MAPE: 0.56%\n",
      "[1600 Epochs]    RMSE:0.00555,   MAE: 0.00548,  MAPE: 2.60%\n",
      "[1700 Epochs]    RMSE:0.00442,   MAE: 0.00440,  MAPE: 2.10%\n",
      "[1800 Epochs]    RMSE:0.00203,   MAE: 0.00198,  MAPE: 0.94%\n",
      "[1900 Epochs]    RMSE:0.00217,   MAE: 0.00196,  MAPE: 0.94%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00074,   MAE: 0.00053,  MAPE: 0.24%\n",
      "\n",
      "\n",
      "Trial No.66\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.34694,   MAE: 0.34177,  MAPE: 163.04%\n",
      "[100 Epochs]    RMSE:0.00211,   MAE: 0.00175,  MAPE: 0.82%\n",
      "[200 Epochs]    RMSE:0.00562,   MAE: 0.00522,  MAPE: 2.46%\n",
      "[300 Epochs]    RMSE:0.00179,   MAE: 0.00148,  MAPE: 0.71%\n",
      "[400 Epochs]    RMSE:0.00223,   MAE: 0.00203,  MAPE: 0.96%\n",
      "[500 Epochs]    RMSE:0.00342,   MAE: 0.00328,  MAPE: 1.55%\n",
      "[600 Epochs]    RMSE:0.00190,   MAE: 0.00175,  MAPE: 0.82%\n",
      "[700 Epochs]    RMSE:0.00097,   MAE: 0.00075,  MAPE: 0.37%\n",
      "[800 Epochs]    RMSE:0.00131,   MAE: 0.00115,  MAPE: 0.53%\n",
      "[900 Epochs]    RMSE:0.00061,   MAE: 0.00052,  MAPE: 0.25%\n",
      "[1000 Epochs]    RMSE:0.00087,   MAE: 0.00080,  MAPE: 0.38%\n",
      "[1100 Epochs]    RMSE:0.00091,   MAE: 0.00079,  MAPE: 0.37%\n",
      "[1200 Epochs]    RMSE:0.00070,   MAE: 0.00058,  MAPE: 0.27%\n",
      "[1300 Epochs]    RMSE:0.00037,   MAE: 0.00031,  MAPE: 0.15%\n",
      "[1400 Epochs]    RMSE:0.00417,   MAE: 0.00412,  MAPE: 1.98%\n",
      "[1500 Epochs]    RMSE:0.00071,   MAE: 0.00057,  MAPE: 0.28%\n",
      "[1600 Epochs]    RMSE:0.00148,   MAE: 0.00142,  MAPE: 0.69%\n",
      "[1700 Epochs]    RMSE:0.00149,   MAE: 0.00137,  MAPE: 0.66%\n",
      "[1800 Epochs]    RMSE:0.00127,   MAE: 0.00108,  MAPE: 0.50%\n",
      "[1900 Epochs]    RMSE:0.00174,   MAE: 0.00158,  MAPE: 0.76%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00264,   MAE: 0.00241,  MAPE: 1.13%\n",
      "\n",
      "\n",
      "Trial No.67\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.26302,   MAE: 0.26128,  MAPE: 124.66%\n",
      "[100 Epochs]    RMSE:0.00359,   MAE: 0.00295,  MAPE: 1.38%\n",
      "[200 Epochs]    RMSE:0.00308,   MAE: 0.00249,  MAPE: 1.21%\n",
      "[300 Epochs]    RMSE:0.00383,   MAE: 0.00344,  MAPE: 1.65%\n",
      "[400 Epochs]    RMSE:0.00172,   MAE: 0.00148,  MAPE: 0.69%\n",
      "[500 Epochs]    RMSE:0.00826,   MAE: 0.00820,  MAPE: 3.91%\n",
      "[600 Epochs]    RMSE:0.00306,   MAE: 0.00298,  MAPE: 1.43%\n",
      "[700 Epochs]    RMSE:0.00341,   MAE: 0.00335,  MAPE: 1.59%\n",
      "[800 Epochs]    RMSE:0.00050,   MAE: 0.00040,  MAPE: 0.20%\n",
      "[900 Epochs]    RMSE:0.00122,   MAE: 0.00100,  MAPE: 0.47%\n",
      "[1000 Epochs]    RMSE:0.00427,   MAE: 0.00419,  MAPE: 2.01%\n",
      "[1100 Epochs]    RMSE:0.00171,   MAE: 0.00158,  MAPE: 0.74%\n",
      "[1200 Epochs]    RMSE:0.00044,   MAE: 0.00036,  MAPE: 0.17%\n",
      "[1300 Epochs]    RMSE:0.00123,   MAE: 0.00112,  MAPE: 0.55%\n",
      "[1400 Epochs]    RMSE:0.00089,   MAE: 0.00077,  MAPE: 0.36%\n",
      "[1500 Epochs]    RMSE:0.00175,   MAE: 0.00154,  MAPE: 0.76%\n",
      "[1600 Epochs]    RMSE:0.00159,   MAE: 0.00134,  MAPE: 0.63%\n",
      "[1700 Epochs]    RMSE:0.00233,   MAE: 0.00230,  MAPE: 1.09%\n",
      "[1800 Epochs]    RMSE:0.00112,   MAE: 0.00101,  MAPE: 0.49%\n",
      "[1900 Epochs]    RMSE:0.00105,   MAE: 0.00086,  MAPE: 0.40%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00137,   MAE: 0.00129,  MAPE: 0.61%\n",
      "\n",
      "\n",
      "Trial No.68\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.23919,   MAE: 0.23054,  MAPE: 110.60%\n",
      "[100 Epochs]    RMSE:0.00224,   MAE: 0.00192,  MAPE: 0.95%\n",
      "[200 Epochs]    RMSE:0.00831,   MAE: 0.00800,  MAPE: 3.78%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300 Epochs]    RMSE:0.00454,   MAE: 0.00428,  MAPE: 2.04%\n",
      "[400 Epochs]    RMSE:0.00196,   MAE: 0.00168,  MAPE: 0.79%\n",
      "[500 Epochs]    RMSE:0.00236,   MAE: 0.00213,  MAPE: 1.03%\n",
      "[600 Epochs]    RMSE:0.00240,   MAE: 0.00232,  MAPE: 1.11%\n",
      "[700 Epochs]    RMSE:0.00204,   MAE: 0.00195,  MAPE: 0.93%\n",
      "[800 Epochs]    RMSE:0.00251,   MAE: 0.00244,  MAPE: 1.16%\n",
      "[900 Epochs]    RMSE:0.00083,   MAE: 0.00068,  MAPE: 0.32%\n",
      "[1000 Epochs]    RMSE:0.00112,   MAE: 0.00099,  MAPE: 0.47%\n",
      "[1100 Epochs]    RMSE:0.00188,   MAE: 0.00174,  MAPE: 0.83%\n",
      "[1200 Epochs]    RMSE:0.00115,   MAE: 0.00110,  MAPE: 0.52%\n",
      "[1300 Epochs]    RMSE:0.00235,   MAE: 0.00233,  MAPE: 1.11%\n",
      "[1400 Epochs]    RMSE:0.00155,   MAE: 0.00149,  MAPE: 0.71%\n",
      "[1500 Epochs]    RMSE:0.00189,   MAE: 0.00182,  MAPE: 0.88%\n",
      "[1600 Epochs]    RMSE:0.00208,   MAE: 0.00201,  MAPE: 0.95%\n",
      "[1700 Epochs]    RMSE:0.00200,   MAE: 0.00196,  MAPE: 0.94%\n",
      "[1800 Epochs]    RMSE:0.00207,   MAE: 0.00201,  MAPE: 0.96%\n",
      "[1900 Epochs]    RMSE:0.00563,   MAE: 0.00559,  MAPE: 2.67%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00082,   MAE: 0.00070,  MAPE: 0.33%\n",
      "\n",
      "\n",
      "Trial No.69\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.25368,   MAE: 0.24919,  MAPE: 118.40%\n",
      "[100 Epochs]    RMSE:0.00764,   MAE: 0.00718,  MAPE: 3.40%\n",
      "[200 Epochs]    RMSE:0.01071,   MAE: 0.01053,  MAPE: 5.00%\n",
      "[300 Epochs]    RMSE:0.00262,   MAE: 0.00254,  MAPE: 1.23%\n",
      "[400 Epochs]    RMSE:0.00066,   MAE: 0.00053,  MAPE: 0.26%\n",
      "[500 Epochs]    RMSE:0.00211,   MAE: 0.00204,  MAPE: 0.97%\n",
      "[600 Epochs]    RMSE:0.00287,   MAE: 0.00274,  MAPE: 1.29%\n",
      "[700 Epochs]    RMSE:0.00169,   MAE: 0.00148,  MAPE: 0.69%\n",
      "[800 Epochs]    RMSE:0.00167,   MAE: 0.00145,  MAPE: 0.67%\n",
      "[900 Epochs]    RMSE:0.00526,   MAE: 0.00499,  MAPE: 2.34%\n",
      "[1000 Epochs]    RMSE:0.00048,   MAE: 0.00037,  MAPE: 0.18%\n",
      "[1100 Epochs]    RMSE:0.00346,   MAE: 0.00319,  MAPE: 1.49%\n",
      "[1200 Epochs]    RMSE:0.00332,   MAE: 0.00324,  MAPE: 1.56%\n",
      "[1300 Epochs]    RMSE:0.00117,   MAE: 0.00107,  MAPE: 0.51%\n",
      "[1400 Epochs]    RMSE:0.00104,   MAE: 0.00085,  MAPE: 0.42%\n",
      "[1500 Epochs]    RMSE:0.00262,   MAE: 0.00252,  MAPE: 1.19%\n",
      "[1600 Epochs]    RMSE:0.00319,   MAE: 0.00311,  MAPE: 1.49%\n",
      "[1700 Epochs]    RMSE:0.00277,   MAE: 0.00272,  MAPE: 1.30%\n",
      "[1800 Epochs]    RMSE:0.00273,   MAE: 0.00271,  MAPE: 1.29%\n",
      "[1900 Epochs]    RMSE:0.00096,   MAE: 0.00082,  MAPE: 0.39%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00104,   MAE: 0.00094,  MAPE: 0.45%\n",
      "\n",
      "\n",
      "Trial No.70\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.26291,   MAE: 0.26165,  MAPE: 124.93%\n",
      "[100 Epochs]    RMSE:0.00521,   MAE: 0.00455,  MAPE: 2.14%\n",
      "[200 Epochs]    RMSE:0.00343,   MAE: 0.00329,  MAPE: 1.56%\n",
      "[300 Epochs]    RMSE:0.00533,   MAE: 0.00527,  MAPE: 2.53%\n",
      "[400 Epochs]    RMSE:0.00190,   MAE: 0.00182,  MAPE: 0.88%\n",
      "[500 Epochs]    RMSE:0.00130,   MAE: 0.00106,  MAPE: 0.49%\n",
      "[600 Epochs]    RMSE:0.00856,   MAE: 0.00834,  MAPE: 3.94%\n",
      "[700 Epochs]    RMSE:0.00372,   MAE: 0.00345,  MAPE: 1.62%\n",
      "[800 Epochs]    RMSE:0.00076,   MAE: 0.00064,  MAPE: 0.31%\n",
      "[900 Epochs]    RMSE:0.00246,   MAE: 0.00240,  MAPE: 1.14%\n",
      "[1000 Epochs]    RMSE:0.00172,   MAE: 0.00158,  MAPE: 0.76%\n",
      "[1100 Epochs]    RMSE:0.00501,   MAE: 0.00497,  MAPE: 2.37%\n",
      "[1200 Epochs]    RMSE:0.00109,   MAE: 0.00084,  MAPE: 0.41%\n",
      "[1300 Epochs]    RMSE:0.00217,   MAE: 0.00212,  MAPE: 1.01%\n",
      "[1400 Epochs]    RMSE:0.00150,   MAE: 0.00128,  MAPE: 0.63%\n",
      "[1500 Epochs]    RMSE:0.00221,   MAE: 0.00203,  MAPE: 0.95%\n",
      "[1600 Epochs]    RMSE:0.00298,   MAE: 0.00285,  MAPE: 1.37%\n",
      "[1700 Epochs]    RMSE:0.00208,   MAE: 0.00199,  MAPE: 0.97%\n",
      "[1800 Epochs]    RMSE:0.00192,   MAE: 0.00180,  MAPE: 0.85%\n",
      "[1900 Epochs]    RMSE:0.00184,   MAE: 0.00177,  MAPE: 0.85%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00046,   MAE: 0.00036,  MAPE: 0.17%\n",
      "\n",
      "\n",
      "Trial No.71\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.10178,   MAE: 0.08443,  MAPE: 40.42%\n",
      "[100 Epochs]    RMSE:0.00340,   MAE: 0.00308,  MAPE: 1.46%\n",
      "[200 Epochs]    RMSE:0.00193,   MAE: 0.00168,  MAPE: 0.82%\n",
      "[300 Epochs]    RMSE:0.00178,   MAE: 0.00143,  MAPE: 0.69%\n",
      "[400 Epochs]    RMSE:0.00304,   MAE: 0.00269,  MAPE: 1.27%\n",
      "[500 Epochs]    RMSE:0.00166,   MAE: 0.00157,  MAPE: 0.76%\n",
      "[600 Epochs]    RMSE:0.00240,   MAE: 0.00229,  MAPE: 1.09%\n",
      "[700 Epochs]    RMSE:0.00168,   MAE: 0.00164,  MAPE: 0.78%\n",
      "[800 Epochs]    RMSE:0.00193,   MAE: 0.00180,  MAPE: 0.85%\n",
      "[900 Epochs]    RMSE:0.00219,   MAE: 0.00212,  MAPE: 1.01%\n",
      "[1000 Epochs]    RMSE:0.00154,   MAE: 0.00132,  MAPE: 0.62%\n",
      "[1100 Epochs]    RMSE:0.00220,   MAE: 0.00215,  MAPE: 1.04%\n",
      "[1200 Epochs]    RMSE:0.00276,   MAE: 0.00271,  MAPE: 1.29%\n",
      "[1300 Epochs]    RMSE:0.00033,   MAE: 0.00026,  MAPE: 0.13%\n",
      "[1400 Epochs]    RMSE:0.00409,   MAE: 0.00405,  MAPE: 1.93%\n",
      "[1500 Epochs]    RMSE:0.00172,   MAE: 0.00163,  MAPE: 0.79%\n",
      "[1600 Epochs]    RMSE:0.00290,   MAE: 0.00285,  MAPE: 1.36%\n",
      "[1700 Epochs]    RMSE:0.00138,   MAE: 0.00136,  MAPE: 0.65%\n",
      "[1800 Epochs]    RMSE:0.00101,   MAE: 0.00099,  MAPE: 0.47%\n",
      "[1900 Epochs]    RMSE:0.00034,   MAE: 0.00028,  MAPE: 0.13%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00046,   MAE: 0.00037,  MAPE: 0.17%\n",
      "\n",
      "\n",
      "Trial No.72\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.16518,   MAE: 0.15839,  MAPE: 76.72%\n",
      "[100 Epochs]    RMSE:0.00789,   MAE: 0.00751,  MAPE: 3.59%\n",
      "[200 Epochs]    RMSE:0.00247,   MAE: 0.00223,  MAPE: 1.05%\n",
      "[300 Epochs]    RMSE:0.00402,   MAE: 0.00394,  MAPE: 1.88%\n",
      "[400 Epochs]    RMSE:0.00112,   MAE: 0.00091,  MAPE: 0.44%\n",
      "[500 Epochs]    RMSE:0.00232,   MAE: 0.00225,  MAPE: 1.07%\n",
      "[600 Epochs]    RMSE:0.00242,   MAE: 0.00236,  MAPE: 1.13%\n",
      "[700 Epochs]    RMSE:0.00370,   MAE: 0.00366,  MAPE: 1.74%\n",
      "[800 Epochs]    RMSE:0.00043,   MAE: 0.00033,  MAPE: 0.16%\n",
      "[900 Epochs]    RMSE:0.00235,   MAE: 0.00212,  MAPE: 1.00%\n",
      "[1000 Epochs]    RMSE:0.00097,   MAE: 0.00090,  MAPE: 0.42%\n",
      "[1100 Epochs]    RMSE:0.00363,   MAE: 0.00359,  MAPE: 1.72%\n",
      "[1200 Epochs]    RMSE:0.00136,   MAE: 0.00132,  MAPE: 0.63%\n",
      "[1300 Epochs]    RMSE:0.00254,   MAE: 0.00229,  MAPE: 1.07%\n",
      "[1400 Epochs]    RMSE:0.00663,   MAE: 0.00645,  MAPE: 3.05%\n",
      "[1500 Epochs]    RMSE:0.00200,   MAE: 0.00197,  MAPE: 0.94%\n",
      "[1600 Epochs]    RMSE:0.00327,   MAE: 0.00310,  MAPE: 1.46%\n",
      "[1700 Epochs]    RMSE:0.00129,   MAE: 0.00121,  MAPE: 0.57%\n",
      "[1800 Epochs]    RMSE:0.00283,   MAE: 0.00280,  MAPE: 1.33%\n",
      "[1900 Epochs]    RMSE:0.00190,   MAE: 0.00178,  MAPE: 0.83%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00104,   MAE: 0.00090,  MAPE: 0.44%\n",
      "\n",
      "\n",
      "Trial No.73\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.18266,   MAE: 0.17828,  MAPE: 84.92%\n",
      "[100 Epochs]    RMSE:0.00506,   MAE: 0.00445,  MAPE: 2.12%\n",
      "[200 Epochs]    RMSE:0.00296,   MAE: 0.00238,  MAPE: 1.12%\n",
      "[300 Epochs]    RMSE:0.00191,   MAE: 0.00156,  MAPE: 0.76%\n",
      "[400 Epochs]    RMSE:0.00100,   MAE: 0.00082,  MAPE: 0.39%\n",
      "[500 Epochs]    RMSE:0.00339,   MAE: 0.00331,  MAPE: 1.59%\n",
      "[600 Epochs]    RMSE:0.00561,   MAE: 0.00552,  MAPE: 2.62%\n",
      "[700 Epochs]    RMSE:0.00119,   MAE: 0.00102,  MAPE: 0.50%\n",
      "[800 Epochs]    RMSE:0.00077,   MAE: 0.00065,  MAPE: 0.30%\n",
      "[900 Epochs]    RMSE:0.00073,   MAE: 0.00062,  MAPE: 0.30%\n",
      "[1000 Epochs]    RMSE:0.00131,   MAE: 0.00112,  MAPE: 0.53%\n",
      "[1100 Epochs]    RMSE:0.00094,   MAE: 0.00073,  MAPE: 0.36%\n",
      "[1200 Epochs]    RMSE:0.00176,   MAE: 0.00164,  MAPE: 0.77%\n",
      "[1300 Epochs]    RMSE:0.00074,   MAE: 0.00064,  MAPE: 0.31%\n",
      "[1400 Epochs]    RMSE:0.00304,   MAE: 0.00297,  MAPE: 1.41%\n",
      "[1500 Epochs]    RMSE:0.00075,   MAE: 0.00070,  MAPE: 0.33%\n",
      "[1600 Epochs]    RMSE:0.00057,   MAE: 0.00042,  MAPE: 0.20%\n",
      "[1700 Epochs]    RMSE:0.00131,   MAE: 0.00121,  MAPE: 0.59%\n",
      "[1800 Epochs]    RMSE:0.00066,   MAE: 0.00057,  MAPE: 0.28%\n",
      "[1900 Epochs]    RMSE:0.00095,   MAE: 0.00083,  MAPE: 0.39%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00153,   MAE: 0.00146,  MAPE: 0.70%\n",
      "\n",
      "\n",
      "Trial No.74\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.10651,   MAE: 0.09972,  MAPE: 48.08%\n",
      "[100 Epochs]    RMSE:0.00235,   MAE: 0.00201,  MAPE: 0.97%\n",
      "[200 Epochs]    RMSE:0.00802,   MAE: 0.00778,  MAPE: 3.71%\n",
      "[300 Epochs]    RMSE:0.00141,   MAE: 0.00123,  MAPE: 0.59%\n",
      "[400 Epochs]    RMSE:0.00125,   MAE: 0.00104,  MAPE: 0.50%\n",
      "[500 Epochs]    RMSE:0.00167,   MAE: 0.00153,  MAPE: 0.73%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600 Epochs]    RMSE:0.00370,   MAE: 0.00360,  MAPE: 1.73%\n",
      "[700 Epochs]    RMSE:0.00344,   MAE: 0.00340,  MAPE: 1.63%\n",
      "[800 Epochs]    RMSE:0.00118,   MAE: 0.00110,  MAPE: 0.52%\n",
      "[900 Epochs]    RMSE:0.00089,   MAE: 0.00084,  MAPE: 0.40%\n",
      "[1000 Epochs]    RMSE:0.00245,   MAE: 0.00228,  MAPE: 1.07%\n",
      "[1100 Epochs]    RMSE:0.00142,   MAE: 0.00139,  MAPE: 0.66%\n",
      "[1200 Epochs]    RMSE:0.00204,   MAE: 0.00179,  MAPE: 0.83%\n",
      "[1300 Epochs]    RMSE:0.00062,   MAE: 0.00054,  MAPE: 0.26%\n",
      "[1400 Epochs]    RMSE:0.00078,   MAE: 0.00068,  MAPE: 0.33%\n",
      "[1500 Epochs]    RMSE:0.00313,   MAE: 0.00308,  MAPE: 1.47%\n",
      "[1600 Epochs]    RMSE:0.00251,   MAE: 0.00249,  MAPE: 1.19%\n",
      "[1700 Epochs]    RMSE:0.00747,   MAE: 0.00742,  MAPE: 3.53%\n",
      "[1800 Epochs]    RMSE:0.00074,   MAE: 0.00071,  MAPE: 0.34%\n",
      "[1900 Epochs]    RMSE:0.00074,   MAE: 0.00065,  MAPE: 0.32%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00276,   MAE: 0.00272,  MAPE: 1.30%\n",
      "\n",
      "\n",
      "Trial No.75\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.25542,   MAE: 0.25411,  MAPE: 121.23%\n",
      "[100 Epochs]    RMSE:0.00395,   MAE: 0.00356,  MAPE: 1.69%\n",
      "[200 Epochs]    RMSE:0.00206,   MAE: 0.00185,  MAPE: 0.89%\n",
      "[300 Epochs]    RMSE:0.00166,   MAE: 0.00138,  MAPE: 0.66%\n",
      "[400 Epochs]    RMSE:0.00414,   MAE: 0.00407,  MAPE: 1.94%\n",
      "[500 Epochs]    RMSE:0.00078,   MAE: 0.00056,  MAPE: 0.27%\n",
      "[600 Epochs]    RMSE:0.00250,   MAE: 0.00216,  MAPE: 1.00%\n",
      "[700 Epochs]    RMSE:0.00063,   MAE: 0.00052,  MAPE: 0.25%\n",
      "[800 Epochs]    RMSE:0.00625,   MAE: 0.00620,  MAPE: 2.96%\n",
      "[900 Epochs]    RMSE:0.00550,   MAE: 0.00543,  MAPE: 2.58%\n",
      "[1000 Epochs]    RMSE:0.00136,   MAE: 0.00131,  MAPE: 0.63%\n",
      "[1100 Epochs]    RMSE:0.00202,   MAE: 0.00190,  MAPE: 0.89%\n",
      "[1200 Epochs]    RMSE:0.00288,   MAE: 0.00268,  MAPE: 1.26%\n",
      "[1300 Epochs]    RMSE:0.00294,   MAE: 0.00286,  MAPE: 1.38%\n",
      "[1400 Epochs]    RMSE:0.00043,   MAE: 0.00035,  MAPE: 0.17%\n",
      "[1500 Epochs]    RMSE:0.00061,   MAE: 0.00050,  MAPE: 0.25%\n",
      "[1600 Epochs]    RMSE:0.00134,   MAE: 0.00122,  MAPE: 0.57%\n",
      "[1700 Epochs]    RMSE:0.00261,   MAE: 0.00253,  MAPE: 1.20%\n",
      "[1800 Epochs]    RMSE:0.00046,   MAE: 0.00037,  MAPE: 0.18%\n",
      "[1900 Epochs]    RMSE:0.00116,   MAE: 0.00107,  MAPE: 0.50%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00103,   MAE: 0.00087,  MAPE: 0.41%\n",
      "\n",
      "\n",
      "Trial No.76\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.19859,   MAE: 0.19779,  MAPE: 94.65%\n",
      "[100 Epochs]    RMSE:0.00463,   MAE: 0.00391,  MAPE: 1.92%\n",
      "[200 Epochs]    RMSE:0.00564,   MAE: 0.00548,  MAPE: 2.60%\n",
      "[300 Epochs]    RMSE:0.00286,   MAE: 0.00266,  MAPE: 1.30%\n",
      "[400 Epochs]    RMSE:0.00245,   MAE: 0.00216,  MAPE: 1.04%\n",
      "[500 Epochs]    RMSE:0.00421,   MAE: 0.00388,  MAPE: 1.81%\n",
      "[600 Epochs]    RMSE:0.00209,   MAE: 0.00191,  MAPE: 0.90%\n",
      "[700 Epochs]    RMSE:0.00474,   MAE: 0.00451,  MAPE: 2.12%\n",
      "[800 Epochs]    RMSE:0.00102,   MAE: 0.00094,  MAPE: 0.46%\n",
      "[900 Epochs]    RMSE:0.00176,   MAE: 0.00153,  MAPE: 0.72%\n",
      "[1000 Epochs]    RMSE:0.00204,   MAE: 0.00196,  MAPE: 0.93%\n",
      "[1100 Epochs]    RMSE:0.00086,   MAE: 0.00080,  MAPE: 0.38%\n",
      "[1200 Epochs]    RMSE:0.00149,   MAE: 0.00141,  MAPE: 0.67%\n",
      "[1300 Epochs]    RMSE:0.00095,   MAE: 0.00087,  MAPE: 0.42%\n",
      "[1400 Epochs]    RMSE:0.00237,   MAE: 0.00225,  MAPE: 1.06%\n",
      "[1500 Epochs]    RMSE:0.00201,   MAE: 0.00191,  MAPE: 0.90%\n",
      "[1600 Epochs]    RMSE:0.00122,   MAE: 0.00106,  MAPE: 0.49%\n",
      "[1700 Epochs]    RMSE:0.00120,   MAE: 0.00113,  MAPE: 0.54%\n",
      "[1800 Epochs]    RMSE:0.00227,   MAE: 0.00223,  MAPE: 1.08%\n",
      "[1900 Epochs]    RMSE:0.00086,   MAE: 0.00079,  MAPE: 0.37%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00388,   MAE: 0.00368,  MAPE: 1.73%\n",
      "\n",
      "\n",
      "Trial No.77\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.13307,   MAE: 0.12704,  MAPE: 60.56%\n",
      "[100 Epochs]    RMSE:0.00335,   MAE: 0.00298,  MAPE: 1.42%\n",
      "[200 Epochs]    RMSE:0.00240,   MAE: 0.00185,  MAPE: 0.92%\n",
      "[300 Epochs]    RMSE:0.00235,   MAE: 0.00202,  MAPE: 0.96%\n",
      "[400 Epochs]    RMSE:0.00177,   MAE: 0.00169,  MAPE: 0.81%\n",
      "[500 Epochs]    RMSE:0.00111,   MAE: 0.00088,  MAPE: 0.41%\n",
      "[600 Epochs]    RMSE:0.00246,   MAE: 0.00214,  MAPE: 0.99%\n",
      "[700 Epochs]    RMSE:0.00344,   MAE: 0.00328,  MAPE: 1.60%\n",
      "[800 Epochs]    RMSE:0.00178,   MAE: 0.00159,  MAPE: 0.74%\n",
      "[900 Epochs]    RMSE:0.00612,   MAE: 0.00602,  MAPE: 2.86%\n",
      "[1000 Epochs]    RMSE:0.00234,   MAE: 0.00228,  MAPE: 1.09%\n",
      "[1100 Epochs]    RMSE:0.00202,   MAE: 0.00177,  MAPE: 0.85%\n",
      "[1200 Epochs]    RMSE:0.00114,   MAE: 0.00083,  MAPE: 0.39%\n",
      "[1300 Epochs]    RMSE:0.00334,   MAE: 0.00316,  MAPE: 1.54%\n",
      "[1400 Epochs]    RMSE:0.00124,   MAE: 0.00113,  MAPE: 0.55%\n",
      "[1500 Epochs]    RMSE:0.00063,   MAE: 0.00053,  MAPE: 0.25%\n",
      "[1600 Epochs]    RMSE:0.00077,   MAE: 0.00058,  MAPE: 0.28%\n",
      "[1700 Epochs]    RMSE:0.00122,   MAE: 0.00115,  MAPE: 0.54%\n",
      "[1800 Epochs]    RMSE:0.00106,   MAE: 0.00071,  MAPE: 0.35%\n",
      "[1900 Epochs]    RMSE:0.00296,   MAE: 0.00287,  MAPE: 1.36%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00096,   MAE: 0.00085,  MAPE: 0.41%\n",
      "\n",
      "\n",
      "Trial No.78\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.11972,   MAE: 0.11063,  MAPE: 53.92%\n",
      "[100 Epochs]    RMSE:0.00293,   MAE: 0.00240,  MAPE: 1.16%\n",
      "[200 Epochs]    RMSE:0.00507,   MAE: 0.00459,  MAPE: 2.16%\n",
      "[300 Epochs]    RMSE:0.00554,   MAE: 0.00534,  MAPE: 2.55%\n",
      "[400 Epochs]    RMSE:0.00202,   MAE: 0.00185,  MAPE: 0.90%\n",
      "[500 Epochs]    RMSE:0.00145,   MAE: 0.00104,  MAPE: 0.49%\n",
      "[600 Epochs]    RMSE:0.00902,   MAE: 0.00889,  MAPE: 4.22%\n",
      "[700 Epochs]    RMSE:0.00419,   MAE: 0.00416,  MAPE: 1.98%\n",
      "[800 Epochs]    RMSE:0.00172,   MAE: 0.00162,  MAPE: 0.77%\n",
      "[900 Epochs]    RMSE:0.00283,   MAE: 0.00264,  MAPE: 1.25%\n",
      "[1000 Epochs]    RMSE:0.00365,   MAE: 0.00359,  MAPE: 1.71%\n",
      "[1100 Epochs]    RMSE:0.00575,   MAE: 0.00570,  MAPE: 2.72%\n",
      "[1200 Epochs]    RMSE:0.00056,   MAE: 0.00047,  MAPE: 0.23%\n",
      "[1300 Epochs]    RMSE:0.00148,   MAE: 0.00144,  MAPE: 0.69%\n",
      "[1400 Epochs]    RMSE:0.00093,   MAE: 0.00089,  MAPE: 0.42%\n",
      "[1500 Epochs]    RMSE:0.00069,   MAE: 0.00061,  MAPE: 0.29%\n",
      "[1600 Epochs]    RMSE:0.00340,   MAE: 0.00331,  MAPE: 1.57%\n",
      "[1700 Epochs]    RMSE:0.00061,   MAE: 0.00055,  MAPE: 0.26%\n",
      "[1800 Epochs]    RMSE:0.00082,   MAE: 0.00078,  MAPE: 0.37%\n",
      "[1900 Epochs]    RMSE:0.00068,   MAE: 0.00052,  MAPE: 0.24%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00080,   MAE: 0.00078,  MAPE: 0.37%\n",
      "\n",
      "\n",
      "Trial No.79\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.26244,   MAE: 0.26009,  MAPE: 124.09%\n",
      "[100 Epochs]    RMSE:0.00435,   MAE: 0.00300,  MAPE: 1.46%\n",
      "[200 Epochs]    RMSE:0.00340,   MAE: 0.00311,  MAPE: 1.50%\n",
      "[300 Epochs]    RMSE:0.00262,   MAE: 0.00224,  MAPE: 1.08%\n",
      "[400 Epochs]    RMSE:0.00580,   MAE: 0.00570,  MAPE: 2.71%\n",
      "[500 Epochs]    RMSE:0.00284,   MAE: 0.00268,  MAPE: 1.27%\n",
      "[600 Epochs]    RMSE:0.00266,   MAE: 0.00256,  MAPE: 1.21%\n",
      "[700 Epochs]    RMSE:0.00170,   MAE: 0.00153,  MAPE: 0.74%\n",
      "[800 Epochs]    RMSE:0.00306,   MAE: 0.00301,  MAPE: 1.43%\n",
      "[900 Epochs]    RMSE:0.00047,   MAE: 0.00040,  MAPE: 0.19%\n",
      "[1000 Epochs]    RMSE:0.00131,   MAE: 0.00108,  MAPE: 0.50%\n",
      "[1100 Epochs]    RMSE:0.00517,   MAE: 0.00511,  MAPE: 2.43%\n",
      "[1200 Epochs]    RMSE:0.00218,   MAE: 0.00211,  MAPE: 1.01%\n",
      "[1300 Epochs]    RMSE:0.00145,   MAE: 0.00141,  MAPE: 0.67%\n",
      "[1400 Epochs]    RMSE:0.00141,   MAE: 0.00128,  MAPE: 0.62%\n",
      "[1500 Epochs]    RMSE:0.00090,   MAE: 0.00080,  MAPE: 0.38%\n",
      "[1600 Epochs]    RMSE:0.00278,   MAE: 0.00273,  MAPE: 1.31%\n",
      "[1700 Epochs]    RMSE:0.00139,   MAE: 0.00135,  MAPE: 0.64%\n",
      "[1800 Epochs]    RMSE:0.00134,   MAE: 0.00126,  MAPE: 0.59%\n",
      "[1900 Epochs]    RMSE:0.00260,   MAE: 0.00259,  MAPE: 1.24%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00178,   MAE: 0.00173,  MAPE: 0.84%\n",
      "\n",
      "\n",
      "Trial No.80\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.37428,   MAE: 0.36303,  MAPE: 172.54%\n",
      "[100 Epochs]    RMSE:0.00535,   MAE: 0.00469,  MAPE: 2.27%\n",
      "[200 Epochs]    RMSE:0.00432,   MAE: 0.00375,  MAPE: 1.83%\n",
      "[300 Epochs]    RMSE:0.00146,   MAE: 0.00126,  MAPE: 0.61%\n",
      "[400 Epochs]    RMSE:0.00110,   MAE: 0.00093,  MAPE: 0.45%\n",
      "[500 Epochs]    RMSE:0.00254,   MAE: 0.00213,  MAPE: 1.00%\n",
      "[600 Epochs]    RMSE:0.00097,   MAE: 0.00086,  MAPE: 0.41%\n",
      "[700 Epochs]    RMSE:0.00126,   MAE: 0.00115,  MAPE: 0.55%\n",
      "[800 Epochs]    RMSE:0.00598,   MAE: 0.00589,  MAPE: 2.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900 Epochs]    RMSE:0.00388,   MAE: 0.00385,  MAPE: 1.83%\n",
      "[1000 Epochs]    RMSE:0.00142,   MAE: 0.00136,  MAPE: 0.65%\n",
      "[1100 Epochs]    RMSE:0.00175,   MAE: 0.00159,  MAPE: 0.75%\n",
      "[1200 Epochs]    RMSE:0.00180,   MAE: 0.00168,  MAPE: 0.82%\n",
      "[1300 Epochs]    RMSE:0.00116,   MAE: 0.00104,  MAPE: 0.51%\n",
      "[1400 Epochs]    RMSE:0.00127,   MAE: 0.00110,  MAPE: 0.54%\n",
      "[1500 Epochs]    RMSE:0.00048,   MAE: 0.00042,  MAPE: 0.20%\n",
      "[1600 Epochs]    RMSE:0.00307,   MAE: 0.00291,  MAPE: 1.37%\n",
      "[1700 Epochs]    RMSE:0.00171,   MAE: 0.00162,  MAPE: 0.77%\n",
      "[1800 Epochs]    RMSE:0.00084,   MAE: 0.00075,  MAPE: 0.35%\n",
      "[1900 Epochs]    RMSE:0.00212,   MAE: 0.00193,  MAPE: 0.93%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00202,   MAE: 0.00199,  MAPE: 0.95%\n",
      "\n",
      "\n",
      "Trial No.81\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.09855,   MAE: 0.08370,  MAPE: 41.01%\n",
      "[100 Epochs]    RMSE:0.00289,   MAE: 0.00241,  MAPE: 1.12%\n",
      "[200 Epochs]    RMSE:0.00989,   MAE: 0.00940,  MAPE: 4.44%\n",
      "[300 Epochs]    RMSE:0.00671,   MAE: 0.00658,  MAPE: 3.15%\n",
      "[400 Epochs]    RMSE:0.00191,   MAE: 0.00169,  MAPE: 0.83%\n",
      "[500 Epochs]    RMSE:0.00265,   MAE: 0.00255,  MAPE: 1.21%\n",
      "[600 Epochs]    RMSE:0.00248,   MAE: 0.00232,  MAPE: 1.11%\n",
      "[700 Epochs]    RMSE:0.00462,   MAE: 0.00458,  MAPE: 2.18%\n",
      "[800 Epochs]    RMSE:0.00109,   MAE: 0.00099,  MAPE: 0.47%\n",
      "[900 Epochs]    RMSE:0.00167,   MAE: 0.00139,  MAPE: 0.65%\n",
      "[1000 Epochs]    RMSE:0.00068,   MAE: 0.00060,  MAPE: 0.28%\n",
      "[1100 Epochs]    RMSE:0.00269,   MAE: 0.00259,  MAPE: 1.22%\n",
      "[1200 Epochs]    RMSE:0.00104,   MAE: 0.00101,  MAPE: 0.48%\n",
      "[1300 Epochs]    RMSE:0.00196,   MAE: 0.00161,  MAPE: 0.75%\n",
      "[1400 Epochs]    RMSE:0.00307,   MAE: 0.00303,  MAPE: 1.44%\n",
      "[1500 Epochs]    RMSE:0.00774,   MAE: 0.00763,  MAPE: 3.62%\n",
      "[1600 Epochs]    RMSE:0.00160,   MAE: 0.00144,  MAPE: 0.68%\n",
      "[1700 Epochs]    RMSE:0.00309,   MAE: 0.00299,  MAPE: 1.42%\n",
      "[1800 Epochs]    RMSE:0.00200,   MAE: 0.00196,  MAPE: 0.93%\n",
      "[1900 Epochs]    RMSE:0.00229,   MAE: 0.00221,  MAPE: 1.05%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00089,   MAE: 0.00080,  MAPE: 0.38%\n",
      "\n",
      "\n",
      "Trial No.82\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.08631,   MAE: 0.07052,  MAPE: 34.18%\n",
      "[100 Epochs]    RMSE:0.00438,   MAE: 0.00414,  MAPE: 1.99%\n",
      "[200 Epochs]    RMSE:0.00730,   MAE: 0.00710,  MAPE: 3.37%\n",
      "[300 Epochs]    RMSE:0.00451,   MAE: 0.00443,  MAPE: 2.13%\n",
      "[400 Epochs]    RMSE:0.00115,   MAE: 0.00098,  MAPE: 0.47%\n",
      "[500 Epochs]    RMSE:0.00236,   MAE: 0.00226,  MAPE: 1.08%\n",
      "[600 Epochs]    RMSE:0.00098,   MAE: 0.00081,  MAPE: 0.39%\n",
      "[700 Epochs]    RMSE:0.00152,   MAE: 0.00135,  MAPE: 0.65%\n",
      "[800 Epochs]    RMSE:0.00202,   MAE: 0.00169,  MAPE: 0.82%\n",
      "[900 Epochs]    RMSE:0.00196,   MAE: 0.00188,  MAPE: 0.91%\n",
      "[1000 Epochs]    RMSE:0.00164,   MAE: 0.00127,  MAPE: 0.59%\n",
      "[1100 Epochs]    RMSE:0.00122,   MAE: 0.00104,  MAPE: 0.51%\n",
      "[1200 Epochs]    RMSE:0.00474,   MAE: 0.00459,  MAPE: 2.17%\n",
      "[1300 Epochs]    RMSE:0.00151,   MAE: 0.00143,  MAPE: 0.68%\n",
      "[1400 Epochs]    RMSE:0.00154,   MAE: 0.00142,  MAPE: 0.70%\n",
      "[1500 Epochs]    RMSE:0.00276,   MAE: 0.00269,  MAPE: 1.28%\n",
      "[1600 Epochs]    RMSE:0.00119,   MAE: 0.00111,  MAPE: 0.53%\n",
      "[1700 Epochs]    RMSE:0.00330,   MAE: 0.00325,  MAPE: 1.54%\n",
      "[1800 Epochs]    RMSE:0.00310,   MAE: 0.00307,  MAPE: 1.47%\n",
      "[1900 Epochs]    RMSE:0.00442,   MAE: 0.00440,  MAPE: 2.10%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00248,   MAE: 0.00245,  MAPE: 1.17%\n",
      "\n",
      "\n",
      "Trial No.83\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.21272,   MAE: 0.21154,  MAPE: 100.82%\n",
      "[100 Epochs]    RMSE:0.01054,   MAE: 0.01013,  MAPE: 4.80%\n",
      "[200 Epochs]    RMSE:0.01011,   MAE: 0.01004,  MAPE: 4.81%\n",
      "[300 Epochs]    RMSE:0.00336,   MAE: 0.00325,  MAPE: 1.57%\n",
      "[400 Epochs]    RMSE:0.00158,   MAE: 0.00134,  MAPE: 0.63%\n",
      "[500 Epochs]    RMSE:0.00767,   MAE: 0.00763,  MAPE: 3.64%\n",
      "[600 Epochs]    RMSE:0.00238,   MAE: 0.00208,  MAPE: 0.96%\n",
      "[700 Epochs]    RMSE:0.00195,   MAE: 0.00184,  MAPE: 0.87%\n",
      "[800 Epochs]    RMSE:0.00176,   MAE: 0.00169,  MAPE: 0.82%\n",
      "[900 Epochs]    RMSE:0.00277,   MAE: 0.00267,  MAPE: 1.29%\n",
      "[1000 Epochs]    RMSE:0.00184,   MAE: 0.00180,  MAPE: 0.87%\n",
      "[1100 Epochs]    RMSE:0.00199,   MAE: 0.00185,  MAPE: 0.88%\n",
      "[1200 Epochs]    RMSE:0.00553,   MAE: 0.00552,  MAPE: 2.64%\n",
      "[1300 Epochs]    RMSE:0.00229,   MAE: 0.00222,  MAPE: 1.07%\n",
      "[1400 Epochs]    RMSE:0.00365,   MAE: 0.00347,  MAPE: 1.63%\n",
      "[1500 Epochs]    RMSE:0.00295,   MAE: 0.00279,  MAPE: 1.31%\n",
      "[1600 Epochs]    RMSE:0.00111,   MAE: 0.00102,  MAPE: 0.50%\n",
      "[1700 Epochs]    RMSE:0.00346,   MAE: 0.00330,  MAPE: 1.55%\n",
      "[1800 Epochs]    RMSE:0.00237,   MAE: 0.00211,  MAPE: 1.04%\n",
      "[1900 Epochs]    RMSE:0.00143,   MAE: 0.00125,  MAPE: 0.62%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00206,   MAE: 0.00202,  MAPE: 0.97%\n",
      "\n",
      "\n",
      "Trial No.84\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.15902,   MAE: 0.14463,  MAPE: 68.43%\n",
      "[100 Epochs]    RMSE:0.00451,   MAE: 0.00377,  MAPE: 1.80%\n",
      "[200 Epochs]    RMSE:0.00228,   MAE: 0.00190,  MAPE: 0.88%\n",
      "[300 Epochs]    RMSE:0.00364,   MAE: 0.00342,  MAPE: 1.64%\n",
      "[400 Epochs]    RMSE:0.00157,   MAE: 0.00137,  MAPE: 0.66%\n",
      "[500 Epochs]    RMSE:0.00301,   MAE: 0.00266,  MAPE: 1.27%\n",
      "[600 Epochs]    RMSE:0.00221,   MAE: 0.00202,  MAPE: 0.95%\n",
      "[700 Epochs]    RMSE:0.00188,   MAE: 0.00161,  MAPE: 0.79%\n",
      "[800 Epochs]    RMSE:0.00291,   MAE: 0.00287,  MAPE: 1.38%\n",
      "[900 Epochs]    RMSE:0.00192,   MAE: 0.00184,  MAPE: 0.88%\n",
      "[1000 Epochs]    RMSE:0.00216,   MAE: 0.00211,  MAPE: 1.01%\n",
      "[1100 Epochs]    RMSE:0.00341,   MAE: 0.00337,  MAPE: 1.61%\n",
      "[1200 Epochs]    RMSE:0.00115,   MAE: 0.00105,  MAPE: 0.50%\n",
      "[1300 Epochs]    RMSE:0.00179,   MAE: 0.00169,  MAPE: 0.80%\n",
      "[1400 Epochs]    RMSE:0.00121,   MAE: 0.00107,  MAPE: 0.52%\n",
      "[1500 Epochs]    RMSE:0.00158,   MAE: 0.00153,  MAPE: 0.73%\n",
      "[1600 Epochs]    RMSE:0.00195,   MAE: 0.00191,  MAPE: 0.92%\n",
      "[1700 Epochs]    RMSE:0.00378,   MAE: 0.00370,  MAPE: 1.75%\n",
      "[1800 Epochs]    RMSE:0.00096,   MAE: 0.00082,  MAPE: 0.38%\n",
      "[1900 Epochs]    RMSE:0.00232,   MAE: 0.00222,  MAPE: 1.05%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00125,   MAE: 0.00102,  MAPE: 0.51%\n",
      "\n",
      "\n",
      "Trial No.85\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.23287,   MAE: 0.22221,  MAPE: 107.31%\n",
      "[100 Epochs]    RMSE:0.01115,   MAE: 0.01070,  MAPE: 5.14%\n",
      "[200 Epochs]    RMSE:0.00480,   MAE: 0.00438,  MAPE: 2.11%\n",
      "[300 Epochs]    RMSE:0.00270,   MAE: 0.00250,  MAPE: 1.19%\n",
      "[400 Epochs]    RMSE:0.00142,   MAE: 0.00122,  MAPE: 0.57%\n",
      "[500 Epochs]    RMSE:0.00268,   MAE: 0.00250,  MAPE: 1.18%\n",
      "[600 Epochs]    RMSE:0.00818,   MAE: 0.00810,  MAPE: 3.87%\n",
      "[700 Epochs]    RMSE:0.00082,   MAE: 0.00063,  MAPE: 0.30%\n",
      "[800 Epochs]    RMSE:0.00355,   MAE: 0.00330,  MAPE: 1.61%\n",
      "[900 Epochs]    RMSE:0.00181,   MAE: 0.00171,  MAPE: 0.83%\n",
      "[1000 Epochs]    RMSE:0.00275,   MAE: 0.00267,  MAPE: 1.27%\n",
      "[1100 Epochs]    RMSE:0.00521,   MAE: 0.00514,  MAPE: 2.45%\n",
      "[1200 Epochs]    RMSE:0.00456,   MAE: 0.00441,  MAPE: 2.08%\n",
      "[1300 Epochs]    RMSE:0.00231,   MAE: 0.00211,  MAPE: 0.99%\n",
      "[1400 Epochs]    RMSE:0.00346,   MAE: 0.00333,  MAPE: 1.57%\n",
      "[1500 Epochs]    RMSE:0.00123,   MAE: 0.00108,  MAPE: 0.54%\n",
      "[1600 Epochs]    RMSE:0.00072,   MAE: 0.00062,  MAPE: 0.29%\n",
      "[1700 Epochs]    RMSE:0.00161,   MAE: 0.00158,  MAPE: 0.76%\n",
      "[1800 Epochs]    RMSE:0.00125,   MAE: 0.00116,  MAPE: 0.57%\n",
      "[1900 Epochs]    RMSE:0.00154,   MAE: 0.00149,  MAPE: 0.72%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00095,   MAE: 0.00085,  MAPE: 0.40%\n",
      "\n",
      "\n",
      "Trial No.86\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.31759,   MAE: 0.31371,  MAPE: 149.44%\n",
      "[100 Epochs]    RMSE:0.00264,   MAE: 0.00229,  MAPE: 1.09%\n",
      "[200 Epochs]    RMSE:0.00268,   MAE: 0.00237,  MAPE: 1.13%\n",
      "[300 Epochs]    RMSE:0.00132,   MAE: 0.00102,  MAPE: 0.49%\n",
      "[400 Epochs]    RMSE:0.00229,   MAE: 0.00211,  MAPE: 1.01%\n",
      "[500 Epochs]    RMSE:0.00334,   MAE: 0.00314,  MAPE: 1.49%\n",
      "[600 Epochs]    RMSE:0.00357,   MAE: 0.00350,  MAPE: 1.69%\n",
      "[700 Epochs]    RMSE:0.00179,   MAE: 0.00174,  MAPE: 0.84%\n",
      "[800 Epochs]    RMSE:0.00366,   MAE: 0.00354,  MAPE: 1.68%\n",
      "[900 Epochs]    RMSE:0.00192,   MAE: 0.00188,  MAPE: 0.90%\n",
      "[1000 Epochs]    RMSE:0.00098,   MAE: 0.00085,  MAPE: 0.40%\n",
      "[1100 Epochs]    RMSE:0.00181,   MAE: 0.00177,  MAPE: 0.84%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200 Epochs]    RMSE:0.00099,   MAE: 0.00088,  MAPE: 0.41%\n",
      "[1300 Epochs]    RMSE:0.00080,   MAE: 0.00068,  MAPE: 0.32%\n",
      "[1400 Epochs]    RMSE:0.00152,   MAE: 0.00150,  MAPE: 0.72%\n",
      "[1500 Epochs]    RMSE:0.00060,   MAE: 0.00052,  MAPE: 0.26%\n",
      "[1600 Epochs]    RMSE:0.00327,   MAE: 0.00323,  MAPE: 1.54%\n",
      "[1700 Epochs]    RMSE:0.00110,   MAE: 0.00093,  MAPE: 0.45%\n",
      "[1800 Epochs]    RMSE:0.00093,   MAE: 0.00090,  MAPE: 0.43%\n",
      "[1900 Epochs]    RMSE:0.00076,   MAE: 0.00062,  MAPE: 0.30%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00167,   MAE: 0.00163,  MAPE: 0.78%\n",
      "\n",
      "\n",
      "Trial No.87\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.23595,   MAE: 0.23125,  MAPE: 109.74%\n",
      "[100 Epochs]    RMSE:0.00920,   MAE: 0.00866,  MAPE: 4.13%\n",
      "[200 Epochs]    RMSE:0.00153,   MAE: 0.00109,  MAPE: 0.53%\n",
      "[300 Epochs]    RMSE:0.00435,   MAE: 0.00423,  MAPE: 2.03%\n",
      "[400 Epochs]    RMSE:0.00324,   MAE: 0.00280,  MAPE: 1.38%\n",
      "[500 Epochs]    RMSE:0.00226,   MAE: 0.00219,  MAPE: 1.04%\n",
      "[600 Epochs]    RMSE:0.00130,   MAE: 0.00112,  MAPE: 0.53%\n",
      "[700 Epochs]    RMSE:0.00090,   MAE: 0.00083,  MAPE: 0.40%\n",
      "[800 Epochs]    RMSE:0.00259,   MAE: 0.00256,  MAPE: 1.22%\n",
      "[900 Epochs]    RMSE:0.00359,   MAE: 0.00357,  MAPE: 1.71%\n",
      "[1000 Epochs]    RMSE:0.00104,   MAE: 0.00090,  MAPE: 0.42%\n",
      "[1100 Epochs]    RMSE:0.00258,   MAE: 0.00245,  MAPE: 1.16%\n",
      "[1200 Epochs]    RMSE:0.00183,   MAE: 0.00175,  MAPE: 0.83%\n",
      "[1300 Epochs]    RMSE:0.00118,   MAE: 0.00110,  MAPE: 0.53%\n",
      "[1400 Epochs]    RMSE:0.00079,   MAE: 0.00066,  MAPE: 0.31%\n",
      "[1500 Epochs]    RMSE:0.00256,   MAE: 0.00238,  MAPE: 1.11%\n",
      "[1600 Epochs]    RMSE:0.00037,   MAE: 0.00029,  MAPE: 0.14%\n",
      "[1700 Epochs]    RMSE:0.00435,   MAE: 0.00430,  MAPE: 2.04%\n",
      "[1800 Epochs]    RMSE:0.00135,   MAE: 0.00116,  MAPE: 0.58%\n",
      "[1900 Epochs]    RMSE:0.00199,   MAE: 0.00180,  MAPE: 0.84%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00118,   MAE: 0.00100,  MAPE: 0.47%\n",
      "\n",
      "\n",
      "Trial No.88\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.37578,   MAE: 0.36962,  MAPE: 176.34%\n",
      "[100 Epochs]    RMSE:0.01136,   MAE: 0.01129,  MAPE: 5.41%\n",
      "[200 Epochs]    RMSE:0.00265,   MAE: 0.00249,  MAPE: 1.18%\n",
      "[300 Epochs]    RMSE:0.00333,   MAE: 0.00293,  MAPE: 1.36%\n",
      "[400 Epochs]    RMSE:0.00320,   MAE: 0.00313,  MAPE: 1.50%\n",
      "[500 Epochs]    RMSE:0.00086,   MAE: 0.00075,  MAPE: 0.36%\n",
      "[600 Epochs]    RMSE:0.00489,   MAE: 0.00478,  MAPE: 2.27%\n",
      "[700 Epochs]    RMSE:0.00100,   MAE: 0.00081,  MAPE: 0.38%\n",
      "[800 Epochs]    RMSE:0.00134,   MAE: 0.00120,  MAPE: 0.56%\n",
      "[900 Epochs]    RMSE:0.00212,   MAE: 0.00206,  MAPE: 0.98%\n",
      "[1000 Epochs]    RMSE:0.00134,   MAE: 0.00124,  MAPE: 0.59%\n",
      "[1100 Epochs]    RMSE:0.00178,   MAE: 0.00166,  MAPE: 0.81%\n",
      "[1200 Epochs]    RMSE:0.00047,   MAE: 0.00043,  MAPE: 0.21%\n",
      "[1300 Epochs]    RMSE:0.00021,   MAE: 0.00017,  MAPE: 0.08%\n",
      "[1400 Epochs]    RMSE:0.00201,   MAE: 0.00174,  MAPE: 0.81%\n",
      "[1500 Epochs]    RMSE:0.00196,   MAE: 0.00193,  MAPE: 0.92%\n",
      "[1600 Epochs]    RMSE:0.00144,   MAE: 0.00120,  MAPE: 0.60%\n",
      "[1700 Epochs]    RMSE:0.00203,   MAE: 0.00201,  MAPE: 0.96%\n",
      "[1800 Epochs]    RMSE:0.00169,   MAE: 0.00155,  MAPE: 0.72%\n",
      "[1900 Epochs]    RMSE:0.00298,   MAE: 0.00289,  MAPE: 1.37%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00146,   MAE: 0.00140,  MAPE: 0.67%\n",
      "\n",
      "\n",
      "Trial No.89\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.19302,   MAE: 0.19148,  MAPE: 91.48%\n",
      "[100 Epochs]    RMSE:0.00272,   MAE: 0.00244,  MAPE: 1.19%\n",
      "[200 Epochs]    RMSE:0.00425,   MAE: 0.00401,  MAPE: 1.91%\n",
      "[300 Epochs]    RMSE:0.00172,   MAE: 0.00115,  MAPE: 0.57%\n",
      "[400 Epochs]    RMSE:0.00441,   MAE: 0.00415,  MAPE: 1.95%\n",
      "[500 Epochs]    RMSE:0.00213,   MAE: 0.00198,  MAPE: 0.95%\n",
      "[600 Epochs]    RMSE:0.00242,   MAE: 0.00224,  MAPE: 1.06%\n",
      "[700 Epochs]    RMSE:0.00533,   MAE: 0.00509,  MAPE: 2.42%\n",
      "[800 Epochs]    RMSE:0.00056,   MAE: 0.00047,  MAPE: 0.22%\n",
      "[900 Epochs]    RMSE:0.00456,   MAE: 0.00452,  MAPE: 2.16%\n",
      "[1000 Epochs]    RMSE:0.00170,   MAE: 0.00163,  MAPE: 0.78%\n",
      "[1100 Epochs]    RMSE:0.00234,   MAE: 0.00225,  MAPE: 1.07%\n",
      "[1200 Epochs]    RMSE:0.00743,   MAE: 0.00730,  MAPE: 3.46%\n",
      "[1300 Epochs]    RMSE:0.00094,   MAE: 0.00070,  MAPE: 0.33%\n",
      "[1400 Epochs]    RMSE:0.00291,   MAE: 0.00283,  MAPE: 1.34%\n",
      "[1500 Epochs]    RMSE:0.00232,   MAE: 0.00227,  MAPE: 1.08%\n",
      "[1600 Epochs]    RMSE:0.00120,   MAE: 0.00101,  MAPE: 0.50%\n",
      "[1700 Epochs]    RMSE:0.00116,   MAE: 0.00110,  MAPE: 0.52%\n",
      "[1800 Epochs]    RMSE:0.00066,   MAE: 0.00060,  MAPE: 0.29%\n",
      "[1900 Epochs]    RMSE:0.00257,   MAE: 0.00254,  MAPE: 1.22%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00118,   MAE: 0.00100,  MAPE: 0.47%\n",
      "\n",
      "\n",
      "Trial No.90\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.30291,   MAE: 0.29728,  MAPE: 141.73%\n",
      "[100 Epochs]    RMSE:0.01093,   MAE: 0.01060,  MAPE: 5.02%\n",
      "[200 Epochs]    RMSE:0.00505,   MAE: 0.00432,  MAPE: 2.00%\n",
      "[300 Epochs]    RMSE:0.00748,   MAE: 0.00738,  MAPE: 3.51%\n",
      "[400 Epochs]    RMSE:0.00279,   MAE: 0.00254,  MAPE: 1.19%\n",
      "[500 Epochs]    RMSE:0.00095,   MAE: 0.00070,  MAPE: 0.35%\n",
      "[600 Epochs]    RMSE:0.00142,   MAE: 0.00124,  MAPE: 0.61%\n",
      "[700 Epochs]    RMSE:0.00052,   MAE: 0.00038,  MAPE: 0.18%\n",
      "[800 Epochs]    RMSE:0.00293,   MAE: 0.00290,  MAPE: 1.39%\n",
      "[900 Epochs]    RMSE:0.00303,   MAE: 0.00298,  MAPE: 1.41%\n",
      "[1000 Epochs]    RMSE:0.00133,   MAE: 0.00122,  MAPE: 0.57%\n",
      "[1100 Epochs]    RMSE:0.00112,   MAE: 0.00098,  MAPE: 0.46%\n",
      "[1200 Epochs]    RMSE:0.00187,   MAE: 0.00177,  MAPE: 0.83%\n",
      "[1300 Epochs]    RMSE:0.00271,   MAE: 0.00269,  MAPE: 1.29%\n",
      "[1400 Epochs]    RMSE:0.00089,   MAE: 0.00082,  MAPE: 0.38%\n",
      "[1500 Epochs]    RMSE:0.00217,   MAE: 0.00206,  MAPE: 1.01%\n",
      "[1600 Epochs]    RMSE:0.00396,   MAE: 0.00394,  MAPE: 1.88%\n",
      "[1700 Epochs]    RMSE:0.00042,   MAE: 0.00034,  MAPE: 0.17%\n",
      "[1800 Epochs]    RMSE:0.00252,   MAE: 0.00250,  MAPE: 1.20%\n",
      "[1900 Epochs]    RMSE:0.00148,   MAE: 0.00145,  MAPE: 0.69%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00284,   MAE: 0.00276,  MAPE: 1.31%\n",
      "\n",
      "\n",
      "Trial No.91\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.25096,   MAE: 0.24815,  MAPE: 118.08%\n",
      "[100 Epochs]    RMSE:0.00346,   MAE: 0.00304,  MAPE: 1.45%\n",
      "[200 Epochs]    RMSE:0.00080,   MAE: 0.00068,  MAPE: 0.32%\n",
      "[300 Epochs]    RMSE:0.00183,   MAE: 0.00164,  MAPE: 0.76%\n",
      "[400 Epochs]    RMSE:0.00235,   MAE: 0.00230,  MAPE: 1.10%\n",
      "[500 Epochs]    RMSE:0.00088,   MAE: 0.00073,  MAPE: 0.36%\n",
      "[600 Epochs]    RMSE:0.00151,   MAE: 0.00143,  MAPE: 0.69%\n",
      "[700 Epochs]    RMSE:0.00286,   MAE: 0.00259,  MAPE: 1.21%\n",
      "[800 Epochs]    RMSE:0.00178,   MAE: 0.00167,  MAPE: 0.79%\n",
      "[900 Epochs]    RMSE:0.00242,   MAE: 0.00234,  MAPE: 1.11%\n",
      "[1000 Epochs]    RMSE:0.00458,   MAE: 0.00455,  MAPE: 2.18%\n",
      "[1100 Epochs]    RMSE:0.00219,   MAE: 0.00210,  MAPE: 1.01%\n",
      "[1200 Epochs]    RMSE:0.00162,   MAE: 0.00155,  MAPE: 0.73%\n",
      "[1300 Epochs]    RMSE:0.00175,   MAE: 0.00162,  MAPE: 0.79%\n",
      "[1400 Epochs]    RMSE:0.00161,   MAE: 0.00152,  MAPE: 0.74%\n",
      "[1500 Epochs]    RMSE:0.00106,   MAE: 0.00081,  MAPE: 0.39%\n",
      "[1600 Epochs]    RMSE:0.00147,   MAE: 0.00143,  MAPE: 0.68%\n",
      "[1700 Epochs]    RMSE:0.00139,   MAE: 0.00124,  MAPE: 0.57%\n",
      "[1800 Epochs]    RMSE:0.00077,   MAE: 0.00068,  MAPE: 0.32%\n",
      "[1900 Epochs]    RMSE:0.00259,   MAE: 0.00244,  MAPE: 1.15%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00171,   MAE: 0.00167,  MAPE: 0.81%\n",
      "\n",
      "\n",
      "Trial No.92\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.27088,   MAE: 0.26890,  MAPE: 128.27%\n",
      "[100 Epochs]    RMSE:0.00403,   MAE: 0.00345,  MAPE: 1.66%\n",
      "[200 Epochs]    RMSE:0.00604,   MAE: 0.00550,  MAPE: 2.63%\n",
      "[300 Epochs]    RMSE:0.00158,   MAE: 0.00147,  MAPE: 0.71%\n",
      "[400 Epochs]    RMSE:0.00574,   MAE: 0.00562,  MAPE: 2.69%\n",
      "[500 Epochs]    RMSE:0.00211,   MAE: 0.00180,  MAPE: 0.85%\n",
      "[600 Epochs]    RMSE:0.00101,   MAE: 0.00084,  MAPE: 0.40%\n",
      "[700 Epochs]    RMSE:0.00315,   MAE: 0.00308,  MAPE: 1.46%\n",
      "[800 Epochs]    RMSE:0.00126,   MAE: 0.00111,  MAPE: 0.53%\n",
      "[900 Epochs]    RMSE:0.00189,   MAE: 0.00180,  MAPE: 0.87%\n",
      "[1000 Epochs]    RMSE:0.00108,   MAE: 0.00096,  MAPE: 0.45%\n",
      "[1100 Epochs]    RMSE:0.00045,   MAE: 0.00037,  MAPE: 0.17%\n",
      "[1200 Epochs]    RMSE:0.00249,   MAE: 0.00237,  MAPE: 1.14%\n",
      "[1300 Epochs]    RMSE:0.00083,   MAE: 0.00074,  MAPE: 0.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400 Epochs]    RMSE:0.00089,   MAE: 0.00080,  MAPE: 0.38%\n",
      "[1500 Epochs]    RMSE:0.00064,   MAE: 0.00050,  MAPE: 0.23%\n",
      "[1600 Epochs]    RMSE:0.00198,   MAE: 0.00189,  MAPE: 0.91%\n",
      "[1700 Epochs]    RMSE:0.00076,   MAE: 0.00068,  MAPE: 0.32%\n",
      "[1800 Epochs]    RMSE:0.00141,   MAE: 0.00111,  MAPE: 0.56%\n",
      "[1900 Epochs]    RMSE:0.00144,   MAE: 0.00143,  MAPE: 0.69%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00148,   MAE: 0.00142,  MAPE: 0.69%\n",
      "\n",
      "\n",
      "Trial No.93\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.12100,   MAE: 0.11440,  MAPE: 54.47%\n",
      "[100 Epochs]    RMSE:0.00209,   MAE: 0.00161,  MAPE: 0.76%\n",
      "[200 Epochs]    RMSE:0.00467,   MAE: 0.00431,  MAPE: 2.05%\n",
      "[300 Epochs]    RMSE:0.00081,   MAE: 0.00069,  MAPE: 0.33%\n",
      "[400 Epochs]    RMSE:0.00236,   MAE: 0.00182,  MAPE: 0.88%\n",
      "[500 Epochs]    RMSE:0.00314,   MAE: 0.00309,  MAPE: 1.48%\n",
      "[600 Epochs]    RMSE:0.00631,   MAE: 0.00623,  MAPE: 2.96%\n",
      "[700 Epochs]    RMSE:0.00367,   MAE: 0.00362,  MAPE: 1.73%\n",
      "[800 Epochs]    RMSE:0.00245,   MAE: 0.00231,  MAPE: 1.09%\n",
      "[900 Epochs]    RMSE:0.00219,   MAE: 0.00205,  MAPE: 0.98%\n",
      "[1000 Epochs]    RMSE:0.00121,   MAE: 0.00099,  MAPE: 0.46%\n",
      "[1100 Epochs]    RMSE:0.00289,   MAE: 0.00261,  MAPE: 1.22%\n",
      "[1200 Epochs]    RMSE:0.00177,   MAE: 0.00135,  MAPE: 0.63%\n",
      "[1300 Epochs]    RMSE:0.00091,   MAE: 0.00077,  MAPE: 0.37%\n",
      "[1400 Epochs]    RMSE:0.00128,   MAE: 0.00117,  MAPE: 0.55%\n",
      "[1500 Epochs]    RMSE:0.00058,   MAE: 0.00049,  MAPE: 0.23%\n",
      "[1600 Epochs]    RMSE:0.00067,   MAE: 0.00054,  MAPE: 0.26%\n",
      "[1700 Epochs]    RMSE:0.00180,   MAE: 0.00170,  MAPE: 0.82%\n",
      "[1800 Epochs]    RMSE:0.00132,   MAE: 0.00123,  MAPE: 0.59%\n",
      "[1900 Epochs]    RMSE:0.00131,   MAE: 0.00124,  MAPE: 0.59%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00103,   MAE: 0.00090,  MAPE: 0.42%\n",
      "\n",
      "\n",
      "Trial No.94\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.26597,   MAE: 0.26210,  MAPE: 125.60%\n",
      "[100 Epochs]    RMSE:0.00522,   MAE: 0.00464,  MAPE: 2.22%\n",
      "[200 Epochs]    RMSE:0.00108,   MAE: 0.00085,  MAPE: 0.41%\n",
      "[300 Epochs]    RMSE:0.00296,   MAE: 0.00282,  MAPE: 1.34%\n",
      "[400 Epochs]    RMSE:0.00159,   MAE: 0.00142,  MAPE: 0.68%\n",
      "[500 Epochs]    RMSE:0.00167,   MAE: 0.00136,  MAPE: 0.63%\n",
      "[600 Epochs]    RMSE:0.00279,   MAE: 0.00272,  MAPE: 1.30%\n",
      "[700 Epochs]    RMSE:0.00155,   MAE: 0.00146,  MAPE: 0.70%\n",
      "[800 Epochs]    RMSE:0.00110,   MAE: 0.00098,  MAPE: 0.48%\n",
      "[900 Epochs]    RMSE:0.00235,   MAE: 0.00220,  MAPE: 1.04%\n",
      "[1000 Epochs]    RMSE:0.00399,   MAE: 0.00393,  MAPE: 1.87%\n",
      "[1100 Epochs]    RMSE:0.00281,   MAE: 0.00276,  MAPE: 1.31%\n",
      "[1200 Epochs]    RMSE:0.00057,   MAE: 0.00049,  MAPE: 0.23%\n",
      "[1300 Epochs]    RMSE:0.00355,   MAE: 0.00348,  MAPE: 1.65%\n",
      "[1400 Epochs]    RMSE:0.00342,   MAE: 0.00337,  MAPE: 1.60%\n",
      "[1500 Epochs]    RMSE:0.00360,   MAE: 0.00341,  MAPE: 1.60%\n",
      "[1600 Epochs]    RMSE:0.00119,   MAE: 0.00114,  MAPE: 0.54%\n",
      "[1700 Epochs]    RMSE:0.00278,   MAE: 0.00259,  MAPE: 1.22%\n",
      "[1800 Epochs]    RMSE:0.00051,   MAE: 0.00043,  MAPE: 0.20%\n",
      "[1900 Epochs]    RMSE:0.00162,   MAE: 0.00141,  MAPE: 0.66%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00043,   MAE: 0.00034,  MAPE: 0.16%\n",
      "\n",
      "\n",
      "Trial No.95\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.15436,   MAE: 0.14815,  MAPE: 70.79%\n",
      "[100 Epochs]    RMSE:0.00206,   MAE: 0.00171,  MAPE: 0.82%\n",
      "[200 Epochs]    RMSE:0.00112,   MAE: 0.00083,  MAPE: 0.41%\n",
      "[300 Epochs]    RMSE:0.00114,   MAE: 0.00081,  MAPE: 0.39%\n",
      "[400 Epochs]    RMSE:0.00116,   MAE: 0.00095,  MAPE: 0.44%\n",
      "[500 Epochs]    RMSE:0.00307,   MAE: 0.00282,  MAPE: 1.38%\n",
      "[600 Epochs]    RMSE:0.00372,   MAE: 0.00356,  MAPE: 1.68%\n",
      "[700 Epochs]    RMSE:0.00248,   MAE: 0.00243,  MAPE: 1.17%\n",
      "[800 Epochs]    RMSE:0.00170,   MAE: 0.00164,  MAPE: 0.79%\n",
      "[900 Epochs]    RMSE:0.00356,   MAE: 0.00349,  MAPE: 1.66%\n",
      "[1000 Epochs]    RMSE:0.00351,   MAE: 0.00346,  MAPE: 1.65%\n",
      "[1100 Epochs]    RMSE:0.00261,   MAE: 0.00252,  MAPE: 1.19%\n",
      "[1200 Epochs]    RMSE:0.00087,   MAE: 0.00079,  MAPE: 0.39%\n",
      "[1300 Epochs]    RMSE:0.00224,   MAE: 0.00199,  MAPE: 0.94%\n",
      "[1400 Epochs]    RMSE:0.00140,   MAE: 0.00130,  MAPE: 0.62%\n",
      "[1500 Epochs]    RMSE:0.00380,   MAE: 0.00371,  MAPE: 1.76%\n",
      "[1600 Epochs]    RMSE:0.00069,   MAE: 0.00054,  MAPE: 0.25%\n",
      "[1700 Epochs]    RMSE:0.00151,   MAE: 0.00135,  MAPE: 0.63%\n",
      "[1800 Epochs]    RMSE:0.00129,   MAE: 0.00110,  MAPE: 0.51%\n",
      "[1900 Epochs]    RMSE:0.00053,   MAE: 0.00045,  MAPE: 0.21%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00132,   MAE: 0.00120,  MAPE: 0.57%\n",
      "\n",
      "\n",
      "Trial No.96\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.20542,   MAE: 0.20492,  MAPE: 98.17%\n",
      "[100 Epochs]    RMSE:0.00391,   MAE: 0.00331,  MAPE: 1.61%\n",
      "[200 Epochs]    RMSE:0.00185,   MAE: 0.00167,  MAPE: 0.81%\n",
      "[300 Epochs]    RMSE:0.00352,   MAE: 0.00341,  MAPE: 1.64%\n",
      "[400 Epochs]    RMSE:0.00897,   MAE: 0.00885,  MAPE: 4.20%\n",
      "[500 Epochs]    RMSE:0.00286,   MAE: 0.00268,  MAPE: 1.26%\n",
      "[600 Epochs]    RMSE:0.00573,   MAE: 0.00559,  MAPE: 2.65%\n",
      "[700 Epochs]    RMSE:0.00545,   MAE: 0.00530,  MAPE: 2.50%\n",
      "[800 Epochs]    RMSE:0.00132,   MAE: 0.00120,  MAPE: 0.58%\n",
      "[900 Epochs]    RMSE:0.00204,   MAE: 0.00191,  MAPE: 0.90%\n",
      "[1000 Epochs]    RMSE:0.00213,   MAE: 0.00208,  MAPE: 1.00%\n",
      "[1100 Epochs]    RMSE:0.00050,   MAE: 0.00042,  MAPE: 0.21%\n",
      "[1200 Epochs]    RMSE:0.00049,   MAE: 0.00037,  MAPE: 0.18%\n",
      "[1300 Epochs]    RMSE:0.00097,   MAE: 0.00091,  MAPE: 0.43%\n",
      "[1400 Epochs]    RMSE:0.00346,   MAE: 0.00338,  MAPE: 1.60%\n",
      "[1500 Epochs]    RMSE:0.00085,   MAE: 0.00076,  MAPE: 0.37%\n",
      "[1600 Epochs]    RMSE:0.00167,   MAE: 0.00163,  MAPE: 0.79%\n",
      "[1700 Epochs]    RMSE:0.00106,   MAE: 0.00100,  MAPE: 0.48%\n",
      "[1800 Epochs]    RMSE:0.00052,   MAE: 0.00041,  MAPE: 0.20%\n",
      "[1900 Epochs]    RMSE:0.00292,   MAE: 0.00277,  MAPE: 1.30%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00451,   MAE: 0.00450,  MAPE: 2.15%\n",
      "\n",
      "\n",
      "Trial No.97\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.19631,   MAE: 0.19584,  MAPE: 94.03%\n",
      "[100 Epochs]    RMSE:0.00488,   MAE: 0.00461,  MAPE: 2.21%\n",
      "[200 Epochs]    RMSE:0.00704,   MAE: 0.00682,  MAPE: 3.24%\n",
      "[300 Epochs]    RMSE:0.00144,   MAE: 0.00127,  MAPE: 0.59%\n",
      "[400 Epochs]    RMSE:0.00354,   MAE: 0.00342,  MAPE: 1.62%\n",
      "[500 Epochs]    RMSE:0.00396,   MAE: 0.00390,  MAPE: 1.86%\n",
      "[600 Epochs]    RMSE:0.00527,   MAE: 0.00522,  MAPE: 2.48%\n",
      "[700 Epochs]    RMSE:0.00488,   MAE: 0.00485,  MAPE: 2.31%\n",
      "[800 Epochs]    RMSE:0.00141,   MAE: 0.00129,  MAPE: 0.62%\n",
      "[900 Epochs]    RMSE:0.00544,   MAE: 0.00540,  MAPE: 2.59%\n",
      "[1000 Epochs]    RMSE:0.00143,   MAE: 0.00136,  MAPE: 0.64%\n",
      "[1100 Epochs]    RMSE:0.00356,   MAE: 0.00352,  MAPE: 1.68%\n",
      "[1200 Epochs]    RMSE:0.00155,   MAE: 0.00140,  MAPE: 0.65%\n",
      "[1300 Epochs]    RMSE:0.00471,   MAE: 0.00461,  MAPE: 2.18%\n",
      "[1400 Epochs]    RMSE:0.00056,   MAE: 0.00046,  MAPE: 0.23%\n",
      "[1500 Epochs]    RMSE:0.00333,   MAE: 0.00331,  MAPE: 1.59%\n",
      "[1600 Epochs]    RMSE:0.00406,   MAE: 0.00400,  MAPE: 1.90%\n",
      "[1700 Epochs]    RMSE:0.00198,   MAE: 0.00190,  MAPE: 0.89%\n",
      "[1800 Epochs]    RMSE:0.00076,   MAE: 0.00069,  MAPE: 0.34%\n",
      "[1900 Epochs]    RMSE:0.00118,   MAE: 0.00109,  MAPE: 0.53%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00347,   MAE: 0.00345,  MAPE: 1.65%\n",
      "\n",
      "\n",
      "Trial No.98\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.27366,   MAE: 0.27056,  MAPE: 128.67%\n",
      "[100 Epochs]    RMSE:0.00376,   MAE: 0.00327,  MAPE: 1.54%\n",
      "[200 Epochs]    RMSE:0.00084,   MAE: 0.00067,  MAPE: 0.31%\n",
      "[300 Epochs]    RMSE:0.00122,   MAE: 0.00082,  MAPE: 0.38%\n",
      "[400 Epochs]    RMSE:0.00307,   MAE: 0.00298,  MAPE: 1.44%\n",
      "[500 Epochs]    RMSE:0.00281,   MAE: 0.00275,  MAPE: 1.31%\n",
      "[600 Epochs]    RMSE:0.00120,   MAE: 0.00102,  MAPE: 0.50%\n",
      "[700 Epochs]    RMSE:0.00492,   MAE: 0.00479,  MAPE: 2.31%\n",
      "[800 Epochs]    RMSE:0.00382,   MAE: 0.00379,  MAPE: 1.81%\n",
      "[900 Epochs]    RMSE:0.00174,   MAE: 0.00162,  MAPE: 0.77%\n",
      "[1000 Epochs]    RMSE:0.00187,   MAE: 0.00170,  MAPE: 0.79%\n",
      "[1100 Epochs]    RMSE:0.00522,   MAE: 0.00515,  MAPE: 2.49%\n",
      "[1200 Epochs]    RMSE:0.00195,   MAE: 0.00193,  MAPE: 0.92%\n",
      "[1300 Epochs]    RMSE:0.00066,   MAE: 0.00056,  MAPE: 0.27%\n",
      "[1400 Epochs]    RMSE:0.00096,   MAE: 0.00073,  MAPE: 0.36%\n",
      "[1500 Epochs]    RMSE:0.00224,   MAE: 0.00223,  MAPE: 1.06%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1600 Epochs]    RMSE:0.00156,   MAE: 0.00151,  MAPE: 0.73%\n",
      "[1700 Epochs]    RMSE:0.00093,   MAE: 0.00075,  MAPE: 0.37%\n",
      "[1800 Epochs]    RMSE:0.00238,   MAE: 0.00236,  MAPE: 1.13%\n",
      "[1900 Epochs]    RMSE:0.00133,   MAE: 0.00117,  MAPE: 0.55%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00089,   MAE: 0.00078,  MAPE: 0.38%\n",
      "\n",
      "\n",
      "Trial No.99\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.28478,   MAE: 0.28117,  MAPE: 133.95%\n",
      "[100 Epochs]    RMSE:0.00442,   MAE: 0.00400,  MAPE: 1.88%\n",
      "[200 Epochs]    RMSE:0.00248,   MAE: 0.00219,  MAPE: 1.02%\n",
      "[300 Epochs]    RMSE:0.00114,   MAE: 0.00100,  MAPE: 0.48%\n",
      "[400 Epochs]    RMSE:0.00490,   MAE: 0.00475,  MAPE: 2.29%\n",
      "[500 Epochs]    RMSE:0.00068,   MAE: 0.00059,  MAPE: 0.28%\n",
      "[600 Epochs]    RMSE:0.00203,   MAE: 0.00189,  MAPE: 0.89%\n",
      "[700 Epochs]    RMSE:0.00176,   MAE: 0.00165,  MAPE: 0.79%\n",
      "[800 Epochs]    RMSE:0.00293,   MAE: 0.00286,  MAPE: 1.38%\n",
      "[900 Epochs]    RMSE:0.00053,   MAE: 0.00043,  MAPE: 0.21%\n",
      "[1000 Epochs]    RMSE:0.00150,   MAE: 0.00140,  MAPE: 0.67%\n",
      "[1100 Epochs]    RMSE:0.00092,   MAE: 0.00085,  MAPE: 0.41%\n",
      "[1200 Epochs]    RMSE:0.00075,   MAE: 0.00066,  MAPE: 0.32%\n",
      "[1300 Epochs]    RMSE:0.00088,   MAE: 0.00081,  MAPE: 0.39%\n",
      "[1400 Epochs]    RMSE:0.00267,   MAE: 0.00263,  MAPE: 1.27%\n",
      "[1500 Epochs]    RMSE:0.00058,   MAE: 0.00046,  MAPE: 0.22%\n",
      "[1600 Epochs]    RMSE:0.00170,   MAE: 0.00164,  MAPE: 0.78%\n",
      "[1700 Epochs]    RMSE:0.00141,   MAE: 0.00131,  MAPE: 0.63%\n",
      "[1800 Epochs]    RMSE:0.00230,   MAE: 0.00215,  MAPE: 1.01%\n",
      "[1900 Epochs]    RMSE:0.00159,   MAE: 0.00156,  MAPE: 0.75%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00282,   MAE: 0.00272,  MAPE: 1.28%\n",
      "\n",
      "\n",
      "Trial No.100\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.20927,   MAE: 0.20386,  MAPE: 96.95%\n",
      "[100 Epochs]    RMSE:0.00186,   MAE: 0.00161,  MAPE: 0.78%\n",
      "[200 Epochs]    RMSE:0.00249,   MAE: 0.00221,  MAPE: 1.06%\n",
      "[300 Epochs]    RMSE:0.00128,   MAE: 0.00105,  MAPE: 0.49%\n",
      "[400 Epochs]    RMSE:0.00396,   MAE: 0.00391,  MAPE: 1.87%\n",
      "[500 Epochs]    RMSE:0.00080,   MAE: 0.00064,  MAPE: 0.31%\n",
      "[600 Epochs]    RMSE:0.00317,   MAE: 0.00310,  MAPE: 1.47%\n",
      "[700 Epochs]    RMSE:0.00135,   MAE: 0.00125,  MAPE: 0.61%\n",
      "[800 Epochs]    RMSE:0.00189,   MAE: 0.00178,  MAPE: 0.85%\n",
      "[900 Epochs]    RMSE:0.00331,   MAE: 0.00327,  MAPE: 1.57%\n",
      "[1000 Epochs]    RMSE:0.00360,   MAE: 0.00354,  MAPE: 1.70%\n",
      "[1100 Epochs]    RMSE:0.00548,   MAE: 0.00543,  MAPE: 2.59%\n",
      "[1200 Epochs]    RMSE:0.00154,   MAE: 0.00138,  MAPE: 0.67%\n",
      "[1300 Epochs]    RMSE:0.00202,   MAE: 0.00197,  MAPE: 0.95%\n",
      "[1400 Epochs]    RMSE:0.00092,   MAE: 0.00087,  MAPE: 0.41%\n",
      "[1500 Epochs]    RMSE:0.00278,   MAE: 0.00274,  MAPE: 1.31%\n",
      "[1600 Epochs]    RMSE:0.00136,   MAE: 0.00132,  MAPE: 0.64%\n",
      "[1700 Epochs]    RMSE:0.00275,   MAE: 0.00274,  MAPE: 1.31%\n",
      "[1800 Epochs]    RMSE:0.00066,   MAE: 0.00056,  MAPE: 0.26%\n",
      "[1900 Epochs]    RMSE:0.00234,   MAE: 0.00232,  MAPE: 1.10%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00175,   MAE: 0.00171,  MAPE: 0.83%\n",
      "\n",
      "\n",
      "Trial No.101\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.26227,   MAE: 0.26106,  MAPE: 124.69%\n",
      "[100 Epochs]    RMSE:0.00920,   MAE: 0.00893,  MAPE: 4.24%\n",
      "[200 Epochs]    RMSE:0.00563,   MAE: 0.00525,  MAPE: 2.46%\n",
      "[300 Epochs]    RMSE:0.00565,   MAE: 0.00553,  MAPE: 2.64%\n",
      "[400 Epochs]    RMSE:0.00074,   MAE: 0.00064,  MAPE: 0.31%\n",
      "[500 Epochs]    RMSE:0.00088,   MAE: 0.00075,  MAPE: 0.36%\n",
      "[600 Epochs]    RMSE:0.00183,   MAE: 0.00160,  MAPE: 0.76%\n",
      "[700 Epochs]    RMSE:0.00229,   MAE: 0.00220,  MAPE: 1.05%\n",
      "[800 Epochs]    RMSE:0.00054,   MAE: 0.00043,  MAPE: 0.20%\n",
      "[900 Epochs]    RMSE:0.00056,   MAE: 0.00045,  MAPE: 0.22%\n",
      "[1000 Epochs]    RMSE:0.00077,   MAE: 0.00064,  MAPE: 0.30%\n",
      "[1100 Epochs]    RMSE:0.00236,   MAE: 0.00232,  MAPE: 1.10%\n",
      "[1200 Epochs]    RMSE:0.00167,   MAE: 0.00159,  MAPE: 0.77%\n",
      "[1300 Epochs]    RMSE:0.00147,   MAE: 0.00127,  MAPE: 0.59%\n",
      "[1400 Epochs]    RMSE:0.00135,   MAE: 0.00128,  MAPE: 0.61%\n",
      "[1500 Epochs]    RMSE:0.00099,   MAE: 0.00096,  MAPE: 0.46%\n",
      "[1600 Epochs]    RMSE:0.00097,   MAE: 0.00087,  MAPE: 0.41%\n",
      "[1700 Epochs]    RMSE:0.00161,   MAE: 0.00154,  MAPE: 0.73%\n",
      "[1800 Epochs]    RMSE:0.00311,   MAE: 0.00302,  MAPE: 1.43%\n",
      "[1900 Epochs]    RMSE:0.00125,   MAE: 0.00120,  MAPE: 0.57%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00129,   MAE: 0.00110,  MAPE: 0.51%\n",
      "\n",
      "\n",
      "Trial No.102\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.17642,   MAE: 0.17492,  MAPE: 83.51%\n",
      "[100 Epochs]    RMSE:0.00638,   MAE: 0.00625,  MAPE: 2.99%\n",
      "[200 Epochs]    RMSE:0.00161,   MAE: 0.00130,  MAPE: 0.60%\n",
      "[300 Epochs]    RMSE:0.00244,   MAE: 0.00221,  MAPE: 1.08%\n",
      "[400 Epochs]    RMSE:0.00214,   MAE: 0.00172,  MAPE: 0.83%\n",
      "[500 Epochs]    RMSE:0.00333,   MAE: 0.00317,  MAPE: 1.51%\n",
      "[600 Epochs]    RMSE:0.00138,   MAE: 0.00125,  MAPE: 0.60%\n",
      "[700 Epochs]    RMSE:0.00131,   MAE: 0.00111,  MAPE: 0.54%\n",
      "[800 Epochs]    RMSE:0.00207,   MAE: 0.00202,  MAPE: 0.97%\n",
      "[900 Epochs]    RMSE:0.00110,   MAE: 0.00102,  MAPE: 0.49%\n",
      "[1000 Epochs]    RMSE:0.00128,   MAE: 0.00121,  MAPE: 0.58%\n",
      "[1100 Epochs]    RMSE:0.00180,   MAE: 0.00161,  MAPE: 0.78%\n",
      "[1200 Epochs]    RMSE:0.00165,   MAE: 0.00158,  MAPE: 0.76%\n",
      "[1300 Epochs]    RMSE:0.00205,   MAE: 0.00188,  MAPE: 0.88%\n",
      "[1400 Epochs]    RMSE:0.00124,   MAE: 0.00114,  MAPE: 0.54%\n",
      "[1500 Epochs]    RMSE:0.00193,   MAE: 0.00190,  MAPE: 0.91%\n",
      "[1600 Epochs]    RMSE:0.00150,   MAE: 0.00141,  MAPE: 0.66%\n",
      "[1700 Epochs]    RMSE:0.00049,   MAE: 0.00041,  MAPE: 0.20%\n",
      "[1800 Epochs]    RMSE:0.00107,   MAE: 0.00097,  MAPE: 0.47%\n",
      "[1900 Epochs]    RMSE:0.00127,   MAE: 0.00123,  MAPE: 0.59%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00135,   MAE: 0.00115,  MAPE: 0.53%\n",
      "\n",
      "\n",
      "Trial No.103\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.22404,   MAE: 0.21698,  MAPE: 102.39%\n",
      "[100 Epochs]    RMSE:0.00353,   MAE: 0.00318,  MAPE: 1.55%\n",
      "[200 Epochs]    RMSE:0.00301,   MAE: 0.00277,  MAPE: 1.35%\n",
      "[300 Epochs]    RMSE:0.00258,   MAE: 0.00223,  MAPE: 1.08%\n",
      "[400 Epochs]    RMSE:0.00143,   MAE: 0.00126,  MAPE: 0.61%\n",
      "[500 Epochs]    RMSE:0.00133,   MAE: 0.00112,  MAPE: 0.52%\n",
      "[600 Epochs]    RMSE:0.00155,   MAE: 0.00138,  MAPE: 0.67%\n",
      "[700 Epochs]    RMSE:0.00803,   MAE: 0.00786,  MAPE: 3.72%\n",
      "[800 Epochs]    RMSE:0.00550,   MAE: 0.00497,  MAPE: 2.31%\n",
      "[900 Epochs]    RMSE:0.00283,   MAE: 0.00277,  MAPE: 1.32%\n",
      "[1000 Epochs]    RMSE:0.00123,   MAE: 0.00121,  MAPE: 0.58%\n",
      "[1100 Epochs]    RMSE:0.00133,   MAE: 0.00130,  MAPE: 0.62%\n",
      "[1200 Epochs]    RMSE:0.00366,   MAE: 0.00363,  MAPE: 1.73%\n",
      "[1300 Epochs]    RMSE:0.00134,   MAE: 0.00118,  MAPE: 0.58%\n",
      "[1400 Epochs]    RMSE:0.00229,   MAE: 0.00202,  MAPE: 0.93%\n",
      "[1500 Epochs]    RMSE:0.00256,   MAE: 0.00255,  MAPE: 1.22%\n",
      "[1600 Epochs]    RMSE:0.00131,   MAE: 0.00118,  MAPE: 0.55%\n",
      "[1700 Epochs]    RMSE:0.00040,   MAE: 0.00037,  MAPE: 0.18%\n",
      "[1800 Epochs]    RMSE:0.00250,   MAE: 0.00246,  MAPE: 1.17%\n",
      "[1900 Epochs]    RMSE:0.00111,   MAE: 0.00100,  MAPE: 0.47%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00087,   MAE: 0.00083,  MAPE: 0.39%\n",
      "\n",
      "\n",
      "Trial No.104\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.18284,   MAE: 0.17976,  MAPE: 85.45%\n",
      "[100 Epochs]    RMSE:0.00282,   MAE: 0.00249,  MAPE: 1.20%\n",
      "[200 Epochs]    RMSE:0.00224,   MAE: 0.00203,  MAPE: 0.96%\n",
      "[300 Epochs]    RMSE:0.00516,   MAE: 0.00510,  MAPE: 2.43%\n",
      "[400 Epochs]    RMSE:0.00178,   MAE: 0.00162,  MAPE: 0.78%\n",
      "[500 Epochs]    RMSE:0.00227,   MAE: 0.00204,  MAPE: 0.96%\n",
      "[600 Epochs]    RMSE:0.00060,   MAE: 0.00040,  MAPE: 0.20%\n",
      "[700 Epochs]    RMSE:0.00241,   MAE: 0.00235,  MAPE: 1.12%\n",
      "[800 Epochs]    RMSE:0.00128,   MAE: 0.00112,  MAPE: 0.55%\n",
      "[900 Epochs]    RMSE:0.00293,   MAE: 0.00290,  MAPE: 1.38%\n",
      "[1000 Epochs]    RMSE:0.00289,   MAE: 0.00283,  MAPE: 1.36%\n",
      "[1100 Epochs]    RMSE:0.00183,   MAE: 0.00167,  MAPE: 0.78%\n",
      "[1200 Epochs]    RMSE:0.00426,   MAE: 0.00404,  MAPE: 1.90%\n",
      "[1300 Epochs]    RMSE:0.00394,   MAE: 0.00376,  MAPE: 1.77%\n",
      "[1400 Epochs]    RMSE:0.00095,   MAE: 0.00082,  MAPE: 0.39%\n",
      "[1500 Epochs]    RMSE:0.00154,   MAE: 0.00137,  MAPE: 0.64%\n",
      "[1600 Epochs]    RMSE:0.00164,   MAE: 0.00154,  MAPE: 0.73%\n",
      "[1700 Epochs]    RMSE:0.00182,   MAE: 0.00174,  MAPE: 0.83%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1800 Epochs]    RMSE:0.00333,   MAE: 0.00331,  MAPE: 1.58%\n",
      "[1900 Epochs]    RMSE:0.00049,   MAE: 0.00038,  MAPE: 0.18%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00207,   MAE: 0.00203,  MAPE: 0.97%\n",
      "\n",
      "\n",
      "Trial No.105\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.21680,   MAE: 0.21489,  MAPE: 103.29%\n",
      "[100 Epochs]    RMSE:0.00591,   MAE: 0.00550,  MAPE: 2.65%\n",
      "[200 Epochs]    RMSE:0.00326,   MAE: 0.00297,  MAPE: 1.41%\n",
      "[300 Epochs]    RMSE:0.00379,   MAE: 0.00340,  MAPE: 1.60%\n",
      "[400 Epochs]    RMSE:0.00111,   MAE: 0.00098,  MAPE: 0.48%\n",
      "[500 Epochs]    RMSE:0.01211,   MAE: 0.01204,  MAPE: 5.74%\n",
      "[600 Epochs]    RMSE:0.00204,   MAE: 0.00178,  MAPE: 0.83%\n",
      "[700 Epochs]    RMSE:0.00106,   MAE: 0.00090,  MAPE: 0.42%\n",
      "[800 Epochs]    RMSE:0.00135,   MAE: 0.00121,  MAPE: 0.58%\n",
      "[900 Epochs]    RMSE:0.00315,   MAE: 0.00309,  MAPE: 1.47%\n",
      "[1000 Epochs]    RMSE:0.00099,   MAE: 0.00092,  MAPE: 0.43%\n",
      "[1100 Epochs]    RMSE:0.00124,   MAE: 0.00106,  MAPE: 0.50%\n",
      "[1200 Epochs]    RMSE:0.00268,   MAE: 0.00262,  MAPE: 1.24%\n",
      "[1300 Epochs]    RMSE:0.00189,   MAE: 0.00175,  MAPE: 0.82%\n",
      "[1400 Epochs]    RMSE:0.00099,   MAE: 0.00086,  MAPE: 0.40%\n",
      "[1500 Epochs]    RMSE:0.00606,   MAE: 0.00593,  MAPE: 2.80%\n",
      "[1600 Epochs]    RMSE:0.00240,   MAE: 0.00237,  MAPE: 1.13%\n",
      "[1700 Epochs]    RMSE:0.00060,   MAE: 0.00050,  MAPE: 0.24%\n",
      "[1800 Epochs]    RMSE:0.00419,   MAE: 0.00415,  MAPE: 1.98%\n",
      "[1900 Epochs]    RMSE:0.00212,   MAE: 0.00208,  MAPE: 1.00%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00259,   MAE: 0.00232,  MAPE: 1.08%\n",
      "\n",
      "\n",
      "Trial No.106\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.10955,   MAE: 0.10176,  MAPE: 48.52%\n",
      "[100 Epochs]    RMSE:0.00753,   MAE: 0.00677,  MAPE: 3.24%\n",
      "[200 Epochs]    RMSE:0.00712,   MAE: 0.00695,  MAPE: 3.33%\n",
      "[300 Epochs]    RMSE:0.00179,   MAE: 0.00143,  MAPE: 0.69%\n",
      "[400 Epochs]    RMSE:0.00104,   MAE: 0.00084,  MAPE: 0.40%\n",
      "[500 Epochs]    RMSE:0.00086,   MAE: 0.00075,  MAPE: 0.36%\n",
      "[600 Epochs]    RMSE:0.00147,   MAE: 0.00115,  MAPE: 0.54%\n",
      "[700 Epochs]    RMSE:0.00427,   MAE: 0.00420,  MAPE: 2.00%\n",
      "[800 Epochs]    RMSE:0.00068,   MAE: 0.00047,  MAPE: 0.23%\n",
      "[900 Epochs]    RMSE:0.00315,   MAE: 0.00307,  MAPE: 1.46%\n",
      "[1000 Epochs]    RMSE:0.00134,   MAE: 0.00126,  MAPE: 0.61%\n",
      "[1100 Epochs]    RMSE:0.00136,   MAE: 0.00129,  MAPE: 0.62%\n",
      "[1200 Epochs]    RMSE:0.00352,   MAE: 0.00329,  MAPE: 1.54%\n",
      "[1300 Epochs]    RMSE:0.00139,   MAE: 0.00119,  MAPE: 0.56%\n",
      "[1400 Epochs]    RMSE:0.00109,   MAE: 0.00098,  MAPE: 0.48%\n",
      "[1500 Epochs]    RMSE:0.00114,   MAE: 0.00109,  MAPE: 0.53%\n",
      "[1600 Epochs]    RMSE:0.00064,   MAE: 0.00057,  MAPE: 0.27%\n",
      "[1700 Epochs]    RMSE:0.00049,   MAE: 0.00041,  MAPE: 0.20%\n",
      "[1800 Epochs]    RMSE:0.00359,   MAE: 0.00358,  MAPE: 1.72%\n",
      "[1900 Epochs]    RMSE:0.00142,   MAE: 0.00134,  MAPE: 0.63%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00022,   MAE: 0.00016,  MAPE: 0.08%\n",
      "\n",
      "\n",
      "Trial No.107\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.17930,   MAE: 0.17725,  MAPE: 84.92%\n",
      "[100 Epochs]    RMSE:0.00315,   MAE: 0.00259,  MAPE: 1.25%\n",
      "[200 Epochs]    RMSE:0.00147,   MAE: 0.00116,  MAPE: 0.54%\n",
      "[300 Epochs]    RMSE:0.00207,   MAE: 0.00175,  MAPE: 0.82%\n",
      "[400 Epochs]    RMSE:0.00390,   MAE: 0.00375,  MAPE: 1.81%\n",
      "[500 Epochs]    RMSE:0.00125,   MAE: 0.00106,  MAPE: 0.51%\n",
      "[600 Epochs]    RMSE:0.00208,   MAE: 0.00200,  MAPE: 0.95%\n",
      "[700 Epochs]    RMSE:0.00172,   MAE: 0.00157,  MAPE: 0.76%\n",
      "[800 Epochs]    RMSE:0.00189,   MAE: 0.00166,  MAPE: 0.80%\n",
      "[900 Epochs]    RMSE:0.00222,   MAE: 0.00214,  MAPE: 1.02%\n",
      "[1000 Epochs]    RMSE:0.00262,   MAE: 0.00255,  MAPE: 1.21%\n",
      "[1100 Epochs]    RMSE:0.00296,   MAE: 0.00293,  MAPE: 1.40%\n",
      "[1200 Epochs]    RMSE:0.00065,   MAE: 0.00055,  MAPE: 0.26%\n",
      "[1300 Epochs]    RMSE:0.00168,   MAE: 0.00150,  MAPE: 0.71%\n",
      "[1400 Epochs]    RMSE:0.00156,   MAE: 0.00148,  MAPE: 0.71%\n",
      "[1500 Epochs]    RMSE:0.00117,   MAE: 0.00110,  MAPE: 0.52%\n",
      "[1600 Epochs]    RMSE:0.00063,   MAE: 0.00053,  MAPE: 0.25%\n",
      "[1700 Epochs]    RMSE:0.00090,   MAE: 0.00081,  MAPE: 0.38%\n",
      "[1800 Epochs]    RMSE:0.00152,   MAE: 0.00136,  MAPE: 0.67%\n",
      "[1900 Epochs]    RMSE:0.00302,   MAE: 0.00294,  MAPE: 1.39%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00302,   MAE: 0.00289,  MAPE: 1.40%\n",
      "\n",
      "\n",
      "Trial No.108\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.28749,   MAE: 0.28513,  MAPE: 136.26%\n",
      "[100 Epochs]    RMSE:0.00408,   MAE: 0.00351,  MAPE: 1.67%\n",
      "[200 Epochs]    RMSE:0.00162,   MAE: 0.00124,  MAPE: 0.58%\n",
      "[300 Epochs]    RMSE:0.00185,   MAE: 0.00157,  MAPE: 0.75%\n",
      "[400 Epochs]    RMSE:0.00197,   MAE: 0.00185,  MAPE: 0.89%\n",
      "[500 Epochs]    RMSE:0.00097,   MAE: 0.00072,  MAPE: 0.35%\n",
      "[600 Epochs]    RMSE:0.00400,   MAE: 0.00366,  MAPE: 1.71%\n",
      "[700 Epochs]    RMSE:0.00074,   MAE: 0.00058,  MAPE: 0.27%\n",
      "[800 Epochs]    RMSE:0.00235,   MAE: 0.00221,  MAPE: 1.04%\n",
      "[900 Epochs]    RMSE:0.00542,   MAE: 0.00531,  MAPE: 2.52%\n",
      "[1000 Epochs]    RMSE:0.00064,   MAE: 0.00051,  MAPE: 0.24%\n",
      "[1100 Epochs]    RMSE:0.00176,   MAE: 0.00169,  MAPE: 0.80%\n",
      "[1200 Epochs]    RMSE:0.00043,   MAE: 0.00035,  MAPE: 0.17%\n",
      "[1300 Epochs]    RMSE:0.00285,   MAE: 0.00279,  MAPE: 1.34%\n",
      "[1400 Epochs]    RMSE:0.00341,   MAE: 0.00336,  MAPE: 1.60%\n",
      "[1500 Epochs]    RMSE:0.00079,   MAE: 0.00067,  MAPE: 0.33%\n",
      "[1600 Epochs]    RMSE:0.00037,   MAE: 0.00033,  MAPE: 0.16%\n",
      "[1700 Epochs]    RMSE:0.00064,   MAE: 0.00051,  MAPE: 0.24%\n",
      "[1800 Epochs]    RMSE:0.00131,   MAE: 0.00114,  MAPE: 0.53%\n",
      "[1900 Epochs]    RMSE:0.00153,   MAE: 0.00149,  MAPE: 0.72%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00082,   MAE: 0.00072,  MAPE: 0.34%\n",
      "\n",
      "\n",
      "Trial No.109\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.16217,   MAE: 0.15769,  MAPE: 74.87%\n",
      "[100 Epochs]    RMSE:0.00315,   MAE: 0.00264,  MAPE: 1.26%\n",
      "[200 Epochs]    RMSE:0.00553,   MAE: 0.00526,  MAPE: 2.49%\n",
      "[300 Epochs]    RMSE:0.00253,   MAE: 0.00237,  MAPE: 1.15%\n",
      "[400 Epochs]    RMSE:0.00631,   MAE: 0.00626,  MAPE: 2.99%\n",
      "[500 Epochs]    RMSE:0.00434,   MAE: 0.00406,  MAPE: 1.91%\n",
      "[600 Epochs]    RMSE:0.00194,   MAE: 0.00165,  MAPE: 0.79%\n",
      "[700 Epochs]    RMSE:0.00139,   MAE: 0.00130,  MAPE: 0.63%\n",
      "[800 Epochs]    RMSE:0.00140,   MAE: 0.00126,  MAPE: 0.59%\n",
      "[900 Epochs]    RMSE:0.00170,   MAE: 0.00151,  MAPE: 0.71%\n",
      "[1000 Epochs]    RMSE:0.00415,   MAE: 0.00406,  MAPE: 1.93%\n",
      "[1100 Epochs]    RMSE:0.00436,   MAE: 0.00434,  MAPE: 2.08%\n",
      "[1200 Epochs]    RMSE:0.00382,   MAE: 0.00377,  MAPE: 1.80%\n",
      "[1300 Epochs]    RMSE:0.00091,   MAE: 0.00084,  MAPE: 0.40%\n",
      "[1400 Epochs]    RMSE:0.00310,   MAE: 0.00308,  MAPE: 1.48%\n",
      "[1500 Epochs]    RMSE:0.00257,   MAE: 0.00252,  MAPE: 1.20%\n",
      "[1600 Epochs]    RMSE:0.00168,   MAE: 0.00154,  MAPE: 0.72%\n",
      "[1700 Epochs]    RMSE:0.00173,   MAE: 0.00171,  MAPE: 0.82%\n",
      "[1800 Epochs]    RMSE:0.00114,   MAE: 0.00109,  MAPE: 0.53%\n",
      "[1900 Epochs]    RMSE:0.00220,   MAE: 0.00218,  MAPE: 1.05%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00580,   MAE: 0.00567,  MAPE: 2.69%\n",
      "\n",
      "\n",
      "Trial No.110\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.27141,   MAE: 0.26785,  MAPE: 127.36%\n",
      "[100 Epochs]    RMSE:0.00519,   MAE: 0.00460,  MAPE: 2.15%\n",
      "[200 Epochs]    RMSE:0.00184,   MAE: 0.00167,  MAPE: 0.79%\n",
      "[300 Epochs]    RMSE:0.00562,   MAE: 0.00551,  MAPE: 2.66%\n",
      "[400 Epochs]    RMSE:0.00313,   MAE: 0.00291,  MAPE: 1.36%\n",
      "[500 Epochs]    RMSE:0.00287,   MAE: 0.00284,  MAPE: 1.36%\n",
      "[600 Epochs]    RMSE:0.00151,   MAE: 0.00126,  MAPE: 0.61%\n",
      "[700 Epochs]    RMSE:0.00167,   MAE: 0.00151,  MAPE: 0.72%\n",
      "[800 Epochs]    RMSE:0.00080,   MAE: 0.00064,  MAPE: 0.30%\n",
      "[900 Epochs]    RMSE:0.00081,   MAE: 0.00065,  MAPE: 0.32%\n",
      "[1000 Epochs]    RMSE:0.00417,   MAE: 0.00413,  MAPE: 1.97%\n",
      "[1100 Epochs]    RMSE:0.00357,   MAE: 0.00354,  MAPE: 1.69%\n",
      "[1200 Epochs]    RMSE:0.00080,   MAE: 0.00055,  MAPE: 0.25%\n",
      "[1300 Epochs]    RMSE:0.00241,   MAE: 0.00216,  MAPE: 1.01%\n",
      "[1400 Epochs]    RMSE:0.00093,   MAE: 0.00080,  MAPE: 0.40%\n",
      "[1500 Epochs]    RMSE:0.00116,   MAE: 0.00107,  MAPE: 0.52%\n",
      "[1600 Epochs]    RMSE:0.00553,   MAE: 0.00550,  MAPE: 2.62%\n",
      "[1700 Epochs]    RMSE:0.00198,   MAE: 0.00185,  MAPE: 0.86%\n",
      "[1800 Epochs]    RMSE:0.00041,   MAE: 0.00033,  MAPE: 0.16%\n",
      "[1900 Epochs]    RMSE:0.00121,   MAE: 0.00119,  MAPE: 0.57%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Final Epochs]    RMSE:0.00248,   MAE: 0.00241,  MAPE: 1.14%\n",
      "\n",
      "\n",
      "Trial No.111\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.27135,   MAE: 0.26923,  MAPE: 128.59%\n",
      "[100 Epochs]    RMSE:0.00211,   MAE: 0.00185,  MAPE: 0.90%\n",
      "[200 Epochs]    RMSE:0.00580,   MAE: 0.00558,  MAPE: 2.65%\n",
      "[300 Epochs]    RMSE:0.00091,   MAE: 0.00076,  MAPE: 0.36%\n",
      "[400 Epochs]    RMSE:0.00362,   MAE: 0.00346,  MAPE: 1.67%\n",
      "[500 Epochs]    RMSE:0.00432,   MAE: 0.00428,  MAPE: 2.04%\n",
      "[600 Epochs]    RMSE:0.00278,   MAE: 0.00271,  MAPE: 1.31%\n",
      "[700 Epochs]    RMSE:0.00341,   MAE: 0.00338,  MAPE: 1.61%\n",
      "[800 Epochs]    RMSE:0.00243,   MAE: 0.00233,  MAPE: 1.10%\n",
      "[900 Epochs]    RMSE:0.00322,   MAE: 0.00320,  MAPE: 1.53%\n",
      "[1000 Epochs]    RMSE:0.00328,   MAE: 0.00325,  MAPE: 1.56%\n",
      "[1100 Epochs]    RMSE:0.00105,   MAE: 0.00100,  MAPE: 0.49%\n",
      "[1200 Epochs]    RMSE:0.00122,   MAE: 0.00112,  MAPE: 0.53%\n",
      "[1300 Epochs]    RMSE:0.00382,   MAE: 0.00379,  MAPE: 1.80%\n",
      "[1400 Epochs]    RMSE:0.00193,   MAE: 0.00188,  MAPE: 0.90%\n",
      "[1500 Epochs]    RMSE:0.00121,   MAE: 0.00106,  MAPE: 0.49%\n",
      "[1600 Epochs]    RMSE:0.00436,   MAE: 0.00435,  MAPE: 2.08%\n",
      "[1700 Epochs]    RMSE:0.00094,   MAE: 0.00080,  MAPE: 0.37%\n",
      "[1800 Epochs]    RMSE:0.00227,   MAE: 0.00226,  MAPE: 1.08%\n",
      "[1900 Epochs]    RMSE:0.00532,   MAE: 0.00526,  MAPE: 2.50%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00425,   MAE: 0.00421,  MAPE: 2.00%\n",
      "\n",
      "\n",
      "Trial No.112\n",
      "Prediction :VS\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.18174,   MAE: 0.18115,  MAPE: 86.84%\n",
      "[100 Epochs]    RMSE:0.00208,   MAE: 0.00157,  MAPE: 0.77%\n",
      "[200 Epochs]    RMSE:0.00555,   MAE: 0.00543,  MAPE: 2.57%\n",
      "[300 Epochs]    RMSE:0.00103,   MAE: 0.00083,  MAPE: 0.39%\n",
      "[400 Epochs]    RMSE:0.00073,   MAE: 0.00059,  MAPE: 0.29%\n",
      "[500 Epochs]    RMSE:0.00107,   MAE: 0.00097,  MAPE: 0.46%\n",
      "[600 Epochs]    RMSE:0.00360,   MAE: 0.00346,  MAPE: 1.63%\n",
      "[700 Epochs]    RMSE:0.00118,   MAE: 0.00115,  MAPE: 0.55%\n",
      "[800 Epochs]    RMSE:0.00191,   MAE: 0.00172,  MAPE: 0.81%\n",
      "[900 Epochs]    RMSE:0.00504,   MAE: 0.00496,  MAPE: 2.35%\n",
      "[1000 Epochs]    RMSE:0.00158,   MAE: 0.00154,  MAPE: 0.74%\n",
      "[1100 Epochs]    RMSE:0.00144,   MAE: 0.00141,  MAPE: 0.67%\n",
      "[1200 Epochs]    RMSE:0.00364,   MAE: 0.00342,  MAPE: 1.60%\n",
      "[1300 Epochs]    RMSE:0.00268,   MAE: 0.00240,  MAPE: 1.19%\n",
      "[1400 Epochs]    RMSE:0.00065,   MAE: 0.00057,  MAPE: 0.27%\n",
      "[1500 Epochs]    RMSE:0.00386,   MAE: 0.00384,  MAPE: 1.83%\n",
      "[1600 Epochs]    RMSE:0.00184,   MAE: 0.00180,  MAPE: 0.85%\n",
      "[1700 Epochs]    RMSE:0.00142,   MAE: 0.00138,  MAPE: 0.65%\n",
      "[1800 Epochs]    RMSE:0.00146,   MAE: 0.00123,  MAPE: 0.61%\n",
      "[1900 Epochs]    RMSE:0.00199,   MAE: 0.00195,  MAPE: 0.93%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00510,   MAE: 0.00503,  MAPE: 2.39%\n",
      "\n",
      "\n",
      "Trial No.113\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.23885,   MAE: 0.23706,  MAPE: 112.89%\n",
      "[100 Epochs]    RMSE:0.00640,   MAE: 0.00596,  MAPE: 2.82%\n",
      "[200 Epochs]    RMSE:0.00662,   MAE: 0.00632,  MAPE: 3.05%\n",
      "[300 Epochs]    RMSE:0.00507,   MAE: 0.00487,  MAPE: 2.32%\n",
      "[400 Epochs]    RMSE:0.00224,   MAE: 0.00204,  MAPE: 0.97%\n",
      "[500 Epochs]    RMSE:0.00230,   MAE: 0.00220,  MAPE: 1.06%\n",
      "[600 Epochs]    RMSE:0.00455,   MAE: 0.00443,  MAPE: 2.11%\n",
      "[700 Epochs]    RMSE:0.00136,   MAE: 0.00117,  MAPE: 0.57%\n",
      "[800 Epochs]    RMSE:0.00637,   MAE: 0.00618,  MAPE: 2.93%\n",
      "[900 Epochs]    RMSE:0.00280,   MAE: 0.00244,  MAPE: 1.13%\n",
      "[1000 Epochs]    RMSE:0.00117,   MAE: 0.00106,  MAPE: 0.51%\n",
      "[1100 Epochs]    RMSE:0.00239,   MAE: 0.00226,  MAPE: 1.10%\n",
      "[1200 Epochs]    RMSE:0.00095,   MAE: 0.00083,  MAPE: 0.40%\n",
      "[1300 Epochs]    RMSE:0.00190,   MAE: 0.00166,  MAPE: 0.77%\n",
      "[1400 Epochs]    RMSE:0.00109,   MAE: 0.00090,  MAPE: 0.42%\n",
      "[1500 Epochs]    RMSE:0.00239,   MAE: 0.00217,  MAPE: 1.03%\n",
      "[1600 Epochs]    RMSE:0.00485,   MAE: 0.00476,  MAPE: 2.26%\n",
      "[1700 Epochs]    RMSE:0.00273,   MAE: 0.00243,  MAPE: 1.13%\n",
      "[1800 Epochs]    RMSE:0.00071,   MAE: 0.00053,  MAPE: 0.25%\n",
      "[1900 Epochs]    RMSE:0.00333,   MAE: 0.00325,  MAPE: 1.54%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00179,   MAE: 0.00162,  MAPE: 0.79%\n",
      "\n",
      "\n",
      "Trial No.114\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.09026,   MAE: 0.07571,  MAPE: 37.09%\n",
      "[100 Epochs]    RMSE:0.01139,   MAE: 0.01097,  MAPE: 5.18%\n",
      "[200 Epochs]    RMSE:0.00916,   MAE: 0.00900,  MAPE: 4.26%\n",
      "[300 Epochs]    RMSE:0.00402,   MAE: 0.00378,  MAPE: 1.84%\n",
      "[400 Epochs]    RMSE:0.00098,   MAE: 0.00077,  MAPE: 0.37%\n",
      "[500 Epochs]    RMSE:0.00202,   MAE: 0.00185,  MAPE: 0.89%\n",
      "[600 Epochs]    RMSE:0.00177,   MAE: 0.00172,  MAPE: 0.82%\n",
      "[700 Epochs]    RMSE:0.00256,   MAE: 0.00244,  MAPE: 1.15%\n",
      "[800 Epochs]    RMSE:0.00168,   MAE: 0.00161,  MAPE: 0.76%\n",
      "[900 Epochs]    RMSE:0.00308,   MAE: 0.00304,  MAPE: 1.46%\n",
      "[1000 Epochs]    RMSE:0.00301,   MAE: 0.00294,  MAPE: 1.42%\n",
      "[1100 Epochs]    RMSE:0.00433,   MAE: 0.00430,  MAPE: 2.06%\n",
      "[1200 Epochs]    RMSE:0.00068,   MAE: 0.00052,  MAPE: 0.26%\n",
      "[1300 Epochs]    RMSE:0.00135,   MAE: 0.00118,  MAPE: 0.55%\n",
      "[1400 Epochs]    RMSE:0.00204,   MAE: 0.00186,  MAPE: 0.91%\n",
      "[1500 Epochs]    RMSE:0.00344,   MAE: 0.00332,  MAPE: 1.56%\n",
      "[1600 Epochs]    RMSE:0.00337,   MAE: 0.00331,  MAPE: 1.58%\n",
      "[1700 Epochs]    RMSE:0.00200,   MAE: 0.00179,  MAPE: 0.88%\n",
      "[1800 Epochs]    RMSE:0.00091,   MAE: 0.00083,  MAPE: 0.40%\n",
      "[1900 Epochs]    RMSE:0.00406,   MAE: 0.00404,  MAPE: 1.94%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00250,   MAE: 0.00249,  MAPE: 1.19%\n",
      "\n",
      "\n",
      "Trial No.115\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.20852,   MAE: 0.20127,  MAPE: 96.33%\n",
      "[100 Epochs]    RMSE:0.00208,   MAE: 0.00181,  MAPE: 0.88%\n",
      "[200 Epochs]    RMSE:0.00147,   MAE: 0.00127,  MAPE: 0.61%\n",
      "[300 Epochs]    RMSE:0.00248,   MAE: 0.00226,  MAPE: 1.06%\n",
      "[400 Epochs]    RMSE:0.00149,   MAE: 0.00137,  MAPE: 0.65%\n",
      "[500 Epochs]    RMSE:0.00221,   MAE: 0.00216,  MAPE: 1.04%\n",
      "[600 Epochs]    RMSE:0.00284,   MAE: 0.00273,  MAPE: 1.32%\n",
      "[700 Epochs]    RMSE:0.00211,   MAE: 0.00206,  MAPE: 0.98%\n",
      "[800 Epochs]    RMSE:0.00086,   MAE: 0.00071,  MAPE: 0.34%\n",
      "[900 Epochs]    RMSE:0.00118,   MAE: 0.00113,  MAPE: 0.54%\n",
      "[1000 Epochs]    RMSE:0.00172,   MAE: 0.00166,  MAPE: 0.81%\n",
      "[1100 Epochs]    RMSE:0.00185,   MAE: 0.00170,  MAPE: 0.79%\n",
      "[1200 Epochs]    RMSE:0.00371,   MAE: 0.00368,  MAPE: 1.75%\n",
      "[1300 Epochs]    RMSE:0.00070,   MAE: 0.00052,  MAPE: 0.24%\n",
      "[1400 Epochs]    RMSE:0.00208,   MAE: 0.00189,  MAPE: 0.88%\n",
      "[1500 Epochs]    RMSE:0.00334,   MAE: 0.00331,  MAPE: 1.58%\n",
      "[1600 Epochs]    RMSE:0.00107,   MAE: 0.00101,  MAPE: 0.49%\n",
      "[1700 Epochs]    RMSE:0.00089,   MAE: 0.00075,  MAPE: 0.35%\n",
      "[1800 Epochs]    RMSE:0.00120,   MAE: 0.00106,  MAPE: 0.50%\n",
      "[1900 Epochs]    RMSE:0.00062,   MAE: 0.00051,  MAPE: 0.25%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00074,   MAE: 0.00062,  MAPE: 0.30%\n",
      "\n",
      "\n",
      "Trial No.116\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.32370,   MAE: 0.31801,  MAPE: 151.93%\n",
      "[100 Epochs]    RMSE:0.00708,   MAE: 0.00688,  MAPE: 3.30%\n",
      "[200 Epochs]    RMSE:0.00724,   MAE: 0.00690,  MAPE: 3.25%\n",
      "[300 Epochs]    RMSE:0.00080,   MAE: 0.00057,  MAPE: 0.28%\n",
      "[400 Epochs]    RMSE:0.00685,   MAE: 0.00654,  MAPE: 3.08%\n",
      "[500 Epochs]    RMSE:0.00427,   MAE: 0.00408,  MAPE: 1.93%\n",
      "[600 Epochs]    RMSE:0.00286,   MAE: 0.00229,  MAPE: 1.13%\n",
      "[700 Epochs]    RMSE:0.00355,   MAE: 0.00344,  MAPE: 1.63%\n",
      "[800 Epochs]    RMSE:0.00266,   MAE: 0.00254,  MAPE: 1.21%\n",
      "[900 Epochs]    RMSE:0.00540,   MAE: 0.00528,  MAPE: 2.50%\n",
      "[1000 Epochs]    RMSE:0.00064,   MAE: 0.00050,  MAPE: 0.24%\n",
      "[1100 Epochs]    RMSE:0.00168,   MAE: 0.00158,  MAPE: 0.75%\n",
      "[1200 Epochs]    RMSE:0.00202,   MAE: 0.00188,  MAPE: 0.88%\n",
      "[1300 Epochs]    RMSE:0.00512,   MAE: 0.00488,  MAPE: 2.29%\n",
      "[1400 Epochs]    RMSE:0.00430,   MAE: 0.00417,  MAPE: 1.99%\n",
      "[1500 Epochs]    RMSE:0.00230,   MAE: 0.00220,  MAPE: 1.04%\n",
      "[1600 Epochs]    RMSE:0.00232,   MAE: 0.00212,  MAPE: 0.99%\n",
      "[1700 Epochs]    RMSE:0.00149,   MAE: 0.00132,  MAPE: 0.65%\n",
      "[1800 Epochs]    RMSE:0.00192,   MAE: 0.00184,  MAPE: 0.89%\n",
      "[1900 Epochs]    RMSE:0.00145,   MAE: 0.00143,  MAPE: 0.68%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00066,   MAE: 0.00058,  MAPE: 0.28%\n",
      "\n",
      "\n",
      "Trial No.117\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 Epochs]    RMSE:0.13943,   MAE: 0.13598,  MAPE: 65.54%\n",
      "[100 Epochs]    RMSE:0.00743,   MAE: 0.00696,  MAPE: 3.26%\n",
      "[200 Epochs]    RMSE:0.00331,   MAE: 0.00309,  MAPE: 1.49%\n",
      "[300 Epochs]    RMSE:0.00241,   MAE: 0.00229,  MAPE: 1.09%\n",
      "[400 Epochs]    RMSE:0.01073,   MAE: 0.01061,  MAPE: 5.04%\n",
      "[500 Epochs]    RMSE:0.00138,   MAE: 0.00106,  MAPE: 0.50%\n",
      "[600 Epochs]    RMSE:0.00338,   MAE: 0.00320,  MAPE: 1.52%\n",
      "[700 Epochs]    RMSE:0.00158,   MAE: 0.00139,  MAPE: 0.67%\n",
      "[800 Epochs]    RMSE:0.00332,   MAE: 0.00327,  MAPE: 1.56%\n",
      "[900 Epochs]    RMSE:0.00509,   MAE: 0.00499,  MAPE: 2.37%\n",
      "[1000 Epochs]    RMSE:0.00318,   MAE: 0.00310,  MAPE: 1.49%\n",
      "[1100 Epochs]    RMSE:0.00362,   MAE: 0.00354,  MAPE: 1.70%\n",
      "[1200 Epochs]    RMSE:0.00231,   MAE: 0.00215,  MAPE: 1.03%\n",
      "[1300 Epochs]    RMSE:0.00154,   MAE: 0.00137,  MAPE: 0.66%\n",
      "[1400 Epochs]    RMSE:0.00396,   MAE: 0.00384,  MAPE: 1.83%\n",
      "[1500 Epochs]    RMSE:0.00459,   MAE: 0.00444,  MAPE: 2.09%\n",
      "[1600 Epochs]    RMSE:0.00123,   MAE: 0.00111,  MAPE: 0.54%\n",
      "[1700 Epochs]    RMSE:0.00193,   MAE: 0.00188,  MAPE: 0.89%\n",
      "[1800 Epochs]    RMSE:0.00164,   MAE: 0.00138,  MAPE: 0.69%\n",
      "[1900 Epochs]    RMSE:0.00096,   MAE: 0.00086,  MAPE: 0.40%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00310,   MAE: 0.00286,  MAPE: 1.34%\n",
      "\n",
      "\n",
      "Trial No.118\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.16710,   MAE: 0.16579,  MAPE: 79.67%\n",
      "[100 Epochs]    RMSE:0.01036,   MAE: 0.01028,  MAPE: 4.92%\n",
      "[200 Epochs]    RMSE:0.00417,   MAE: 0.00403,  MAPE: 1.93%\n",
      "[300 Epochs]    RMSE:0.00387,   MAE: 0.00375,  MAPE: 1.81%\n",
      "[400 Epochs]    RMSE:0.00249,   MAE: 0.00242,  MAPE: 1.17%\n",
      "[500 Epochs]    RMSE:0.00517,   MAE: 0.00514,  MAPE: 2.47%\n",
      "[600 Epochs]    RMSE:0.00197,   MAE: 0.00165,  MAPE: 0.76%\n",
      "[700 Epochs]    RMSE:0.00233,   MAE: 0.00225,  MAPE: 1.09%\n",
      "[800 Epochs]    RMSE:0.00166,   MAE: 0.00154,  MAPE: 0.75%\n",
      "[900 Epochs]    RMSE:0.00384,   MAE: 0.00383,  MAPE: 1.83%\n",
      "[1000 Epochs]    RMSE:0.00367,   MAE: 0.00364,  MAPE: 1.75%\n",
      "[1100 Epochs]    RMSE:0.00197,   MAE: 0.00182,  MAPE: 0.85%\n",
      "[1200 Epochs]    RMSE:0.00224,   MAE: 0.00210,  MAPE: 0.98%\n",
      "[1300 Epochs]    RMSE:0.00292,   MAE: 0.00287,  MAPE: 1.37%\n",
      "[1400 Epochs]    RMSE:0.00505,   MAE: 0.00503,  MAPE: 2.41%\n",
      "[1500 Epochs]    RMSE:0.00397,   MAE: 0.00377,  MAPE: 1.77%\n",
      "[1600 Epochs]    RMSE:0.00332,   MAE: 0.00330,  MAPE: 1.58%\n",
      "[1700 Epochs]    RMSE:0.00210,   MAE: 0.00207,  MAPE: 0.99%\n",
      "[1800 Epochs]    RMSE:0.00190,   MAE: 0.00174,  MAPE: 0.81%\n",
      "[1900 Epochs]    RMSE:0.00499,   MAE: 0.00493,  MAPE: 2.34%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00030,   MAE: 0.00023,  MAPE: 0.11%\n",
      "\n",
      "\n",
      "Trial No.119\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.38846,   MAE: 0.37900,  MAPE: 179.93%\n",
      "[100 Epochs]    RMSE:0.00772,   MAE: 0.00651,  MAPE: 3.23%\n",
      "[200 Epochs]    RMSE:0.00889,   MAE: 0.00882,  MAPE: 4.24%\n",
      "[300 Epochs]    RMSE:0.00235,   MAE: 0.00209,  MAPE: 0.98%\n",
      "[400 Epochs]    RMSE:0.01225,   MAE: 0.01217,  MAPE: 5.80%\n",
      "[500 Epochs]    RMSE:0.00190,   MAE: 0.00187,  MAPE: 0.89%\n",
      "[600 Epochs]    RMSE:0.00129,   MAE: 0.00112,  MAPE: 0.52%\n",
      "[700 Epochs]    RMSE:0.00221,   MAE: 0.00185,  MAPE: 0.92%\n",
      "[800 Epochs]    RMSE:0.00043,   MAE: 0.00034,  MAPE: 0.16%\n",
      "[900 Epochs]    RMSE:0.00224,   MAE: 0.00206,  MAPE: 0.97%\n",
      "[1000 Epochs]    RMSE:0.00490,   MAE: 0.00488,  MAPE: 2.33%\n",
      "[1100 Epochs]    RMSE:0.00082,   MAE: 0.00077,  MAPE: 0.37%\n",
      "[1200 Epochs]    RMSE:0.00187,   MAE: 0.00176,  MAPE: 0.83%\n",
      "[1300 Epochs]    RMSE:0.00202,   MAE: 0.00190,  MAPE: 0.89%\n",
      "[1400 Epochs]    RMSE:0.00112,   MAE: 0.00101,  MAPE: 0.48%\n",
      "[1500 Epochs]    RMSE:0.00614,   MAE: 0.00605,  MAPE: 2.87%\n",
      "[1600 Epochs]    RMSE:0.00203,   MAE: 0.00183,  MAPE: 0.85%\n",
      "[1700 Epochs]    RMSE:0.00262,   MAE: 0.00256,  MAPE: 1.24%\n",
      "[1800 Epochs]    RMSE:0.00104,   MAE: 0.00089,  MAPE: 0.42%\n",
      "[1900 Epochs]    RMSE:0.00432,   MAE: 0.00426,  MAPE: 2.02%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00036,   MAE: 0.00027,  MAPE: 0.12%\n",
      "\n",
      "\n",
      "Trial No.120\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.15074,   MAE: 0.14188,  MAPE: 67.87%\n",
      "[100 Epochs]    RMSE:0.00534,   MAE: 0.00525,  MAPE: 2.52%\n",
      "[200 Epochs]    RMSE:0.00613,   MAE: 0.00607,  MAPE: 2.90%\n",
      "[300 Epochs]    RMSE:0.00260,   MAE: 0.00251,  MAPE: 1.20%\n",
      "[400 Epochs]    RMSE:0.00299,   MAE: 0.00289,  MAPE: 1.37%\n",
      "[500 Epochs]    RMSE:0.00314,   MAE: 0.00309,  MAPE: 1.47%\n",
      "[600 Epochs]    RMSE:0.00064,   MAE: 0.00054,  MAPE: 0.25%\n",
      "[700 Epochs]    RMSE:0.00265,   MAE: 0.00263,  MAPE: 1.26%\n",
      "[800 Epochs]    RMSE:0.00176,   MAE: 0.00171,  MAPE: 0.83%\n",
      "[900 Epochs]    RMSE:0.00187,   MAE: 0.00171,  MAPE: 0.80%\n",
      "[1000 Epochs]    RMSE:0.00166,   MAE: 0.00153,  MAPE: 0.72%\n",
      "[1100 Epochs]    RMSE:0.00206,   MAE: 0.00196,  MAPE: 0.93%\n",
      "[1200 Epochs]    RMSE:0.00264,   MAE: 0.00261,  MAPE: 1.24%\n",
      "[1300 Epochs]    RMSE:0.00202,   MAE: 0.00197,  MAPE: 0.95%\n",
      "[1400 Epochs]    RMSE:0.00084,   MAE: 0.00076,  MAPE: 0.37%\n",
      "[1500 Epochs]    RMSE:0.00044,   MAE: 0.00035,  MAPE: 0.17%\n",
      "[1600 Epochs]    RMSE:0.00148,   MAE: 0.00142,  MAPE: 0.68%\n",
      "[1700 Epochs]    RMSE:0.00137,   MAE: 0.00126,  MAPE: 0.59%\n",
      "[1800 Epochs]    RMSE:0.00104,   MAE: 0.00098,  MAPE: 0.48%\n",
      "[1900 Epochs]    RMSE:0.00060,   MAE: 0.00055,  MAPE: 0.27%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00041,   MAE: 0.00036,  MAPE: 0.17%\n",
      "\n",
      "\n",
      "Trial No.121\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.18046,   MAE: 0.17918,  MAPE: 85.39%\n",
      "[100 Epochs]    RMSE:0.00352,   MAE: 0.00337,  MAPE: 1.61%\n",
      "[200 Epochs]    RMSE:0.00467,   MAE: 0.00456,  MAPE: 2.20%\n",
      "[300 Epochs]    RMSE:0.00101,   MAE: 0.00072,  MAPE: 0.35%\n",
      "[400 Epochs]    RMSE:0.00220,   MAE: 0.00179,  MAPE: 0.86%\n",
      "[500 Epochs]    RMSE:0.00389,   MAE: 0.00386,  MAPE: 1.84%\n",
      "[600 Epochs]    RMSE:0.00309,   MAE: 0.00300,  MAPE: 1.42%\n",
      "[700 Epochs]    RMSE:0.00148,   MAE: 0.00133,  MAPE: 0.62%\n",
      "[800 Epochs]    RMSE:0.00152,   MAE: 0.00141,  MAPE: 0.68%\n",
      "[900 Epochs]    RMSE:0.01039,   MAE: 0.01014,  MAPE: 4.79%\n",
      "[1000 Epochs]    RMSE:0.00263,   MAE: 0.00250,  MAPE: 1.18%\n",
      "[1100 Epochs]    RMSE:0.00580,   MAE: 0.00574,  MAPE: 2.73%\n",
      "[1200 Epochs]    RMSE:0.00311,   MAE: 0.00305,  MAPE: 1.45%\n",
      "[1300 Epochs]    RMSE:0.00245,   MAE: 0.00229,  MAPE: 1.11%\n",
      "[1400 Epochs]    RMSE:0.00197,   MAE: 0.00192,  MAPE: 0.92%\n",
      "[1500 Epochs]    RMSE:0.00147,   MAE: 0.00139,  MAPE: 0.66%\n",
      "[1600 Epochs]    RMSE:0.00048,   MAE: 0.00036,  MAPE: 0.17%\n",
      "[1700 Epochs]    RMSE:0.00468,   MAE: 0.00461,  MAPE: 2.19%\n",
      "[1800 Epochs]    RMSE:0.00182,   MAE: 0.00178,  MAPE: 0.85%\n",
      "[1900 Epochs]    RMSE:0.00096,   MAE: 0.00090,  MAPE: 0.43%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00543,   MAE: 0.00527,  MAPE: 2.50%\n",
      "\n",
      "\n",
      "Trial No.122\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.23321,   MAE: 0.23053,  MAPE: 109.67%\n",
      "[100 Epochs]    RMSE:0.00334,   MAE: 0.00312,  MAPE: 1.50%\n",
      "[200 Epochs]    RMSE:0.00825,   MAE: 0.00819,  MAPE: 3.91%\n",
      "[300 Epochs]    RMSE:0.00111,   MAE: 0.00098,  MAPE: 0.47%\n",
      "[400 Epochs]    RMSE:0.00110,   MAE: 0.00087,  MAPE: 0.43%\n",
      "[500 Epochs]    RMSE:0.00581,   MAE: 0.00567,  MAPE: 2.69%\n",
      "[600 Epochs]    RMSE:0.00249,   MAE: 0.00245,  MAPE: 1.18%\n",
      "[700 Epochs]    RMSE:0.00593,   MAE: 0.00575,  MAPE: 2.72%\n",
      "[800 Epochs]    RMSE:0.00494,   MAE: 0.00464,  MAPE: 2.17%\n",
      "[900 Epochs]    RMSE:0.00183,   MAE: 0.00176,  MAPE: 0.85%\n",
      "[1000 Epochs]    RMSE:0.00027,   MAE: 0.00023,  MAPE: 0.11%\n",
      "[1100 Epochs]    RMSE:0.00380,   MAE: 0.00377,  MAPE: 1.80%\n",
      "[1200 Epochs]    RMSE:0.00295,   MAE: 0.00291,  MAPE: 1.39%\n",
      "[1300 Epochs]    RMSE:0.00295,   MAE: 0.00286,  MAPE: 1.35%\n",
      "[1400 Epochs]    RMSE:0.00205,   MAE: 0.00194,  MAPE: 0.91%\n",
      "[1500 Epochs]    RMSE:0.00109,   MAE: 0.00104,  MAPE: 0.49%\n",
      "[1600 Epochs]    RMSE:0.00271,   MAE: 0.00251,  MAPE: 1.23%\n",
      "[1700 Epochs]    RMSE:0.00109,   MAE: 0.00096,  MAPE: 0.45%\n",
      "[1800 Epochs]    RMSE:0.00602,   MAE: 0.00600,  MAPE: 2.87%\n",
      "[1900 Epochs]    RMSE:0.00526,   MAE: 0.00524,  MAPE: 2.50%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00305,   MAE: 0.00302,  MAPE: 1.44%\n",
      "\n",
      "\n",
      "Trial No.123\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.24338,   MAE: 0.23949,  MAPE: 114.16%\n",
      "[100 Epochs]    RMSE:0.00353,   MAE: 0.00291,  MAPE: 1.44%\n",
      "[200 Epochs]    RMSE:0.00137,   MAE: 0.00110,  MAPE: 0.51%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300 Epochs]    RMSE:0.00197,   MAE: 0.00185,  MAPE: 0.90%\n",
      "[400 Epochs]    RMSE:0.00371,   MAE: 0.00361,  MAPE: 1.71%\n",
      "[500 Epochs]    RMSE:0.00073,   MAE: 0.00066,  MAPE: 0.31%\n",
      "[600 Epochs]    RMSE:0.00187,   MAE: 0.00178,  MAPE: 0.85%\n",
      "[700 Epochs]    RMSE:0.00272,   MAE: 0.00223,  MAPE: 1.11%\n",
      "[800 Epochs]    RMSE:0.00288,   MAE: 0.00237,  MAPE: 1.18%\n",
      "[900 Epochs]    RMSE:0.00430,   MAE: 0.00427,  MAPE: 2.04%\n",
      "[1000 Epochs]    RMSE:0.00177,   MAE: 0.00159,  MAPE: 0.75%\n",
      "[1100 Epochs]    RMSE:0.00207,   MAE: 0.00200,  MAPE: 0.96%\n",
      "[1200 Epochs]    RMSE:0.00180,   MAE: 0.00178,  MAPE: 0.85%\n",
      "[1300 Epochs]    RMSE:0.00100,   MAE: 0.00078,  MAPE: 0.39%\n",
      "[1400 Epochs]    RMSE:0.00562,   MAE: 0.00546,  MAPE: 2.58%\n",
      "[1500 Epochs]    RMSE:0.00139,   MAE: 0.00110,  MAPE: 0.51%\n",
      "[1600 Epochs]    RMSE:0.00215,   MAE: 0.00203,  MAPE: 0.99%\n",
      "[1700 Epochs]    RMSE:0.00178,   MAE: 0.00168,  MAPE: 0.79%\n",
      "[1800 Epochs]    RMSE:0.00169,   MAE: 0.00163,  MAPE: 0.78%\n",
      "[1900 Epochs]    RMSE:0.00107,   MAE: 0.00092,  MAPE: 0.44%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00069,   MAE: 0.00059,  MAPE: 0.28%\n",
      "\n",
      "\n",
      "Trial No.124\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.11948,   MAE: 0.10343,  MAPE: 50.27%\n",
      "[100 Epochs]    RMSE:0.01304,   MAE: 0.01268,  MAPE: 5.99%\n",
      "[200 Epochs]    RMSE:0.00717,   MAE: 0.00713,  MAPE: 3.43%\n",
      "[300 Epochs]    RMSE:0.00137,   MAE: 0.00127,  MAPE: 0.61%\n",
      "[400 Epochs]    RMSE:0.00120,   MAE: 0.00098,  MAPE: 0.46%\n",
      "[500 Epochs]    RMSE:0.00331,   MAE: 0.00287,  MAPE: 1.33%\n",
      "[600 Epochs]    RMSE:0.00222,   MAE: 0.00197,  MAPE: 0.92%\n",
      "[700 Epochs]    RMSE:0.00145,   MAE: 0.00138,  MAPE: 0.65%\n",
      "[800 Epochs]    RMSE:0.00464,   MAE: 0.00455,  MAPE: 2.20%\n",
      "[900 Epochs]    RMSE:0.00235,   MAE: 0.00224,  MAPE: 1.06%\n",
      "[1000 Epochs]    RMSE:0.00174,   MAE: 0.00162,  MAPE: 0.78%\n",
      "[1100 Epochs]    RMSE:0.00262,   MAE: 0.00255,  MAPE: 1.21%\n",
      "[1200 Epochs]    RMSE:0.00085,   MAE: 0.00066,  MAPE: 0.33%\n",
      "[1300 Epochs]    RMSE:0.00285,   MAE: 0.00270,  MAPE: 1.27%\n",
      "[1400 Epochs]    RMSE:0.00350,   MAE: 0.00345,  MAPE: 1.64%\n",
      "[1500 Epochs]    RMSE:0.00204,   MAE: 0.00197,  MAPE: 0.93%\n",
      "[1600 Epochs]    RMSE:0.00093,   MAE: 0.00064,  MAPE: 0.32%\n",
      "[1700 Epochs]    RMSE:0.00084,   MAE: 0.00060,  MAPE: 0.30%\n",
      "[1800 Epochs]    RMSE:0.00066,   MAE: 0.00052,  MAPE: 0.26%\n",
      "[1900 Epochs]    RMSE:0.00089,   MAE: 0.00076,  MAPE: 0.35%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00041,   MAE: 0.00033,  MAPE: 0.16%\n",
      "\n",
      "\n",
      "Trial No.125\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.30110,   MAE: 0.29707,  MAPE: 142.19%\n",
      "[100 Epochs]    RMSE:0.00256,   MAE: 0.00234,  MAPE: 1.10%\n",
      "[200 Epochs]    RMSE:0.00197,   MAE: 0.00160,  MAPE: 0.78%\n",
      "[300 Epochs]    RMSE:0.00493,   MAE: 0.00478,  MAPE: 2.29%\n",
      "[400 Epochs]    RMSE:0.00663,   MAE: 0.00641,  MAPE: 3.03%\n",
      "[500 Epochs]    RMSE:0.00447,   MAE: 0.00421,  MAPE: 1.97%\n",
      "[600 Epochs]    RMSE:0.00148,   MAE: 0.00132,  MAPE: 0.63%\n",
      "[700 Epochs]    RMSE:0.00089,   MAE: 0.00079,  MAPE: 0.38%\n",
      "[800 Epochs]    RMSE:0.00064,   MAE: 0.00051,  MAPE: 0.24%\n",
      "[900 Epochs]    RMSE:0.00155,   MAE: 0.00106,  MAPE: 0.51%\n",
      "[1000 Epochs]    RMSE:0.00490,   MAE: 0.00478,  MAPE: 2.26%\n",
      "[1100 Epochs]    RMSE:0.00759,   MAE: 0.00755,  MAPE: 3.62%\n",
      "[1200 Epochs]    RMSE:0.00304,   MAE: 0.00277,  MAPE: 1.29%\n",
      "[1300 Epochs]    RMSE:0.00451,   MAE: 0.00439,  MAPE: 2.09%\n",
      "[1400 Epochs]    RMSE:0.00332,   MAE: 0.00326,  MAPE: 1.55%\n",
      "[1500 Epochs]    RMSE:0.00254,   MAE: 0.00249,  MAPE: 1.18%\n",
      "[1600 Epochs]    RMSE:0.00469,   MAE: 0.00462,  MAPE: 2.19%\n",
      "[1700 Epochs]    RMSE:0.00114,   MAE: 0.00110,  MAPE: 0.53%\n",
      "[1800 Epochs]    RMSE:0.00446,   MAE: 0.00437,  MAPE: 2.11%\n",
      "[1900 Epochs]    RMSE:0.00137,   MAE: 0.00116,  MAPE: 0.54%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00312,   MAE: 0.00311,  MAPE: 1.49%\n",
      "\n",
      "\n",
      "Trial No.126\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.25147,   MAE: 0.24963,  MAPE: 119.95%\n",
      "[100 Epochs]    RMSE:0.00169,   MAE: 0.00152,  MAPE: 0.74%\n",
      "[200 Epochs]    RMSE:0.00734,   MAE: 0.00721,  MAPE: 3.43%\n",
      "[300 Epochs]    RMSE:0.00106,   MAE: 0.00078,  MAPE: 0.37%\n",
      "[400 Epochs]    RMSE:0.00331,   MAE: 0.00327,  MAPE: 1.56%\n",
      "[500 Epochs]    RMSE:0.00377,   MAE: 0.00368,  MAPE: 1.75%\n",
      "[600 Epochs]    RMSE:0.00382,   MAE: 0.00372,  MAPE: 1.78%\n",
      "[700 Epochs]    RMSE:0.00774,   MAE: 0.00756,  MAPE: 3.57%\n",
      "[800 Epochs]    RMSE:0.00191,   MAE: 0.00158,  MAPE: 0.73%\n",
      "[900 Epochs]    RMSE:0.00078,   MAE: 0.00067,  MAPE: 0.32%\n",
      "[1000 Epochs]    RMSE:0.00329,   MAE: 0.00324,  MAPE: 1.55%\n",
      "[1100 Epochs]    RMSE:0.00120,   MAE: 0.00104,  MAPE: 0.49%\n",
      "[1200 Epochs]    RMSE:0.00206,   MAE: 0.00205,  MAPE: 0.98%\n",
      "[1300 Epochs]    RMSE:0.00094,   MAE: 0.00092,  MAPE: 0.44%\n",
      "[1400 Epochs]    RMSE:0.00094,   MAE: 0.00078,  MAPE: 0.36%\n",
      "[1500 Epochs]    RMSE:0.00404,   MAE: 0.00392,  MAPE: 1.85%\n",
      "[1600 Epochs]    RMSE:0.00477,   MAE: 0.00464,  MAPE: 2.25%\n",
      "[1700 Epochs]    RMSE:0.00113,   MAE: 0.00092,  MAPE: 0.43%\n",
      "[1800 Epochs]    RMSE:0.00164,   MAE: 0.00162,  MAPE: 0.78%\n",
      "[1900 Epochs]    RMSE:0.00212,   MAE: 0.00208,  MAPE: 1.00%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00146,   MAE: 0.00132,  MAPE: 0.61%\n",
      "\n",
      "\n",
      "Trial No.127\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.31566,   MAE: 0.30832,  MAPE: 145.84%\n",
      "[100 Epochs]    RMSE:0.00186,   MAE: 0.00157,  MAPE: 0.76%\n",
      "[200 Epochs]    RMSE:0.00573,   MAE: 0.00560,  MAPE: 2.70%\n",
      "[300 Epochs]    RMSE:0.00498,   MAE: 0.00483,  MAPE: 2.29%\n",
      "[400 Epochs]    RMSE:0.00414,   MAE: 0.00401,  MAPE: 1.90%\n",
      "[500 Epochs]    RMSE:0.00131,   MAE: 0.00111,  MAPE: 0.53%\n",
      "[600 Epochs]    RMSE:0.00220,   MAE: 0.00211,  MAPE: 1.00%\n",
      "[700 Epochs]    RMSE:0.00138,   MAE: 0.00132,  MAPE: 0.62%\n",
      "[800 Epochs]    RMSE:0.00316,   MAE: 0.00312,  MAPE: 1.49%\n",
      "[900 Epochs]    RMSE:0.00121,   MAE: 0.00108,  MAPE: 0.53%\n",
      "[1000 Epochs]    RMSE:0.00558,   MAE: 0.00554,  MAPE: 2.65%\n",
      "[1100 Epochs]    RMSE:0.00145,   MAE: 0.00140,  MAPE: 0.68%\n",
      "[1200 Epochs]    RMSE:0.00172,   MAE: 0.00167,  MAPE: 0.80%\n",
      "[1300 Epochs]    RMSE:0.00236,   MAE: 0.00228,  MAPE: 1.08%\n",
      "[1400 Epochs]    RMSE:0.00146,   MAE: 0.00144,  MAPE: 0.69%\n",
      "[1500 Epochs]    RMSE:0.00084,   MAE: 0.00066,  MAPE: 0.31%\n",
      "[1600 Epochs]    RMSE:0.00093,   MAE: 0.00082,  MAPE: 0.38%\n",
      "[1700 Epochs]    RMSE:0.00253,   MAE: 0.00247,  MAPE: 1.19%\n",
      "[1800 Epochs]    RMSE:0.00159,   MAE: 0.00157,  MAPE: 0.75%\n",
      "[1900 Epochs]    RMSE:0.00176,   MAE: 0.00173,  MAPE: 0.83%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00065,   MAE: 0.00057,  MAPE: 0.27%\n",
      "\n",
      "\n",
      "Trial No.128\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.29682,   MAE: 0.29234,  MAPE: 138.85%\n",
      "[100 Epochs]    RMSE:0.00486,   MAE: 0.00443,  MAPE: 2.15%\n",
      "[200 Epochs]    RMSE:0.00154,   MAE: 0.00122,  MAPE: 0.58%\n",
      "[300 Epochs]    RMSE:0.00289,   MAE: 0.00246,  MAPE: 1.15%\n",
      "[400 Epochs]    RMSE:0.00414,   MAE: 0.00389,  MAPE: 1.83%\n",
      "[500 Epochs]    RMSE:0.00244,   MAE: 0.00233,  MAPE: 1.13%\n",
      "[600 Epochs]    RMSE:0.00402,   MAE: 0.00375,  MAPE: 1.76%\n",
      "[700 Epochs]    RMSE:0.00133,   MAE: 0.00124,  MAPE: 0.58%\n",
      "[800 Epochs]    RMSE:0.00170,   MAE: 0.00160,  MAPE: 0.77%\n",
      "[900 Epochs]    RMSE:0.00859,   MAE: 0.00829,  MAPE: 3.93%\n",
      "[1000 Epochs]    RMSE:0.00098,   MAE: 0.00088,  MAPE: 0.43%\n",
      "[1100 Epochs]    RMSE:0.00444,   MAE: 0.00431,  MAPE: 2.03%\n",
      "[1200 Epochs]    RMSE:0.00181,   MAE: 0.00172,  MAPE: 0.81%\n",
      "[1300 Epochs]    RMSE:0.00346,   MAE: 0.00325,  MAPE: 1.52%\n",
      "[1400 Epochs]    RMSE:0.00049,   MAE: 0.00040,  MAPE: 0.19%\n",
      "[1500 Epochs]    RMSE:0.00229,   MAE: 0.00224,  MAPE: 1.08%\n",
      "[1600 Epochs]    RMSE:0.00040,   MAE: 0.00034,  MAPE: 0.16%\n",
      "[1700 Epochs]    RMSE:0.00058,   MAE: 0.00043,  MAPE: 0.21%\n",
      "[1800 Epochs]    RMSE:0.00307,   MAE: 0.00293,  MAPE: 1.38%\n",
      "[1900 Epochs]    RMSE:0.00061,   MAE: 0.00051,  MAPE: 0.25%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00050,   MAE: 0.00042,  MAPE: 0.20%\n",
      "\n",
      "\n",
      "Trial No.129\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.37391,   MAE: 0.36290,  MAPE: 174.68%\n",
      "[100 Epochs]    RMSE:0.00694,   MAE: 0.00688,  MAPE: 3.29%\n",
      "[200 Epochs]    RMSE:0.00923,   MAE: 0.00873,  MAPE: 4.10%\n",
      "[300 Epochs]    RMSE:0.00414,   MAE: 0.00406,  MAPE: 1.95%\n",
      "[400 Epochs]    RMSE:0.00090,   MAE: 0.00072,  MAPE: 0.35%\n",
      "[500 Epochs]    RMSE:0.00203,   MAE: 0.00197,  MAPE: 0.94%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600 Epochs]    RMSE:0.00143,   MAE: 0.00130,  MAPE: 0.62%\n",
      "[700 Epochs]    RMSE:0.00233,   MAE: 0.00216,  MAPE: 1.02%\n",
      "[800 Epochs]    RMSE:0.00094,   MAE: 0.00069,  MAPE: 0.32%\n",
      "[900 Epochs]    RMSE:0.00355,   MAE: 0.00336,  MAPE: 1.59%\n",
      "[1000 Epochs]    RMSE:0.00307,   MAE: 0.00297,  MAPE: 1.40%\n",
      "[1100 Epochs]    RMSE:0.00395,   MAE: 0.00391,  MAPE: 1.88%\n",
      "[1200 Epochs]    RMSE:0.00135,   MAE: 0.00124,  MAPE: 0.59%\n",
      "[1300 Epochs]    RMSE:0.00349,   MAE: 0.00340,  MAPE: 1.61%\n",
      "[1400 Epochs]    RMSE:0.00161,   MAE: 0.00144,  MAPE: 0.67%\n",
      "[1500 Epochs]    RMSE:0.00103,   MAE: 0.00083,  MAPE: 0.41%\n",
      "[1600 Epochs]    RMSE:0.00099,   MAE: 0.00081,  MAPE: 0.38%\n",
      "[1700 Epochs]    RMSE:0.00089,   MAE: 0.00078,  MAPE: 0.38%\n",
      "[1800 Epochs]    RMSE:0.00098,   MAE: 0.00082,  MAPE: 0.40%\n",
      "[1900 Epochs]    RMSE:0.00141,   MAE: 0.00135,  MAPE: 0.65%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00073,   MAE: 0.00058,  MAPE: 0.27%\n",
      "\n",
      "\n",
      "Trial No.130\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.14788,   MAE: 0.14574,  MAPE: 69.78%\n",
      "[100 Epochs]    RMSE:0.00692,   MAE: 0.00678,  MAPE: 3.22%\n",
      "[200 Epochs]    RMSE:0.00328,   MAE: 0.00310,  MAPE: 1.49%\n",
      "[300 Epochs]    RMSE:0.00554,   MAE: 0.00546,  MAPE: 2.59%\n",
      "[400 Epochs]    RMSE:0.00518,   MAE: 0.00489,  MAPE: 2.29%\n",
      "[500 Epochs]    RMSE:0.00626,   MAE: 0.00605,  MAPE: 2.94%\n",
      "[600 Epochs]    RMSE:0.00167,   MAE: 0.00144,  MAPE: 0.67%\n",
      "[700 Epochs]    RMSE:0.00119,   MAE: 0.00103,  MAPE: 0.50%\n",
      "[800 Epochs]    RMSE:0.00080,   MAE: 0.00074,  MAPE: 0.36%\n",
      "[900 Epochs]    RMSE:0.00250,   MAE: 0.00247,  MAPE: 1.18%\n",
      "[1000 Epochs]    RMSE:0.00134,   MAE: 0.00130,  MAPE: 0.62%\n",
      "[1100 Epochs]    RMSE:0.00122,   MAE: 0.00103,  MAPE: 0.48%\n",
      "[1200 Epochs]    RMSE:0.00164,   MAE: 0.00159,  MAPE: 0.75%\n",
      "[1300 Epochs]    RMSE:0.00336,   MAE: 0.00322,  MAPE: 1.52%\n",
      "[1400 Epochs]    RMSE:0.00345,   MAE: 0.00337,  MAPE: 1.63%\n",
      "[1500 Epochs]    RMSE:0.00147,   MAE: 0.00143,  MAPE: 0.68%\n",
      "[1600 Epochs]    RMSE:0.00138,   MAE: 0.00109,  MAPE: 0.50%\n",
      "[1700 Epochs]    RMSE:0.00056,   MAE: 0.00054,  MAPE: 0.26%\n",
      "[1800 Epochs]    RMSE:0.00181,   MAE: 0.00178,  MAPE: 0.85%\n",
      "[1900 Epochs]    RMSE:0.00089,   MAE: 0.00086,  MAPE: 0.41%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00364,   MAE: 0.00362,  MAPE: 1.73%\n",
      "\n",
      "\n",
      "Trial No.131\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.20519,   MAE: 0.19542,  MAPE: 94.88%\n",
      "[100 Epochs]    RMSE:0.00544,   MAE: 0.00533,  MAPE: 2.54%\n",
      "[200 Epochs]    RMSE:0.00167,   MAE: 0.00150,  MAPE: 0.73%\n",
      "[300 Epochs]    RMSE:0.00094,   MAE: 0.00071,  MAPE: 0.35%\n",
      "[400 Epochs]    RMSE:0.00349,   MAE: 0.00331,  MAPE: 1.56%\n",
      "[500 Epochs]    RMSE:0.00699,   MAE: 0.00696,  MAPE: 3.34%\n",
      "[600 Epochs]    RMSE:0.00253,   MAE: 0.00236,  MAPE: 1.12%\n",
      "[700 Epochs]    RMSE:0.00488,   MAE: 0.00480,  MAPE: 2.30%\n",
      "[800 Epochs]    RMSE:0.00170,   MAE: 0.00158,  MAPE: 0.76%\n",
      "[900 Epochs]    RMSE:0.00144,   MAE: 0.00140,  MAPE: 0.67%\n",
      "[1000 Epochs]    RMSE:0.00270,   MAE: 0.00263,  MAPE: 1.25%\n",
      "[1100 Epochs]    RMSE:0.00291,   MAE: 0.00281,  MAPE: 1.34%\n",
      "[1200 Epochs]    RMSE:0.00331,   MAE: 0.00300,  MAPE: 1.40%\n",
      "[1300 Epochs]    RMSE:0.00373,   MAE: 0.00361,  MAPE: 1.70%\n",
      "[1400 Epochs]    RMSE:0.00057,   MAE: 0.00048,  MAPE: 0.22%\n",
      "[1500 Epochs]    RMSE:0.00195,   MAE: 0.00171,  MAPE: 0.80%\n",
      "[1600 Epochs]    RMSE:0.00091,   MAE: 0.00083,  MAPE: 0.40%\n",
      "[1700 Epochs]    RMSE:0.00084,   MAE: 0.00074,  MAPE: 0.36%\n",
      "[1800 Epochs]    RMSE:0.00034,   MAE: 0.00026,  MAPE: 0.13%\n",
      "[1900 Epochs]    RMSE:0.00162,   MAE: 0.00151,  MAPE: 0.71%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00134,   MAE: 0.00117,  MAPE: 0.54%\n",
      "\n",
      "\n",
      "Trial No.132\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.25242,   MAE: 0.25041,  MAPE: 120.35%\n",
      "[100 Epochs]    RMSE:0.01023,   MAE: 0.01010,  MAPE: 4.84%\n",
      "[200 Epochs]    RMSE:0.00396,   MAE: 0.00368,  MAPE: 1.73%\n",
      "[300 Epochs]    RMSE:0.00297,   MAE: 0.00267,  MAPE: 1.25%\n",
      "[400 Epochs]    RMSE:0.00919,   MAE: 0.00908,  MAPE: 4.39%\n",
      "[500 Epochs]    RMSE:0.00125,   MAE: 0.00102,  MAPE: 0.48%\n",
      "[600 Epochs]    RMSE:0.00221,   MAE: 0.00190,  MAPE: 0.88%\n",
      "[700 Epochs]    RMSE:0.00483,   MAE: 0.00467,  MAPE: 2.21%\n",
      "[800 Epochs]    RMSE:0.00079,   MAE: 0.00066,  MAPE: 0.31%\n",
      "[900 Epochs]    RMSE:0.00260,   MAE: 0.00253,  MAPE: 1.20%\n",
      "[1000 Epochs]    RMSE:0.00157,   MAE: 0.00134,  MAPE: 0.67%\n",
      "[1100 Epochs]    RMSE:0.00115,   MAE: 0.00093,  MAPE: 0.46%\n",
      "[1200 Epochs]    RMSE:0.00184,   MAE: 0.00160,  MAPE: 0.79%\n",
      "[1300 Epochs]    RMSE:0.00269,   MAE: 0.00250,  MAPE: 1.18%\n",
      "[1400 Epochs]    RMSE:0.00144,   MAE: 0.00128,  MAPE: 0.60%\n",
      "[1500 Epochs]    RMSE:0.00044,   MAE: 0.00035,  MAPE: 0.17%\n",
      "[1600 Epochs]    RMSE:0.00234,   MAE: 0.00229,  MAPE: 1.10%\n",
      "[1700 Epochs]    RMSE:0.00299,   MAE: 0.00285,  MAPE: 1.34%\n",
      "[1800 Epochs]    RMSE:0.00181,   MAE: 0.00171,  MAPE: 0.81%\n",
      "[1900 Epochs]    RMSE:0.00103,   MAE: 0.00081,  MAPE: 0.38%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00108,   MAE: 0.00105,  MAPE: 0.50%\n",
      "\n",
      "\n",
      "Trial No.133\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 80\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.29087,   MAE: 0.27626,  MAPE: 131.75%\n",
      "[100 Epochs]    RMSE:0.00150,   MAE: 0.00115,  MAPE: 0.56%\n",
      "[200 Epochs]    RMSE:0.00310,   MAE: 0.00304,  MAPE: 1.46%\n",
      "[300 Epochs]    RMSE:0.00612,   MAE: 0.00584,  MAPE: 2.75%\n",
      "[400 Epochs]    RMSE:0.00159,   MAE: 0.00147,  MAPE: 0.72%\n",
      "[500 Epochs]    RMSE:0.00885,   MAE: 0.00867,  MAPE: 4.11%\n",
      "[600 Epochs]    RMSE:0.00112,   MAE: 0.00093,  MAPE: 0.45%\n",
      "[700 Epochs]    RMSE:0.00287,   MAE: 0.00274,  MAPE: 1.29%\n",
      "[800 Epochs]    RMSE:0.00671,   MAE: 0.00669,  MAPE: 3.22%\n",
      "[900 Epochs]    RMSE:0.00578,   MAE: 0.00577,  MAPE: 2.76%\n",
      "[1000 Epochs]    RMSE:0.00283,   MAE: 0.00261,  MAPE: 1.22%\n",
      "[1100 Epochs]    RMSE:0.00221,   MAE: 0.00213,  MAPE: 1.02%\n",
      "[1200 Epochs]    RMSE:0.00377,   MAE: 0.00374,  MAPE: 1.80%\n",
      "[1300 Epochs]    RMSE:0.00103,   MAE: 0.00094,  MAPE: 0.45%\n",
      "[1400 Epochs]    RMSE:0.00156,   MAE: 0.00149,  MAPE: 0.72%\n",
      "[1500 Epochs]    RMSE:0.00223,   MAE: 0.00217,  MAPE: 1.03%\n",
      "[1600 Epochs]    RMSE:0.00073,   MAE: 0.00063,  MAPE: 0.31%\n",
      "[1700 Epochs]    RMSE:0.00146,   MAE: 0.00125,  MAPE: 0.58%\n",
      "[1800 Epochs]    RMSE:0.00120,   MAE: 0.00097,  MAPE: 0.44%\n",
      "[1900 Epochs]    RMSE:0.00141,   MAE: 0.00130,  MAPE: 0.62%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00229,   MAE: 0.00220,  MAPE: 1.07%\n",
      "\n",
      "\n",
      "Trial No.134\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.25356,   MAE: 0.24638,  MAPE: 117.43%\n",
      "[100 Epochs]    RMSE:0.00464,   MAE: 0.00450,  MAPE: 2.17%\n",
      "[200 Epochs]    RMSE:0.00111,   MAE: 0.00088,  MAPE: 0.43%\n",
      "[300 Epochs]    RMSE:0.00529,   MAE: 0.00521,  MAPE: 2.52%\n",
      "[400 Epochs]    RMSE:0.00326,   MAE: 0.00318,  MAPE: 1.51%\n",
      "[500 Epochs]    RMSE:0.00357,   MAE: 0.00352,  MAPE: 1.68%\n",
      "[600 Epochs]    RMSE:0.00125,   MAE: 0.00098,  MAPE: 0.49%\n",
      "[700 Epochs]    RMSE:0.00124,   MAE: 0.00107,  MAPE: 0.51%\n",
      "[800 Epochs]    RMSE:0.00129,   MAE: 0.00112,  MAPE: 0.53%\n",
      "[900 Epochs]    RMSE:0.00151,   MAE: 0.00143,  MAPE: 0.69%\n",
      "[1000 Epochs]    RMSE:0.00230,   MAE: 0.00205,  MAPE: 0.96%\n",
      "[1100 Epochs]    RMSE:0.00422,   MAE: 0.00404,  MAPE: 1.91%\n",
      "[1200 Epochs]    RMSE:0.00342,   MAE: 0.00329,  MAPE: 1.60%\n",
      "[1300 Epochs]    RMSE:0.00052,   MAE: 0.00043,  MAPE: 0.20%\n",
      "[1400 Epochs]    RMSE:0.00090,   MAE: 0.00076,  MAPE: 0.35%\n",
      "[1500 Epochs]    RMSE:0.00187,   MAE: 0.00171,  MAPE: 0.84%\n",
      "[1600 Epochs]    RMSE:0.00202,   MAE: 0.00192,  MAPE: 0.90%\n",
      "[1700 Epochs]    RMSE:0.00271,   MAE: 0.00248,  MAPE: 1.16%\n",
      "[1800 Epochs]    RMSE:0.00202,   MAE: 0.00189,  MAPE: 0.89%\n",
      "[1900 Epochs]    RMSE:0.00187,   MAE: 0.00178,  MAPE: 0.85%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00207,   MAE: 0.00204,  MAPE: 0.97%\n",
      "\n",
      "\n",
      "Trial No.135\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.34263,   MAE: 0.32932,  MAPE: 158.38%\n",
      "[100 Epochs]    RMSE:0.00180,   MAE: 0.00139,  MAPE: 0.66%\n",
      "[200 Epochs]    RMSE:0.00878,   MAE: 0.00874,  MAPE: 4.17%\n",
      "[300 Epochs]    RMSE:0.00655,   MAE: 0.00652,  MAPE: 3.12%\n",
      "[400 Epochs]    RMSE:0.00159,   MAE: 0.00145,  MAPE: 0.71%\n",
      "[500 Epochs]    RMSE:0.00546,   MAE: 0.00526,  MAPE: 2.48%\n",
      "[600 Epochs]    RMSE:0.00590,   MAE: 0.00571,  MAPE: 2.70%\n",
      "[700 Epochs]    RMSE:0.00082,   MAE: 0.00071,  MAPE: 0.34%\n",
      "[800 Epochs]    RMSE:0.00083,   MAE: 0.00077,  MAPE: 0.37%\n",
      "[900 Epochs]    RMSE:0.00244,   MAE: 0.00241,  MAPE: 1.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000 Epochs]    RMSE:0.00270,   MAE: 0.00256,  MAPE: 1.21%\n",
      "[1100 Epochs]    RMSE:0.00312,   MAE: 0.00309,  MAPE: 1.48%\n",
      "[1200 Epochs]    RMSE:0.00145,   MAE: 0.00131,  MAPE: 0.61%\n",
      "[1300 Epochs]    RMSE:0.00139,   MAE: 0.00122,  MAPE: 0.60%\n",
      "[1400 Epochs]    RMSE:0.00124,   MAE: 0.00120,  MAPE: 0.57%\n",
      "[1500 Epochs]    RMSE:0.00182,   MAE: 0.00168,  MAPE: 0.79%\n",
      "[1600 Epochs]    RMSE:0.00215,   MAE: 0.00210,  MAPE: 1.00%\n",
      "[1700 Epochs]    RMSE:0.00382,   MAE: 0.00380,  MAPE: 1.81%\n",
      "[1800 Epochs]    RMSE:0.00191,   MAE: 0.00180,  MAPE: 0.86%\n",
      "[1900 Epochs]    RMSE:0.00101,   MAE: 0.00096,  MAPE: 0.46%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00079,   MAE: 0.00065,  MAPE: 0.31%\n",
      "\n",
      "\n",
      "Trial No.136\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.22785,   MAE: 0.22399,  MAPE: 106.14%\n",
      "[100 Epochs]    RMSE:0.00657,   MAE: 0.00638,  MAPE: 3.03%\n",
      "[200 Epochs]    RMSE:0.00123,   MAE: 0.00105,  MAPE: 0.51%\n",
      "[300 Epochs]    RMSE:0.00271,   MAE: 0.00255,  MAPE: 1.21%\n",
      "[400 Epochs]    RMSE:0.00349,   MAE: 0.00341,  MAPE: 1.64%\n",
      "[500 Epochs]    RMSE:0.00175,   MAE: 0.00167,  MAPE: 0.80%\n",
      "[600 Epochs]    RMSE:0.00077,   MAE: 0.00065,  MAPE: 0.31%\n",
      "[700 Epochs]    RMSE:0.00141,   MAE: 0.00129,  MAPE: 0.63%\n",
      "[800 Epochs]    RMSE:0.00157,   MAE: 0.00142,  MAPE: 0.68%\n",
      "[900 Epochs]    RMSE:0.00093,   MAE: 0.00083,  MAPE: 0.40%\n",
      "[1000 Epochs]    RMSE:0.00151,   MAE: 0.00143,  MAPE: 0.69%\n",
      "[1100 Epochs]    RMSE:0.00075,   MAE: 0.00062,  MAPE: 0.29%\n",
      "[1200 Epochs]    RMSE:0.00199,   MAE: 0.00195,  MAPE: 0.93%\n",
      "[1300 Epochs]    RMSE:0.00133,   MAE: 0.00125,  MAPE: 0.59%\n",
      "[1400 Epochs]    RMSE:0.00322,   MAE: 0.00315,  MAPE: 1.50%\n",
      "[1500 Epochs]    RMSE:0.00148,   MAE: 0.00145,  MAPE: 0.69%\n",
      "[1600 Epochs]    RMSE:0.00102,   MAE: 0.00089,  MAPE: 0.41%\n",
      "[1700 Epochs]    RMSE:0.00103,   MAE: 0.00095,  MAPE: 0.45%\n",
      "[1800 Epochs]    RMSE:0.00058,   MAE: 0.00051,  MAPE: 0.25%\n",
      "[1900 Epochs]    RMSE:0.00463,   MAE: 0.00458,  MAPE: 2.18%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00199,   MAE: 0.00192,  MAPE: 0.90%\n",
      "\n",
      "\n",
      "Trial No.137\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.19752,   MAE: 0.19406,  MAPE: 92.68%\n",
      "[100 Epochs]    RMSE:0.00865,   MAE: 0.00846,  MAPE: 4.01%\n",
      "[200 Epochs]    RMSE:0.00173,   MAE: 0.00149,  MAPE: 0.70%\n",
      "[300 Epochs]    RMSE:0.00218,   MAE: 0.00181,  MAPE: 0.89%\n",
      "[400 Epochs]    RMSE:0.00285,   MAE: 0.00210,  MAPE: 1.06%\n",
      "[500 Epochs]    RMSE:0.00098,   MAE: 0.00085,  MAPE: 0.41%\n",
      "[600 Epochs]    RMSE:0.00190,   MAE: 0.00161,  MAPE: 0.74%\n",
      "[700 Epochs]    RMSE:0.00507,   MAE: 0.00487,  MAPE: 2.29%\n",
      "[800 Epochs]    RMSE:0.00045,   MAE: 0.00035,  MAPE: 0.17%\n",
      "[900 Epochs]    RMSE:0.00299,   MAE: 0.00294,  MAPE: 1.42%\n",
      "[1000 Epochs]    RMSE:0.00141,   MAE: 0.00123,  MAPE: 0.58%\n",
      "[1100 Epochs]    RMSE:0.00787,   MAE: 0.00783,  MAPE: 3.74%\n",
      "[1200 Epochs]    RMSE:0.00104,   MAE: 0.00063,  MAPE: 0.30%\n",
      "[1300 Epochs]    RMSE:0.00114,   MAE: 0.00102,  MAPE: 0.48%\n",
      "[1400 Epochs]    RMSE:0.00202,   MAE: 0.00194,  MAPE: 0.93%\n",
      "[1500 Epochs]    RMSE:0.00227,   MAE: 0.00195,  MAPE: 0.90%\n",
      "[1600 Epochs]    RMSE:0.00140,   MAE: 0.00116,  MAPE: 0.58%\n",
      "[1700 Epochs]    RMSE:0.00101,   MAE: 0.00090,  MAPE: 0.42%\n",
      "[1800 Epochs]    RMSE:0.00083,   MAE: 0.00068,  MAPE: 0.34%\n",
      "[1900 Epochs]    RMSE:0.00137,   MAE: 0.00124,  MAPE: 0.58%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00052,   MAE: 0.00043,  MAPE: 0.20%\n",
      "\n",
      "\n",
      "Trial No.138\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.17305,   MAE: 0.16921,  MAPE: 81.66%\n",
      "[100 Epochs]    RMSE:0.00364,   MAE: 0.00343,  MAPE: 1.62%\n",
      "[200 Epochs]    RMSE:0.00600,   MAE: 0.00594,  MAPE: 2.83%\n",
      "[300 Epochs]    RMSE:0.00709,   MAE: 0.00692,  MAPE: 3.32%\n",
      "[400 Epochs]    RMSE:0.00143,   MAE: 0.00119,  MAPE: 0.55%\n",
      "[500 Epochs]    RMSE:0.00335,   MAE: 0.00321,  MAPE: 1.51%\n",
      "[600 Epochs]    RMSE:0.00649,   MAE: 0.00623,  MAPE: 2.93%\n",
      "[700 Epochs]    RMSE:0.00220,   MAE: 0.00204,  MAPE: 1.00%\n",
      "[800 Epochs]    RMSE:0.00738,   MAE: 0.00736,  MAPE: 3.52%\n",
      "[900 Epochs]    RMSE:0.00071,   MAE: 0.00055,  MAPE: 0.26%\n",
      "[1000 Epochs]    RMSE:0.00057,   MAE: 0.00050,  MAPE: 0.24%\n",
      "[1100 Epochs]    RMSE:0.00119,   MAE: 0.00106,  MAPE: 0.50%\n",
      "[1200 Epochs]    RMSE:0.00238,   MAE: 0.00227,  MAPE: 1.07%\n",
      "[1300 Epochs]    RMSE:0.00458,   MAE: 0.00433,  MAPE: 2.03%\n",
      "[1400 Epochs]    RMSE:0.00060,   MAE: 0.00055,  MAPE: 0.27%\n",
      "[1500 Epochs]    RMSE:0.00295,   MAE: 0.00291,  MAPE: 1.38%\n",
      "[1600 Epochs]    RMSE:0.00533,   MAE: 0.00518,  MAPE: 2.45%\n",
      "[1700 Epochs]    RMSE:0.00047,   MAE: 0.00040,  MAPE: 0.19%\n",
      "[1800 Epochs]    RMSE:0.00215,   MAE: 0.00198,  MAPE: 0.93%\n",
      "[1900 Epochs]    RMSE:0.00174,   MAE: 0.00161,  MAPE: 0.75%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00087,   MAE: 0.00068,  MAPE: 0.31%\n",
      "\n",
      "\n",
      "Trial No.139\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.23068,   MAE: 0.22885,  MAPE: 109.90%\n",
      "[100 Epochs]    RMSE:0.00277,   MAE: 0.00251,  MAPE: 1.18%\n",
      "[200 Epochs]    RMSE:0.00489,   MAE: 0.00431,  MAPE: 2.00%\n",
      "[300 Epochs]    RMSE:0.00308,   MAE: 0.00272,  MAPE: 1.30%\n",
      "[400 Epochs]    RMSE:0.00116,   MAE: 0.00104,  MAPE: 0.50%\n",
      "[500 Epochs]    RMSE:0.00183,   MAE: 0.00165,  MAPE: 0.81%\n",
      "[600 Epochs]    RMSE:0.00534,   MAE: 0.00531,  MAPE: 2.53%\n",
      "[700 Epochs]    RMSE:0.00108,   MAE: 0.00102,  MAPE: 0.49%\n",
      "[800 Epochs]    RMSE:0.00148,   MAE: 0.00137,  MAPE: 0.64%\n",
      "[900 Epochs]    RMSE:0.00193,   MAE: 0.00187,  MAPE: 0.90%\n",
      "[1000 Epochs]    RMSE:0.00318,   MAE: 0.00304,  MAPE: 1.48%\n",
      "[1100 Epochs]    RMSE:0.00183,   MAE: 0.00180,  MAPE: 0.86%\n",
      "[1200 Epochs]    RMSE:0.00253,   MAE: 0.00245,  MAPE: 1.16%\n",
      "[1300 Epochs]    RMSE:0.00046,   MAE: 0.00039,  MAPE: 0.18%\n",
      "[1400 Epochs]    RMSE:0.00108,   MAE: 0.00082,  MAPE: 0.38%\n",
      "[1500 Epochs]    RMSE:0.00363,   MAE: 0.00358,  MAPE: 1.73%\n",
      "[1600 Epochs]    RMSE:0.00130,   MAE: 0.00121,  MAPE: 0.57%\n",
      "[1700 Epochs]    RMSE:0.00393,   MAE: 0.00390,  MAPE: 1.86%\n",
      "[1800 Epochs]    RMSE:0.00095,   MAE: 0.00081,  MAPE: 0.40%\n",
      "[1900 Epochs]    RMSE:0.00384,   MAE: 0.00362,  MAPE: 1.70%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00029,   MAE: 0.00023,  MAPE: 0.11%\n",
      "\n",
      "\n",
      "Trial No.140\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 90\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.09312,   MAE: 0.07958,  MAPE: 38.88%\n",
      "[100 Epochs]    RMSE:0.00606,   MAE: 0.00583,  MAPE: 2.76%\n",
      "[200 Epochs]    RMSE:0.00724,   MAE: 0.00694,  MAPE: 3.27%\n",
      "[300 Epochs]    RMSE:0.00398,   MAE: 0.00362,  MAPE: 1.69%\n",
      "[400 Epochs]    RMSE:0.00151,   MAE: 0.00125,  MAPE: 0.61%\n",
      "[500 Epochs]    RMSE:0.00333,   MAE: 0.00304,  MAPE: 1.42%\n",
      "[600 Epochs]    RMSE:0.00070,   MAE: 0.00060,  MAPE: 0.29%\n",
      "[700 Epochs]    RMSE:0.00249,   MAE: 0.00224,  MAPE: 1.05%\n",
      "[800 Epochs]    RMSE:0.00195,   MAE: 0.00190,  MAPE: 0.90%\n",
      "[900 Epochs]    RMSE:0.00325,   MAE: 0.00280,  MAPE: 1.29%\n",
      "[1000 Epochs]    RMSE:0.00158,   MAE: 0.00154,  MAPE: 0.73%\n",
      "[1100 Epochs]    RMSE:0.00273,   MAE: 0.00248,  MAPE: 1.16%\n",
      "[1200 Epochs]    RMSE:0.00323,   MAE: 0.00321,  MAPE: 1.53%\n",
      "[1300 Epochs]    RMSE:0.00116,   MAE: 0.00109,  MAPE: 0.52%\n",
      "[1400 Epochs]    RMSE:0.00064,   MAE: 0.00058,  MAPE: 0.28%\n",
      "[1500 Epochs]    RMSE:0.00284,   MAE: 0.00265,  MAPE: 1.24%\n",
      "[1600 Epochs]    RMSE:0.00185,   MAE: 0.00158,  MAPE: 0.77%\n",
      "[1700 Epochs]    RMSE:0.00263,   MAE: 0.00247,  MAPE: 1.16%\n",
      "[1800 Epochs]    RMSE:0.00049,   MAE: 0.00041,  MAPE: 0.20%\n",
      "[1900 Epochs]    RMSE:0.00257,   MAE: 0.00253,  MAPE: 1.21%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00191,   MAE: 0.00187,  MAPE: 0.90%\n",
      "\n",
      "\n",
      "Trial No.141\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.14799,   MAE: 0.14038,  MAPE: 66.51%\n",
      "[100 Epochs]    RMSE:0.00474,   MAE: 0.00445,  MAPE: 2.11%\n",
      "[200 Epochs]    RMSE:0.00416,   MAE: 0.00409,  MAPE: 1.95%\n",
      "[300 Epochs]    RMSE:0.00356,   MAE: 0.00350,  MAPE: 1.67%\n",
      "[400 Epochs]    RMSE:0.00465,   MAE: 0.00448,  MAPE: 2.12%\n",
      "[500 Epochs]    RMSE:0.00232,   MAE: 0.00216,  MAPE: 1.04%\n",
      "[600 Epochs]    RMSE:0.00220,   MAE: 0.00203,  MAPE: 0.98%\n",
      "[700 Epochs]    RMSE:0.00053,   MAE: 0.00043,  MAPE: 0.20%\n",
      "[800 Epochs]    RMSE:0.00141,   MAE: 0.00132,  MAPE: 0.62%\n",
      "[900 Epochs]    RMSE:0.00291,   MAE: 0.00290,  MAPE: 1.39%\n",
      "[1000 Epochs]    RMSE:0.00316,   MAE: 0.00311,  MAPE: 1.47%\n",
      "[1100 Epochs]    RMSE:0.00126,   MAE: 0.00096,  MAPE: 0.44%\n",
      "[1200 Epochs]    RMSE:0.00149,   MAE: 0.00145,  MAPE: 0.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300 Epochs]    RMSE:0.00126,   MAE: 0.00110,  MAPE: 0.52%\n",
      "[1400 Epochs]    RMSE:0.00312,   MAE: 0.00298,  MAPE: 1.41%\n",
      "[1500 Epochs]    RMSE:0.00071,   MAE: 0.00047,  MAPE: 0.24%\n",
      "[1600 Epochs]    RMSE:0.00046,   MAE: 0.00039,  MAPE: 0.18%\n",
      "[1700 Epochs]    RMSE:0.00148,   MAE: 0.00135,  MAPE: 0.63%\n",
      "[1800 Epochs]    RMSE:0.00156,   MAE: 0.00153,  MAPE: 0.74%\n",
      "[1900 Epochs]    RMSE:0.00368,   MAE: 0.00366,  MAPE: 1.74%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00188,   MAE: 0.00175,  MAPE: 0.82%\n",
      "\n",
      "\n",
      "Trial No.142\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.16827,   MAE: 0.16159,  MAPE: 76.42%\n",
      "[100 Epochs]    RMSE:0.00163,   MAE: 0.00138,  MAPE: 0.65%\n",
      "[200 Epochs]    RMSE:0.00617,   MAE: 0.00607,  MAPE: 2.93%\n",
      "[300 Epochs]    RMSE:0.00453,   MAE: 0.00441,  MAPE: 2.09%\n",
      "[400 Epochs]    RMSE:0.00834,   MAE: 0.00821,  MAPE: 3.89%\n",
      "[500 Epochs]    RMSE:0.00310,   MAE: 0.00306,  MAPE: 1.47%\n",
      "[600 Epochs]    RMSE:0.00052,   MAE: 0.00044,  MAPE: 0.21%\n",
      "[700 Epochs]    RMSE:0.00082,   MAE: 0.00066,  MAPE: 0.32%\n",
      "[800 Epochs]    RMSE:0.00055,   MAE: 0.00046,  MAPE: 0.22%\n",
      "[900 Epochs]    RMSE:0.00254,   MAE: 0.00233,  MAPE: 1.08%\n",
      "[1000 Epochs]    RMSE:0.00517,   MAE: 0.00503,  MAPE: 2.38%\n",
      "[1100 Epochs]    RMSE:0.00136,   MAE: 0.00123,  MAPE: 0.57%\n",
      "[1200 Epochs]    RMSE:0.00235,   MAE: 0.00225,  MAPE: 1.06%\n",
      "[1300 Epochs]    RMSE:0.00407,   MAE: 0.00401,  MAPE: 1.91%\n",
      "[1400 Epochs]    RMSE:0.00267,   MAE: 0.00260,  MAPE: 1.23%\n",
      "[1500 Epochs]    RMSE:0.00219,   MAE: 0.00208,  MAPE: 0.98%\n",
      "[1600 Epochs]    RMSE:0.00166,   MAE: 0.00153,  MAPE: 0.72%\n",
      "[1700 Epochs]    RMSE:0.00081,   MAE: 0.00075,  MAPE: 0.35%\n",
      "[1800 Epochs]    RMSE:0.00212,   MAE: 0.00185,  MAPE: 0.86%\n",
      "[1900 Epochs]    RMSE:0.00091,   MAE: 0.00086,  MAPE: 0.41%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00068,   MAE: 0.00058,  MAPE: 0.27%\n",
      "\n",
      "\n",
      "Trial No.143\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.26800,   MAE: 0.26492,  MAPE: 125.86%\n",
      "[100 Epochs]    RMSE:0.00426,   MAE: 0.00405,  MAPE: 1.91%\n",
      "[200 Epochs]    RMSE:0.00328,   MAE: 0.00310,  MAPE: 1.49%\n",
      "[300 Epochs]    RMSE:0.00210,   MAE: 0.00199,  MAPE: 0.96%\n",
      "[400 Epochs]    RMSE:0.00576,   MAE: 0.00566,  MAPE: 2.69%\n",
      "[500 Epochs]    RMSE:0.00265,   MAE: 0.00245,  MAPE: 1.15%\n",
      "[600 Epochs]    RMSE:0.00099,   MAE: 0.00080,  MAPE: 0.38%\n",
      "[700 Epochs]    RMSE:0.00265,   MAE: 0.00257,  MAPE: 1.22%\n",
      "[800 Epochs]    RMSE:0.00092,   MAE: 0.00076,  MAPE: 0.35%\n",
      "[900 Epochs]    RMSE:0.00204,   MAE: 0.00168,  MAPE: 0.77%\n",
      "[1000 Epochs]    RMSE:0.00281,   MAE: 0.00270,  MAPE: 1.28%\n",
      "[1100 Epochs]    RMSE:0.00075,   MAE: 0.00064,  MAPE: 0.30%\n",
      "[1200 Epochs]    RMSE:0.00166,   MAE: 0.00163,  MAPE: 0.78%\n",
      "[1300 Epochs]    RMSE:0.00176,   MAE: 0.00164,  MAPE: 0.76%\n",
      "[1400 Epochs]    RMSE:0.00184,   MAE: 0.00182,  MAPE: 0.87%\n",
      "[1500 Epochs]    RMSE:0.00412,   MAE: 0.00409,  MAPE: 1.95%\n",
      "[1600 Epochs]    RMSE:0.00108,   MAE: 0.00099,  MAPE: 0.46%\n",
      "[1700 Epochs]    RMSE:0.00183,   MAE: 0.00178,  MAPE: 0.84%\n",
      "[1800 Epochs]    RMSE:0.00043,   MAE: 0.00038,  MAPE: 0.18%\n",
      "[1900 Epochs]    RMSE:0.00092,   MAE: 0.00075,  MAPE: 0.37%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00123,   MAE: 0.00117,  MAPE: 0.56%\n",
      "\n",
      "\n",
      "Trial No.144\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.16889,   MAE: 0.16719,  MAPE: 80.66%\n",
      "[100 Epochs]    RMSE:0.00108,   MAE: 0.00081,  MAPE: 0.39%\n",
      "[200 Epochs]    RMSE:0.00386,   MAE: 0.00366,  MAPE: 1.74%\n",
      "[300 Epochs]    RMSE:0.00711,   MAE: 0.00688,  MAPE: 3.35%\n",
      "[400 Epochs]    RMSE:0.00072,   MAE: 0.00055,  MAPE: 0.26%\n",
      "[500 Epochs]    RMSE:0.00241,   MAE: 0.00237,  MAPE: 1.14%\n",
      "[600 Epochs]    RMSE:0.00196,   MAE: 0.00187,  MAPE: 0.90%\n",
      "[700 Epochs]    RMSE:0.00762,   MAE: 0.00754,  MAPE: 3.58%\n",
      "[800 Epochs]    RMSE:0.00121,   MAE: 0.00102,  MAPE: 0.49%\n",
      "[900 Epochs]    RMSE:0.00186,   MAE: 0.00164,  MAPE: 0.76%\n",
      "[1000 Epochs]    RMSE:0.00456,   MAE: 0.00448,  MAPE: 2.14%\n",
      "[1100 Epochs]    RMSE:0.00101,   MAE: 0.00087,  MAPE: 0.41%\n",
      "[1200 Epochs]    RMSE:0.00715,   MAE: 0.00713,  MAPE: 3.40%\n",
      "[1300 Epochs]    RMSE:0.00094,   MAE: 0.00090,  MAPE: 0.43%\n",
      "[1400 Epochs]    RMSE:0.00506,   MAE: 0.00502,  MAPE: 2.40%\n",
      "[1500 Epochs]    RMSE:0.00203,   MAE: 0.00185,  MAPE: 0.91%\n",
      "[1600 Epochs]    RMSE:0.00518,   MAE: 0.00498,  MAPE: 2.34%\n",
      "[1700 Epochs]    RMSE:0.00215,   MAE: 0.00212,  MAPE: 1.01%\n",
      "[1800 Epochs]    RMSE:0.00107,   MAE: 0.00078,  MAPE: 0.39%\n",
      "[1900 Epochs]    RMSE:0.00123,   MAE: 0.00112,  MAPE: 0.53%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00279,   MAE: 0.00275,  MAPE: 1.31%\n",
      "\n",
      "\n",
      "Trial No.145\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.29737,   MAE: 0.29273,  MAPE: 138.90%\n",
      "[100 Epochs]    RMSE:0.00256,   MAE: 0.00232,  MAPE: 1.11%\n",
      "[200 Epochs]    RMSE:0.00637,   MAE: 0.00622,  MAPE: 2.94%\n",
      "[300 Epochs]    RMSE:0.00409,   MAE: 0.00387,  MAPE: 1.83%\n",
      "[400 Epochs]    RMSE:0.00285,   MAE: 0.00259,  MAPE: 1.22%\n",
      "[500 Epochs]    RMSE:0.00360,   MAE: 0.00354,  MAPE: 1.70%\n",
      "[600 Epochs]    RMSE:0.00100,   MAE: 0.00070,  MAPE: 0.32%\n",
      "[700 Epochs]    RMSE:0.00192,   MAE: 0.00184,  MAPE: 0.87%\n",
      "[800 Epochs]    RMSE:0.00358,   MAE: 0.00349,  MAPE: 1.66%\n",
      "[900 Epochs]    RMSE:0.00431,   MAE: 0.00385,  MAPE: 1.79%\n",
      "[1000 Epochs]    RMSE:0.00081,   MAE: 0.00067,  MAPE: 0.32%\n",
      "[1100 Epochs]    RMSE:0.00265,   MAE: 0.00221,  MAPE: 1.02%\n",
      "[1200 Epochs]    RMSE:0.00321,   MAE: 0.00312,  MAPE: 1.48%\n",
      "[1300 Epochs]    RMSE:0.00508,   MAE: 0.00496,  MAPE: 2.35%\n",
      "[1400 Epochs]    RMSE:0.00109,   MAE: 0.00097,  MAPE: 0.45%\n",
      "[1500 Epochs]    RMSE:0.00605,   MAE: 0.00601,  MAPE: 2.86%\n",
      "[1600 Epochs]    RMSE:0.00259,   MAE: 0.00238,  MAPE: 1.11%\n",
      "[1700 Epochs]    RMSE:0.00296,   MAE: 0.00290,  MAPE: 1.38%\n",
      "[1800 Epochs]    RMSE:0.00142,   MAE: 0.00137,  MAPE: 0.66%\n",
      "[1900 Epochs]    RMSE:0.00176,   MAE: 0.00171,  MAPE: 0.81%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00218,   MAE: 0.00212,  MAPE: 1.02%\n",
      "\n",
      "\n",
      "Trial No.146\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.21501,   MAE: 0.21465,  MAPE: 102.71%\n",
      "[100 Epochs]    RMSE:0.01032,   MAE: 0.00996,  MAPE: 4.70%\n",
      "[200 Epochs]    RMSE:0.00369,   MAE: 0.00356,  MAPE: 1.68%\n",
      "[300 Epochs]    RMSE:0.00299,   MAE: 0.00286,  MAPE: 1.35%\n",
      "[400 Epochs]    RMSE:0.00948,   MAE: 0.00942,  MAPE: 4.48%\n",
      "[500 Epochs]    RMSE:0.00278,   MAE: 0.00262,  MAPE: 1.23%\n",
      "[600 Epochs]    RMSE:0.00107,   MAE: 0.00097,  MAPE: 0.46%\n",
      "[700 Epochs]    RMSE:0.00158,   MAE: 0.00143,  MAPE: 0.67%\n",
      "[800 Epochs]    RMSE:0.00543,   MAE: 0.00536,  MAPE: 2.55%\n",
      "[900 Epochs]    RMSE:0.00225,   MAE: 0.00218,  MAPE: 1.03%\n",
      "[1000 Epochs]    RMSE:0.00215,   MAE: 0.00206,  MAPE: 1.00%\n",
      "[1100 Epochs]    RMSE:0.00139,   MAE: 0.00121,  MAPE: 0.60%\n",
      "[1200 Epochs]    RMSE:0.00364,   MAE: 0.00361,  MAPE: 1.72%\n",
      "[1300 Epochs]    RMSE:0.00055,   MAE: 0.00042,  MAPE: 0.20%\n",
      "[1400 Epochs]    RMSE:0.00128,   MAE: 0.00125,  MAPE: 0.60%\n",
      "[1500 Epochs]    RMSE:0.00129,   MAE: 0.00119,  MAPE: 0.56%\n",
      "[1600 Epochs]    RMSE:0.00090,   MAE: 0.00075,  MAPE: 0.35%\n",
      "[1700 Epochs]    RMSE:0.00142,   MAE: 0.00135,  MAPE: 0.65%\n",
      "[1800 Epochs]    RMSE:0.00389,   MAE: 0.00388,  MAPE: 1.86%\n",
      "[1900 Epochs]    RMSE:0.00147,   MAE: 0.00142,  MAPE: 0.68%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00217,   MAE: 0.00197,  MAPE: 0.92%\n",
      "\n",
      "\n",
      "Trial No.147\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 100\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.20418,   MAE: 0.19730,  MAPE: 96.04%\n",
      "[100 Epochs]    RMSE:0.00624,   MAE: 0.00610,  MAPE: 2.91%\n",
      "[200 Epochs]    RMSE:0.00749,   MAE: 0.00742,  MAPE: 3.53%\n",
      "[300 Epochs]    RMSE:0.00389,   MAE: 0.00385,  MAPE: 1.84%\n",
      "[400 Epochs]    RMSE:0.00298,   MAE: 0.00235,  MAPE: 1.17%\n",
      "[500 Epochs]    RMSE:0.00124,   MAE: 0.00111,  MAPE: 0.52%\n",
      "[600 Epochs]    RMSE:0.00366,   MAE: 0.00353,  MAPE: 1.66%\n",
      "[700 Epochs]    RMSE:0.00388,   MAE: 0.00364,  MAPE: 1.70%\n",
      "[800 Epochs]    RMSE:0.00377,   MAE: 0.00372,  MAPE: 1.78%\n",
      "[900 Epochs]    RMSE:0.00281,   MAE: 0.00279,  MAPE: 1.33%\n",
      "[1000 Epochs]    RMSE:0.00109,   MAE: 0.00101,  MAPE: 0.49%\n",
      "[1100 Epochs]    RMSE:0.00242,   MAE: 0.00240,  MAPE: 1.15%\n",
      "[1200 Epochs]    RMSE:0.00291,   MAE: 0.00288,  MAPE: 1.37%\n",
      "[1300 Epochs]    RMSE:0.00135,   MAE: 0.00127,  MAPE: 0.62%\n",
      "[1400 Epochs]    RMSE:0.00240,   MAE: 0.00231,  MAPE: 1.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500 Epochs]    RMSE:0.00164,   MAE: 0.00161,  MAPE: 0.77%\n",
      "[1600 Epochs]    RMSE:0.00089,   MAE: 0.00077,  MAPE: 0.37%\n",
      "[1700 Epochs]    RMSE:0.00209,   MAE: 0.00186,  MAPE: 0.87%\n",
      "[1800 Epochs]    RMSE:0.00124,   MAE: 0.00122,  MAPE: 0.58%\n",
      "[1900 Epochs]    RMSE:0.00041,   MAE: 0.00033,  MAPE: 0.16%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00048,   MAE: 0.00040,  MAPE: 0.20%\n",
      "\n",
      "\n",
      "Trial No.148\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.18137,   MAE: 0.17120,  MAPE: 82.01%\n",
      "[100 Epochs]    RMSE:0.00442,   MAE: 0.00426,  MAPE: 2.02%\n",
      "[200 Epochs]    RMSE:0.00556,   MAE: 0.00545,  MAPE: 2.59%\n",
      "[300 Epochs]    RMSE:0.00559,   MAE: 0.00535,  MAPE: 2.52%\n",
      "[400 Epochs]    RMSE:0.00231,   MAE: 0.00209,  MAPE: 0.98%\n",
      "[500 Epochs]    RMSE:0.00118,   MAE: 0.00106,  MAPE: 0.50%\n",
      "[600 Epochs]    RMSE:0.00328,   MAE: 0.00321,  MAPE: 1.55%\n",
      "[700 Epochs]    RMSE:0.00346,   MAE: 0.00323,  MAPE: 1.52%\n",
      "[800 Epochs]    RMSE:0.00267,   MAE: 0.00241,  MAPE: 1.12%\n",
      "[900 Epochs]    RMSE:0.00209,   MAE: 0.00206,  MAPE: 0.98%\n",
      "[1000 Epochs]    RMSE:0.00167,   MAE: 0.00148,  MAPE: 0.69%\n",
      "[1100 Epochs]    RMSE:0.00492,   MAE: 0.00490,  MAPE: 2.34%\n",
      "[1200 Epochs]    RMSE:0.00276,   MAE: 0.00251,  MAPE: 1.17%\n",
      "[1300 Epochs]    RMSE:0.00664,   MAE: 0.00655,  MAPE: 3.11%\n",
      "[1400 Epochs]    RMSE:0.00092,   MAE: 0.00083,  MAPE: 0.39%\n",
      "[1500 Epochs]    RMSE:0.00075,   MAE: 0.00064,  MAPE: 0.30%\n",
      "[1600 Epochs]    RMSE:0.00055,   MAE: 0.00051,  MAPE: 0.24%\n",
      "[1700 Epochs]    RMSE:0.00107,   MAE: 0.00105,  MAPE: 0.50%\n",
      "[1800 Epochs]    RMSE:0.00090,   MAE: 0.00078,  MAPE: 0.36%\n",
      "[1900 Epochs]    RMSE:0.00034,   MAE: 0.00029,  MAPE: 0.14%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00120,   MAE: 0.00112,  MAPE: 0.54%\n",
      "\n",
      "\n",
      "Trial No.149\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.20473,   MAE: 0.20272,  MAPE: 97.08%\n",
      "[100 Epochs]    RMSE:0.00456,   MAE: 0.00434,  MAPE: 2.11%\n",
      "[200 Epochs]    RMSE:0.00188,   MAE: 0.00165,  MAPE: 0.79%\n",
      "[300 Epochs]    RMSE:0.00526,   MAE: 0.00495,  MAPE: 2.32%\n",
      "[400 Epochs]    RMSE:0.00677,   MAE: 0.00653,  MAPE: 3.08%\n",
      "[500 Epochs]    RMSE:0.00084,   MAE: 0.00074,  MAPE: 0.36%\n",
      "[600 Epochs]    RMSE:0.00644,   MAE: 0.00641,  MAPE: 3.06%\n",
      "[700 Epochs]    RMSE:0.00109,   MAE: 0.00089,  MAPE: 0.44%\n",
      "[800 Epochs]    RMSE:0.00052,   MAE: 0.00044,  MAPE: 0.21%\n",
      "[900 Epochs]    RMSE:0.00139,   MAE: 0.00121,  MAPE: 0.60%\n",
      "[1000 Epochs]    RMSE:0.00267,   MAE: 0.00253,  MAPE: 1.19%\n",
      "[1100 Epochs]    RMSE:0.00363,   MAE: 0.00351,  MAPE: 1.65%\n",
      "[1200 Epochs]    RMSE:0.00199,   MAE: 0.00190,  MAPE: 0.93%\n",
      "[1300 Epochs]    RMSE:0.00355,   MAE: 0.00342,  MAPE: 1.61%\n",
      "[1400 Epochs]    RMSE:0.00131,   MAE: 0.00114,  MAPE: 0.56%\n",
      "[1500 Epochs]    RMSE:0.00198,   MAE: 0.00191,  MAPE: 0.91%\n",
      "[1600 Epochs]    RMSE:0.00247,   MAE: 0.00231,  MAPE: 1.09%\n",
      "[1700 Epochs]    RMSE:0.00195,   MAE: 0.00190,  MAPE: 0.90%\n",
      "[1800 Epochs]    RMSE:0.00160,   MAE: 0.00155,  MAPE: 0.74%\n",
      "[1900 Epochs]    RMSE:0.00171,   MAE: 0.00167,  MAPE: 0.80%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00362,   MAE: 0.00357,  MAPE: 1.72%\n",
      "\n",
      "\n",
      "Trial No.150\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.11185,   MAE: 0.09946,  MAPE: 47.57%\n",
      "[100 Epochs]    RMSE:0.00909,   MAE: 0.00888,  MAPE: 4.27%\n",
      "[200 Epochs]    RMSE:0.00242,   MAE: 0.00233,  MAPE: 1.12%\n",
      "[300 Epochs]    RMSE:0.00380,   MAE: 0.00378,  MAPE: 1.82%\n",
      "[400 Epochs]    RMSE:0.00135,   MAE: 0.00095,  MAPE: 0.48%\n",
      "[500 Epochs]    RMSE:0.00160,   MAE: 0.00153,  MAPE: 0.73%\n",
      "[600 Epochs]    RMSE:0.00160,   MAE: 0.00152,  MAPE: 0.72%\n",
      "[700 Epochs]    RMSE:0.00122,   MAE: 0.00112,  MAPE: 0.53%\n",
      "[800 Epochs]    RMSE:0.00137,   MAE: 0.00130,  MAPE: 0.62%\n",
      "[900 Epochs]    RMSE:0.00436,   MAE: 0.00432,  MAPE: 2.07%\n",
      "[1000 Epochs]    RMSE:0.00498,   MAE: 0.00481,  MAPE: 2.27%\n",
      "[1100 Epochs]    RMSE:0.00512,   MAE: 0.00501,  MAPE: 2.37%\n",
      "[1200 Epochs]    RMSE:0.00529,   MAE: 0.00526,  MAPE: 2.51%\n",
      "[1300 Epochs]    RMSE:0.00413,   MAE: 0.00411,  MAPE: 1.97%\n",
      "[1400 Epochs]    RMSE:0.00233,   MAE: 0.00231,  MAPE: 1.10%\n",
      "[1500 Epochs]    RMSE:0.00103,   MAE: 0.00082,  MAPE: 0.40%\n",
      "[1600 Epochs]    RMSE:0.00225,   MAE: 0.00220,  MAPE: 1.04%\n",
      "[1700 Epochs]    RMSE:0.00049,   MAE: 0.00040,  MAPE: 0.19%\n",
      "[1800 Epochs]    RMSE:0.00380,   MAE: 0.00377,  MAPE: 1.80%\n",
      "[1900 Epochs]    RMSE:0.00081,   MAE: 0.00057,  MAPE: 0.29%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00220,   MAE: 0.00216,  MAPE: 1.04%\n",
      "\n",
      "\n",
      "Trial No.151\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.25864,   MAE: 0.25740,  MAPE: 122.84%\n",
      "[100 Epochs]    RMSE:0.00328,   MAE: 0.00293,  MAPE: 1.38%\n",
      "[200 Epochs]    RMSE:0.00680,   MAE: 0.00652,  MAPE: 3.07%\n",
      "[300 Epochs]    RMSE:0.00201,   MAE: 0.00181,  MAPE: 0.85%\n",
      "[400 Epochs]    RMSE:0.00374,   MAE: 0.00364,  MAPE: 1.76%\n",
      "[500 Epochs]    RMSE:0.00358,   MAE: 0.00355,  MAPE: 1.70%\n",
      "[600 Epochs]    RMSE:0.00538,   MAE: 0.00535,  MAPE: 2.56%\n",
      "[700 Epochs]    RMSE:0.00051,   MAE: 0.00038,  MAPE: 0.19%\n",
      "[800 Epochs]    RMSE:0.00087,   MAE: 0.00073,  MAPE: 0.34%\n",
      "[900 Epochs]    RMSE:0.00220,   MAE: 0.00216,  MAPE: 1.04%\n",
      "[1000 Epochs]    RMSE:0.00042,   MAE: 0.00033,  MAPE: 0.16%\n",
      "[1100 Epochs]    RMSE:0.00169,   MAE: 0.00163,  MAPE: 0.78%\n",
      "[1200 Epochs]    RMSE:0.00130,   MAE: 0.00119,  MAPE: 0.58%\n",
      "[1300 Epochs]    RMSE:0.00133,   MAE: 0.00128,  MAPE: 0.61%\n",
      "[1400 Epochs]    RMSE:0.00144,   MAE: 0.00136,  MAPE: 0.64%\n",
      "[1500 Epochs]    RMSE:0.00370,   MAE: 0.00360,  MAPE: 1.70%\n",
      "[1600 Epochs]    RMSE:0.00141,   MAE: 0.00138,  MAPE: 0.65%\n",
      "[1700 Epochs]    RMSE:0.00027,   MAE: 0.00021,  MAPE: 0.10%\n",
      "[1800 Epochs]    RMSE:0.00173,   MAE: 0.00167,  MAPE: 0.79%\n",
      "[1900 Epochs]    RMSE:0.00273,   MAE: 0.00268,  MAPE: 1.29%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00099,   MAE: 0.00097,  MAPE: 0.46%\n",
      "\n",
      "\n",
      "Trial No.152\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.11529,   MAE: 0.10896,  MAPE: 52.68%\n",
      "[100 Epochs]    RMSE:0.01071,   MAE: 0.01049,  MAPE: 5.02%\n",
      "[200 Epochs]    RMSE:0.00401,   MAE: 0.00391,  MAPE: 1.86%\n",
      "[300 Epochs]    RMSE:0.00202,   MAE: 0.00179,  MAPE: 0.84%\n",
      "[400 Epochs]    RMSE:0.00033,   MAE: 0.00028,  MAPE: 0.13%\n",
      "[500 Epochs]    RMSE:0.00055,   MAE: 0.00043,  MAPE: 0.20%\n",
      "[600 Epochs]    RMSE:0.00519,   MAE: 0.00512,  MAPE: 2.43%\n",
      "[700 Epochs]    RMSE:0.00568,   MAE: 0.00536,  MAPE: 2.51%\n",
      "[800 Epochs]    RMSE:0.00069,   MAE: 0.00059,  MAPE: 0.29%\n",
      "[900 Epochs]    RMSE:0.00054,   MAE: 0.00047,  MAPE: 0.23%\n",
      "[1000 Epochs]    RMSE:0.00149,   MAE: 0.00145,  MAPE: 0.70%\n",
      "[1100 Epochs]    RMSE:0.00249,   MAE: 0.00240,  MAPE: 1.16%\n",
      "[1200 Epochs]    RMSE:0.00317,   MAE: 0.00308,  MAPE: 1.47%\n",
      "[1300 Epochs]    RMSE:0.00148,   MAE: 0.00135,  MAPE: 0.63%\n",
      "[1400 Epochs]    RMSE:0.00187,   MAE: 0.00183,  MAPE: 0.88%\n",
      "[1500 Epochs]    RMSE:0.00302,   MAE: 0.00299,  MAPE: 1.43%\n",
      "[1600 Epochs]    RMSE:0.00267,   MAE: 0.00249,  MAPE: 1.16%\n",
      "[1700 Epochs]    RMSE:0.00166,   MAE: 0.00150,  MAPE: 0.73%\n",
      "[1800 Epochs]    RMSE:0.00117,   MAE: 0.00105,  MAPE: 0.50%\n",
      "[1900 Epochs]    RMSE:0.00038,   MAE: 0.00032,  MAPE: 0.16%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00233,   MAE: 0.00231,  MAPE: 1.11%\n",
      "\n",
      "\n",
      "Trial No.153\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.33657,   MAE: 0.32659,  MAPE: 154.66%\n",
      "[100 Epochs]    RMSE:0.00389,   MAE: 0.00362,  MAPE: 1.72%\n",
      "[200 Epochs]    RMSE:0.00435,   MAE: 0.00416,  MAPE: 2.03%\n",
      "[300 Epochs]    RMSE:0.00272,   MAE: 0.00251,  MAPE: 1.18%\n",
      "[400 Epochs]    RMSE:0.00127,   MAE: 0.00101,  MAPE: 0.47%\n",
      "[500 Epochs]    RMSE:0.00496,   MAE: 0.00490,  MAPE: 2.33%\n",
      "[600 Epochs]    RMSE:0.00092,   MAE: 0.00081,  MAPE: 0.39%\n",
      "[700 Epochs]    RMSE:0.00072,   MAE: 0.00062,  MAPE: 0.30%\n",
      "[800 Epochs]    RMSE:0.00105,   MAE: 0.00098,  MAPE: 0.47%\n",
      "[900 Epochs]    RMSE:0.00083,   MAE: 0.00064,  MAPE: 0.32%\n",
      "[1000 Epochs]    RMSE:0.00516,   MAE: 0.00509,  MAPE: 2.42%\n",
      "[1100 Epochs]    RMSE:0.00318,   MAE: 0.00312,  MAPE: 1.48%\n",
      "[1200 Epochs]    RMSE:0.00092,   MAE: 0.00072,  MAPE: 0.34%\n",
      "[1300 Epochs]    RMSE:0.00185,   MAE: 0.00177,  MAPE: 0.83%\n",
      "[1400 Epochs]    RMSE:0.00327,   MAE: 0.00325,  MAPE: 1.55%\n",
      "[1500 Epochs]    RMSE:0.00121,   MAE: 0.00111,  MAPE: 0.52%\n",
      "[1600 Epochs]    RMSE:0.00127,   MAE: 0.00119,  MAPE: 0.56%\n",
      "[1700 Epochs]    RMSE:0.00184,   MAE: 0.00169,  MAPE: 0.83%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1800 Epochs]    RMSE:0.00350,   MAE: 0.00335,  MAPE: 1.58%\n",
      "[1900 Epochs]    RMSE:0.00061,   MAE: 0.00049,  MAPE: 0.24%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00079,   MAE: 0.00063,  MAPE: 0.31%\n",
      "\n",
      "\n",
      "Trial No.154\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 110\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.25172,   MAE: 0.24895,  MAPE: 119.92%\n",
      "[100 Epochs]    RMSE:0.00454,   MAE: 0.00415,  MAPE: 2.03%\n",
      "[200 Epochs]    RMSE:0.00451,   MAE: 0.00441,  MAPE: 2.12%\n",
      "[300 Epochs]    RMSE:0.00371,   MAE: 0.00368,  MAPE: 1.77%\n",
      "[400 Epochs]    RMSE:0.00710,   MAE: 0.00700,  MAPE: 3.32%\n",
      "[500 Epochs]    RMSE:0.00345,   MAE: 0.00342,  MAPE: 1.63%\n",
      "[600 Epochs]    RMSE:0.00388,   MAE: 0.00383,  MAPE: 1.83%\n",
      "[700 Epochs]    RMSE:0.00160,   MAE: 0.00145,  MAPE: 0.68%\n",
      "[800 Epochs]    RMSE:0.00272,   MAE: 0.00260,  MAPE: 1.23%\n",
      "[900 Epochs]    RMSE:0.00238,   MAE: 0.00214,  MAPE: 0.99%\n",
      "[1000 Epochs]    RMSE:0.00246,   MAE: 0.00211,  MAPE: 0.99%\n",
      "[1100 Epochs]    RMSE:0.00326,   MAE: 0.00291,  MAPE: 1.42%\n",
      "[1200 Epochs]    RMSE:0.00165,   MAE: 0.00159,  MAPE: 0.76%\n",
      "[1300 Epochs]    RMSE:0.00163,   MAE: 0.00136,  MAPE: 0.63%\n",
      "[1400 Epochs]    RMSE:0.00083,   MAE: 0.00077,  MAPE: 0.37%\n",
      "[1500 Epochs]    RMSE:0.00297,   MAE: 0.00261,  MAPE: 1.21%\n",
      "[1600 Epochs]    RMSE:0.00140,   MAE: 0.00122,  MAPE: 0.56%\n",
      "[1700 Epochs]    RMSE:0.00170,   MAE: 0.00158,  MAPE: 0.75%\n",
      "[1800 Epochs]    RMSE:0.00173,   MAE: 0.00171,  MAPE: 0.82%\n",
      "[1900 Epochs]    RMSE:0.00157,   MAE: 0.00151,  MAPE: 0.73%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00110,   MAE: 0.00090,  MAPE: 0.41%\n",
      "\n",
      "\n",
      "Trial No.155\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.21104,   MAE: 0.20749,  MAPE: 98.78%\n",
      "[100 Epochs]    RMSE:0.00420,   MAE: 0.00385,  MAPE: 1.85%\n",
      "[200 Epochs]    RMSE:0.00570,   MAE: 0.00557,  MAPE: 2.69%\n",
      "[300 Epochs]    RMSE:0.00182,   MAE: 0.00172,  MAPE: 0.83%\n",
      "[400 Epochs]    RMSE:0.00117,   MAE: 0.00099,  MAPE: 0.47%\n",
      "[500 Epochs]    RMSE:0.00520,   MAE: 0.00510,  MAPE: 2.42%\n",
      "[600 Epochs]    RMSE:0.00141,   MAE: 0.00117,  MAPE: 0.54%\n",
      "[700 Epochs]    RMSE:0.00078,   MAE: 0.00060,  MAPE: 0.28%\n",
      "[800 Epochs]    RMSE:0.00342,   MAE: 0.00336,  MAPE: 1.60%\n",
      "[900 Epochs]    RMSE:0.00182,   MAE: 0.00173,  MAPE: 0.82%\n",
      "[1000 Epochs]    RMSE:0.00125,   MAE: 0.00116,  MAPE: 0.54%\n",
      "[1100 Epochs]    RMSE:0.00145,   MAE: 0.00139,  MAPE: 0.66%\n",
      "[1200 Epochs]    RMSE:0.00303,   MAE: 0.00298,  MAPE: 1.42%\n",
      "[1300 Epochs]    RMSE:0.00233,   MAE: 0.00218,  MAPE: 1.02%\n",
      "[1400 Epochs]    RMSE:0.00372,   MAE: 0.00368,  MAPE: 1.76%\n",
      "[1500 Epochs]    RMSE:0.00417,   MAE: 0.00407,  MAPE: 1.93%\n",
      "[1600 Epochs]    RMSE:0.00181,   MAE: 0.00175,  MAPE: 0.83%\n",
      "[1700 Epochs]    RMSE:0.00323,   MAE: 0.00310,  MAPE: 1.46%\n",
      "[1800 Epochs]    RMSE:0.00208,   MAE: 0.00205,  MAPE: 0.98%\n",
      "[1900 Epochs]    RMSE:0.00506,   MAE: 0.00501,  MAPE: 2.38%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00214,   MAE: 0.00204,  MAPE: 0.96%\n",
      "\n",
      "\n",
      "Trial No.156\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.19928,   MAE: 0.19652,  MAPE: 93.38%\n",
      "[100 Epochs]    RMSE:0.00773,   MAE: 0.00760,  MAPE: 3.63%\n",
      "[200 Epochs]    RMSE:0.00156,   MAE: 0.00126,  MAPE: 0.58%\n",
      "[300 Epochs]    RMSE:0.00205,   MAE: 0.00167,  MAPE: 0.81%\n",
      "[400 Epochs]    RMSE:0.00276,   MAE: 0.00267,  MAPE: 1.27%\n",
      "[500 Epochs]    RMSE:0.00449,   MAE: 0.00445,  MAPE: 2.14%\n",
      "[600 Epochs]    RMSE:0.00193,   MAE: 0.00183,  MAPE: 0.88%\n",
      "[700 Epochs]    RMSE:0.00480,   MAE: 0.00472,  MAPE: 2.25%\n",
      "[800 Epochs]    RMSE:0.00147,   MAE: 0.00139,  MAPE: 0.67%\n",
      "[900 Epochs]    RMSE:0.00144,   MAE: 0.00139,  MAPE: 0.66%\n",
      "[1000 Epochs]    RMSE:0.00461,   MAE: 0.00458,  MAPE: 2.20%\n",
      "[1100 Epochs]    RMSE:0.00290,   MAE: 0.00283,  MAPE: 1.37%\n",
      "[1200 Epochs]    RMSE:0.00208,   MAE: 0.00202,  MAPE: 0.98%\n",
      "[1300 Epochs]    RMSE:0.00110,   MAE: 0.00091,  MAPE: 0.45%\n",
      "[1400 Epochs]    RMSE:0.00151,   MAE: 0.00136,  MAPE: 0.65%\n",
      "[1500 Epochs]    RMSE:0.00074,   MAE: 0.00064,  MAPE: 0.31%\n",
      "[1600 Epochs]    RMSE:0.00190,   MAE: 0.00186,  MAPE: 0.89%\n",
      "[1700 Epochs]    RMSE:0.00185,   MAE: 0.00178,  MAPE: 0.84%\n",
      "[1800 Epochs]    RMSE:0.00099,   MAE: 0.00088,  MAPE: 0.43%\n",
      "[1900 Epochs]    RMSE:0.00131,   MAE: 0.00124,  MAPE: 0.60%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00048,   MAE: 0.00042,  MAPE: 0.20%\n",
      "\n",
      "\n",
      "Trial No.157\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.32677,   MAE: 0.32185,  MAPE: 153.12%\n",
      "[100 Epochs]    RMSE:0.00336,   MAE: 0.00280,  MAPE: 1.32%\n",
      "[200 Epochs]    RMSE:0.00194,   MAE: 0.00188,  MAPE: 0.91%\n",
      "[300 Epochs]    RMSE:0.00309,   MAE: 0.00305,  MAPE: 1.46%\n",
      "[400 Epochs]    RMSE:0.00636,   MAE: 0.00631,  MAPE: 3.01%\n",
      "[500 Epochs]    RMSE:0.00273,   MAE: 0.00265,  MAPE: 1.26%\n",
      "[600 Epochs]    RMSE:0.00263,   MAE: 0.00257,  MAPE: 1.23%\n",
      "[700 Epochs]    RMSE:0.00086,   MAE: 0.00069,  MAPE: 0.32%\n",
      "[800 Epochs]    RMSE:0.00662,   MAE: 0.00660,  MAPE: 3.17%\n",
      "[900 Epochs]    RMSE:0.00636,   MAE: 0.00629,  MAPE: 2.99%\n",
      "[1000 Epochs]    RMSE:0.00186,   MAE: 0.00170,  MAPE: 0.83%\n",
      "[1100 Epochs]    RMSE:0.00150,   MAE: 0.00143,  MAPE: 0.68%\n",
      "[1200 Epochs]    RMSE:0.00143,   MAE: 0.00134,  MAPE: 0.63%\n",
      "[1300 Epochs]    RMSE:0.00116,   MAE: 0.00082,  MAPE: 0.41%\n",
      "[1400 Epochs]    RMSE:0.00223,   MAE: 0.00194,  MAPE: 0.90%\n",
      "[1500 Epochs]    RMSE:0.00146,   MAE: 0.00133,  MAPE: 0.62%\n",
      "[1600 Epochs]    RMSE:0.00203,   MAE: 0.00197,  MAPE: 0.93%\n",
      "[1700 Epochs]    RMSE:0.00127,   MAE: 0.00121,  MAPE: 0.57%\n",
      "[1800 Epochs]    RMSE:0.00151,   MAE: 0.00136,  MAPE: 0.63%\n",
      "[1900 Epochs]    RMSE:0.00157,   MAE: 0.00135,  MAPE: 0.62%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00153,   MAE: 0.00149,  MAPE: 0.71%\n",
      "\n",
      "\n",
      "Trial No.158\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.19386,   MAE: 0.19318,  MAPE: 92.82%\n",
      "[100 Epochs]    RMSE:0.00838,   MAE: 0.00812,  MAPE: 3.85%\n",
      "[200 Epochs]    RMSE:0.00375,   MAE: 0.00358,  MAPE: 1.69%\n",
      "[300 Epochs]    RMSE:0.00321,   MAE: 0.00313,  MAPE: 1.50%\n",
      "[400 Epochs]    RMSE:0.00488,   MAE: 0.00483,  MAPE: 2.30%\n",
      "[500 Epochs]    RMSE:0.00224,   MAE: 0.00197,  MAPE: 0.92%\n",
      "[600 Epochs]    RMSE:0.00823,   MAE: 0.00821,  MAPE: 3.93%\n",
      "[700 Epochs]    RMSE:0.00265,   MAE: 0.00254,  MAPE: 1.20%\n",
      "[800 Epochs]    RMSE:0.00390,   MAE: 0.00386,  MAPE: 1.86%\n",
      "[900 Epochs]    RMSE:0.00341,   MAE: 0.00333,  MAPE: 1.61%\n",
      "[1000 Epochs]    RMSE:0.00307,   MAE: 0.00295,  MAPE: 1.42%\n",
      "[1100 Epochs]    RMSE:0.00106,   MAE: 0.00089,  MAPE: 0.42%\n",
      "[1200 Epochs]    RMSE:0.00593,   MAE: 0.00586,  MAPE: 2.78%\n",
      "[1300 Epochs]    RMSE:0.00347,   MAE: 0.00343,  MAPE: 1.63%\n",
      "[1400 Epochs]    RMSE:0.00637,   MAE: 0.00633,  MAPE: 3.02%\n",
      "[1500 Epochs]    RMSE:0.00190,   MAE: 0.00173,  MAPE: 0.81%\n",
      "[1600 Epochs]    RMSE:0.00273,   MAE: 0.00270,  MAPE: 1.29%\n",
      "[1700 Epochs]    RMSE:0.00117,   MAE: 0.00104,  MAPE: 0.50%\n",
      "[1800 Epochs]    RMSE:0.00168,   MAE: 0.00161,  MAPE: 0.76%\n",
      "[1900 Epochs]    RMSE:0.00076,   MAE: 0.00063,  MAPE: 0.30%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00220,   MAE: 0.00218,  MAPE: 1.05%\n",
      "\n",
      "\n",
      "Trial No.159\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 90\n",
      "[0 Epochs]    RMSE:0.20626,   MAE: 0.20443,  MAPE: 98.51%\n",
      "[100 Epochs]    RMSE:0.00226,   MAE: 0.00196,  MAPE: 0.96%\n",
      "[200 Epochs]    RMSE:0.00212,   MAE: 0.00198,  MAPE: 0.95%\n",
      "[300 Epochs]    RMSE:0.00227,   MAE: 0.00220,  MAPE: 1.06%\n",
      "[400 Epochs]    RMSE:0.00402,   MAE: 0.00365,  MAPE: 1.70%\n",
      "[500 Epochs]    RMSE:0.00282,   MAE: 0.00275,  MAPE: 1.32%\n",
      "[600 Epochs]    RMSE:0.00115,   MAE: 0.00109,  MAPE: 0.52%\n",
      "[700 Epochs]    RMSE:0.00198,   MAE: 0.00193,  MAPE: 0.92%\n",
      "[800 Epochs]    RMSE:0.00126,   MAE: 0.00099,  MAPE: 0.46%\n",
      "[900 Epochs]    RMSE:0.00154,   MAE: 0.00148,  MAPE: 0.71%\n",
      "[1000 Epochs]    RMSE:0.00140,   MAE: 0.00136,  MAPE: 0.65%\n",
      "[1100 Epochs]    RMSE:0.00077,   MAE: 0.00064,  MAPE: 0.32%\n",
      "[1200 Epochs]    RMSE:0.00123,   MAE: 0.00119,  MAPE: 0.56%\n",
      "[1300 Epochs]    RMSE:0.00616,   MAE: 0.00604,  MAPE: 2.86%\n",
      "[1400 Epochs]    RMSE:0.00094,   MAE: 0.00084,  MAPE: 0.41%\n",
      "[1500 Epochs]    RMSE:0.00605,   MAE: 0.00598,  MAPE: 2.84%\n",
      "[1600 Epochs]    RMSE:0.00046,   MAE: 0.00035,  MAPE: 0.17%\n",
      "[1700 Epochs]    RMSE:0.00186,   MAE: 0.00184,  MAPE: 0.88%\n",
      "[1800 Epochs]    RMSE:0.00034,   MAE: 0.00028,  MAPE: 0.13%\n",
      "[1900 Epochs]    RMSE:0.00141,   MAE: 0.00136,  MAPE: 0.66%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Final Epochs]    RMSE:0.00187,   MAE: 0.00185,  MAPE: 0.89%\n",
      "\n",
      "\n",
      "Trial No.160\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.32108,   MAE: 0.31383,  MAPE: 148.93%\n",
      "[100 Epochs]    RMSE:0.00866,   MAE: 0.00862,  MAPE: 4.12%\n",
      "[200 Epochs]    RMSE:0.00329,   MAE: 0.00303,  MAPE: 1.46%\n",
      "[300 Epochs]    RMSE:0.00078,   MAE: 0.00062,  MAPE: 0.30%\n",
      "[400 Epochs]    RMSE:0.00443,   MAE: 0.00427,  MAPE: 2.02%\n",
      "[500 Epochs]    RMSE:0.00063,   MAE: 0.00052,  MAPE: 0.25%\n",
      "[600 Epochs]    RMSE:0.00365,   MAE: 0.00357,  MAPE: 1.70%\n",
      "[700 Epochs]    RMSE:0.00078,   MAE: 0.00068,  MAPE: 0.33%\n",
      "[800 Epochs]    RMSE:0.00223,   MAE: 0.00218,  MAPE: 1.04%\n",
      "[900 Epochs]    RMSE:0.00373,   MAE: 0.00370,  MAPE: 1.78%\n",
      "[1000 Epochs]    RMSE:0.00077,   MAE: 0.00068,  MAPE: 0.33%\n",
      "[1100 Epochs]    RMSE:0.00099,   MAE: 0.00094,  MAPE: 0.45%\n",
      "[1200 Epochs]    RMSE:0.00352,   MAE: 0.00347,  MAPE: 1.68%\n",
      "[1300 Epochs]    RMSE:0.00117,   MAE: 0.00105,  MAPE: 0.51%\n",
      "[1400 Epochs]    RMSE:0.00230,   MAE: 0.00223,  MAPE: 1.06%\n",
      "[1500 Epochs]    RMSE:0.00480,   MAE: 0.00473,  MAPE: 2.25%\n",
      "[1600 Epochs]    RMSE:0.00137,   MAE: 0.00135,  MAPE: 0.65%\n",
      "[1700 Epochs]    RMSE:0.00240,   MAE: 0.00238,  MAPE: 1.14%\n",
      "[1800 Epochs]    RMSE:0.00244,   MAE: 0.00240,  MAPE: 1.14%\n",
      "[1900 Epochs]    RMSE:0.00039,   MAE: 0.00031,  MAPE: 0.15%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00091,   MAE: 0.00085,  MAPE: 0.40%\n",
      "\n",
      "\n",
      "Trial No.161\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 120\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.33001,   MAE: 0.32351,  MAPE: 154.57%\n",
      "[100 Epochs]    RMSE:0.00131,   MAE: 0.00108,  MAPE: 0.51%\n",
      "[200 Epochs]    RMSE:0.00116,   MAE: 0.00095,  MAPE: 0.45%\n",
      "[300 Epochs]    RMSE:0.00560,   MAE: 0.00550,  MAPE: 2.66%\n",
      "[400 Epochs]    RMSE:0.00282,   MAE: 0.00277,  MAPE: 1.33%\n",
      "[500 Epochs]    RMSE:0.00165,   MAE: 0.00151,  MAPE: 0.74%\n",
      "[600 Epochs]    RMSE:0.00243,   MAE: 0.00231,  MAPE: 1.09%\n",
      "[700 Epochs]    RMSE:0.00245,   MAE: 0.00236,  MAPE: 1.13%\n",
      "[800 Epochs]    RMSE:0.00190,   MAE: 0.00173,  MAPE: 0.85%\n",
      "[900 Epochs]    RMSE:0.00126,   MAE: 0.00107,  MAPE: 0.50%\n",
      "[1000 Epochs]    RMSE:0.00090,   MAE: 0.00080,  MAPE: 0.39%\n",
      "[1100 Epochs]    RMSE:0.00434,   MAE: 0.00406,  MAPE: 1.90%\n",
      "[1200 Epochs]    RMSE:0.00077,   MAE: 0.00069,  MAPE: 0.33%\n",
      "[1300 Epochs]    RMSE:0.00131,   MAE: 0.00122,  MAPE: 0.57%\n",
      "[1400 Epochs]    RMSE:0.00190,   MAE: 0.00175,  MAPE: 0.84%\n",
      "[1500 Epochs]    RMSE:0.00120,   MAE: 0.00109,  MAPE: 0.53%\n",
      "[1600 Epochs]    RMSE:0.00190,   MAE: 0.00178,  MAPE: 0.87%\n",
      "[1700 Epochs]    RMSE:0.00216,   MAE: 0.00214,  MAPE: 1.02%\n",
      "[1800 Epochs]    RMSE:0.00123,   MAE: 0.00116,  MAPE: 0.54%\n",
      "[1900 Epochs]    RMSE:0.00187,   MAE: 0.00177,  MAPE: 0.86%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00166,   MAE: 0.00162,  MAPE: 0.78%\n",
      "\n",
      "\n",
      "Trial No.162\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 50\n",
      "[0 Epochs]    RMSE:0.17244,   MAE: 0.14075,  MAPE: 67.44%\n",
      "[100 Epochs]    RMSE:0.00179,   MAE: 0.00151,  MAPE: 0.74%\n",
      "[200 Epochs]    RMSE:0.00391,   MAE: 0.00381,  MAPE: 1.81%\n",
      "[300 Epochs]    RMSE:0.00137,   MAE: 0.00117,  MAPE: 0.55%\n",
      "[400 Epochs]    RMSE:0.00577,   MAE: 0.00567,  MAPE: 2.70%\n",
      "[500 Epochs]    RMSE:0.00410,   MAE: 0.00400,  MAPE: 1.90%\n",
      "[600 Epochs]    RMSE:0.00160,   MAE: 0.00148,  MAPE: 0.71%\n",
      "[700 Epochs]    RMSE:0.00515,   MAE: 0.00498,  MAPE: 2.43%\n",
      "[800 Epochs]    RMSE:0.00139,   MAE: 0.00127,  MAPE: 0.62%\n",
      "[900 Epochs]    RMSE:0.00081,   MAE: 0.00061,  MAPE: 0.28%\n",
      "[1000 Epochs]    RMSE:0.00684,   MAE: 0.00681,  MAPE: 3.25%\n",
      "[1100 Epochs]    RMSE:0.00118,   MAE: 0.00107,  MAPE: 0.51%\n",
      "[1200 Epochs]    RMSE:0.00337,   MAE: 0.00336,  MAPE: 1.61%\n",
      "[1300 Epochs]    RMSE:0.00165,   MAE: 0.00162,  MAPE: 0.78%\n",
      "[1400 Epochs]    RMSE:0.00104,   MAE: 0.00091,  MAPE: 0.45%\n",
      "[1500 Epochs]    RMSE:0.00220,   MAE: 0.00216,  MAPE: 1.03%\n",
      "[1600 Epochs]    RMSE:0.00213,   MAE: 0.00212,  MAPE: 1.01%\n",
      "[1700 Epochs]    RMSE:0.00177,   MAE: 0.00176,  MAPE: 0.84%\n",
      "[1800 Epochs]    RMSE:0.00308,   MAE: 0.00304,  MAPE: 1.44%\n",
      "[1900 Epochs]    RMSE:0.00252,   MAE: 0.00237,  MAPE: 1.11%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00118,   MAE: 0.00105,  MAPE: 0.49%\n",
      "\n",
      "\n",
      "Trial No.163\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 60\n",
      "[0 Epochs]    RMSE:0.14520,   MAE: 0.13637,  MAPE: 64.86%\n",
      "[100 Epochs]    RMSE:0.00137,   MAE: 0.00117,  MAPE: 0.56%\n",
      "[200 Epochs]    RMSE:0.00318,   MAE: 0.00296,  MAPE: 1.40%\n",
      "[300 Epochs]    RMSE:0.00221,   MAE: 0.00213,  MAPE: 1.02%\n",
      "[400 Epochs]    RMSE:0.00502,   MAE: 0.00498,  MAPE: 2.38%\n",
      "[500 Epochs]    RMSE:0.00082,   MAE: 0.00070,  MAPE: 0.33%\n",
      "[600 Epochs]    RMSE:0.00105,   MAE: 0.00089,  MAPE: 0.43%\n",
      "[700 Epochs]    RMSE:0.00539,   MAE: 0.00517,  MAPE: 2.43%\n",
      "[800 Epochs]    RMSE:0.00223,   MAE: 0.00203,  MAPE: 0.95%\n",
      "[900 Epochs]    RMSE:0.00048,   MAE: 0.00042,  MAPE: 0.20%\n",
      "[1000 Epochs]    RMSE:0.00293,   MAE: 0.00273,  MAPE: 1.28%\n",
      "[1100 Epochs]    RMSE:0.00566,   MAE: 0.00532,  MAPE: 2.49%\n",
      "[1200 Epochs]    RMSE:0.00139,   MAE: 0.00134,  MAPE: 0.63%\n",
      "[1300 Epochs]    RMSE:0.00416,   MAE: 0.00405,  MAPE: 1.91%\n",
      "[1400 Epochs]    RMSE:0.00080,   MAE: 0.00072,  MAPE: 0.33%\n",
      "[1500 Epochs]    RMSE:0.00144,   MAE: 0.00115,  MAPE: 0.56%\n",
      "[1600 Epochs]    RMSE:0.00183,   MAE: 0.00180,  MAPE: 0.85%\n",
      "[1700 Epochs]    RMSE:0.00080,   MAE: 0.00077,  MAPE: 0.37%\n",
      "[1800 Epochs]    RMSE:0.00215,   MAE: 0.00210,  MAPE: 0.99%\n",
      "[1900 Epochs]    RMSE:0.00251,   MAE: 0.00245,  MAPE: 1.16%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00100,   MAE: 0.00090,  MAPE: 0.44%\n",
      "\n",
      "\n",
      "Trial No.164\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 70\n",
      "[0 Epochs]    RMSE:0.25789,   MAE: 0.25561,  MAPE: 121.88%\n",
      "[100 Epochs]    RMSE:0.00685,   MAE: 0.00670,  MAPE: 3.21%\n",
      "[200 Epochs]    RMSE:0.00655,   MAE: 0.00650,  MAPE: 3.09%\n",
      "[300 Epochs]    RMSE:0.00451,   MAE: 0.00445,  MAPE: 2.12%\n",
      "[400 Epochs]    RMSE:0.00320,   MAE: 0.00310,  MAPE: 1.47%\n",
      "[500 Epochs]    RMSE:0.00109,   MAE: 0.00085,  MAPE: 0.41%\n",
      "[600 Epochs]    RMSE:0.00379,   MAE: 0.00359,  MAPE: 1.75%\n",
      "[700 Epochs]    RMSE:0.00100,   MAE: 0.00092,  MAPE: 0.43%\n",
      "[800 Epochs]    RMSE:0.00369,   MAE: 0.00361,  MAPE: 1.71%\n",
      "[900 Epochs]    RMSE:0.00121,   MAE: 0.00109,  MAPE: 0.53%\n",
      "[1000 Epochs]    RMSE:0.00966,   MAE: 0.00956,  MAPE: 4.54%\n",
      "[1100 Epochs]    RMSE:0.00183,   MAE: 0.00180,  MAPE: 0.87%\n",
      "[1200 Epochs]    RMSE:0.00068,   MAE: 0.00061,  MAPE: 0.29%\n",
      "[1300 Epochs]    RMSE:0.00135,   MAE: 0.00126,  MAPE: 0.61%\n",
      "[1400 Epochs]    RMSE:0.00158,   MAE: 0.00154,  MAPE: 0.74%\n",
      "[1500 Epochs]    RMSE:0.00149,   MAE: 0.00140,  MAPE: 0.68%\n",
      "[1600 Epochs]    RMSE:0.00158,   MAE: 0.00149,  MAPE: 0.71%\n",
      "[1700 Epochs]    RMSE:0.00161,   MAE: 0.00150,  MAPE: 0.73%\n",
      "[1800 Epochs]    RMSE:0.00059,   MAE: 0.00046,  MAPE: 0.23%\n",
      "[1900 Epochs]    RMSE:0.00155,   MAE: 0.00154,  MAPE: 0.73%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00226,   MAE: 0.00216,  MAPE: 1.05%\n",
      "\n",
      "\n",
      "Trial No.165\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:0.32992,   MAE: 0.32515,  MAPE: 155.20%\n",
      "[100 Epochs]    RMSE:0.01174,   MAE: 0.01166,  MAPE: 5.58%\n",
      "[200 Epochs]    RMSE:0.00543,   MAE: 0.00526,  MAPE: 2.50%\n",
      "[300 Epochs]    RMSE:0.00972,   MAE: 0.00942,  MAPE: 4.44%\n",
      "[400 Epochs]    RMSE:0.00338,   MAE: 0.00322,  MAPE: 1.52%\n",
      "[500 Epochs]    RMSE:0.00063,   MAE: 0.00054,  MAPE: 0.26%\n",
      "[600 Epochs]    RMSE:0.00479,   MAE: 0.00475,  MAPE: 2.27%\n",
      "[700 Epochs]    RMSE:0.00242,   MAE: 0.00238,  MAPE: 1.14%\n",
      "[800 Epochs]    RMSE:0.00174,   MAE: 0.00165,  MAPE: 0.79%\n",
      "[900 Epochs]    RMSE:0.00183,   MAE: 0.00168,  MAPE: 0.79%\n",
      "[1000 Epochs]    RMSE:0.00173,   MAE: 0.00163,  MAPE: 0.77%\n",
      "[1100 Epochs]    RMSE:0.00165,   MAE: 0.00143,  MAPE: 0.67%\n",
      "[1200 Epochs]    RMSE:0.00313,   MAE: 0.00307,  MAPE: 1.45%\n",
      "[1300 Epochs]    RMSE:0.00153,   MAE: 0.00147,  MAPE: 0.69%\n",
      "[1400 Epochs]    RMSE:0.00079,   MAE: 0.00075,  MAPE: 0.36%\n",
      "[1500 Epochs]    RMSE:0.00044,   MAE: 0.00032,  MAPE: 0.15%\n",
      "[1600 Epochs]    RMSE:0.00055,   MAE: 0.00042,  MAPE: 0.21%\n",
      "[1700 Epochs]    RMSE:0.00272,   MAE: 0.00264,  MAPE: 1.25%\n",
      "[1800 Epochs]    RMSE:0.00029,   MAE: 0.00024,  MAPE: 0.12%\n",
      "[1900 Epochs]    RMSE:0.00115,   MAE: 0.00106,  MAPE: 0.50%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00041,   MAE: 0.00033,  MAPE: 0.16%\n",
      "\n",
      "\n",
      "Trial No.166\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 Epochs]    RMSE:0.24429,   MAE: 0.24309,  MAPE: 116.59%\n",
      "[100 Epochs]    RMSE:0.00413,   MAE: 0.00387,  MAPE: 1.83%\n",
      "[200 Epochs]    RMSE:0.00251,   MAE: 0.00232,  MAPE: 1.09%\n",
      "[300 Epochs]    RMSE:0.00663,   MAE: 0.00655,  MAPE: 3.12%\n",
      "[400 Epochs]    RMSE:0.00176,   MAE: 0.00153,  MAPE: 0.72%\n",
      "[500 Epochs]    RMSE:0.00598,   MAE: 0.00589,  MAPE: 2.80%\n",
      "[600 Epochs]    RMSE:0.01180,   MAE: 0.01162,  MAPE: 5.51%\n",
      "[700 Epochs]    RMSE:0.00079,   MAE: 0.00060,  MAPE: 0.29%\n",
      "[800 Epochs]    RMSE:0.00302,   MAE: 0.00292,  MAPE: 1.38%\n",
      "[900 Epochs]    RMSE:0.00271,   MAE: 0.00268,  MAPE: 1.28%\n",
      "[1000 Epochs]    RMSE:0.00232,   MAE: 0.00226,  MAPE: 1.07%\n",
      "[1100 Epochs]    RMSE:0.00162,   MAE: 0.00127,  MAPE: 0.62%\n",
      "[1200 Epochs]    RMSE:0.00039,   MAE: 0.00031,  MAPE: 0.15%\n",
      "[1300 Epochs]    RMSE:0.00251,   MAE: 0.00248,  MAPE: 1.18%\n",
      "[1400 Epochs]    RMSE:0.00138,   MAE: 0.00116,  MAPE: 0.56%\n",
      "[1500 Epochs]    RMSE:0.00488,   MAE: 0.00472,  MAPE: 2.23%\n",
      "[1600 Epochs]    RMSE:0.00133,   MAE: 0.00119,  MAPE: 0.55%\n",
      "[1700 Epochs]    RMSE:0.00071,   MAE: 0.00061,  MAPE: 0.30%\n",
      "[1800 Epochs]    RMSE:0.00345,   MAE: 0.00339,  MAPE: 1.63%\n",
      "[1900 Epochs]    RMSE:0.00147,   MAE: 0.00138,  MAPE: 0.65%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00113,   MAE: 0.00105,  MAPE: 0.50%\n",
      "\n",
      "\n",
      "Trial No.167\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 100\n",
      "[0 Epochs]    RMSE:0.23537,   MAE: 0.23322,  MAPE: 111.13%\n",
      "[100 Epochs]    RMSE:0.00519,   MAE: 0.00510,  MAPE: 2.46%\n",
      "[200 Epochs]    RMSE:0.00199,   MAE: 0.00164,  MAPE: 0.80%\n",
      "[300 Epochs]    RMSE:0.00125,   MAE: 0.00106,  MAPE: 0.51%\n",
      "[400 Epochs]    RMSE:0.00127,   MAE: 0.00110,  MAPE: 0.51%\n",
      "[500 Epochs]    RMSE:0.00321,   MAE: 0.00313,  MAPE: 1.48%\n",
      "[600 Epochs]    RMSE:0.00410,   MAE: 0.00405,  MAPE: 1.95%\n",
      "[700 Epochs]    RMSE:0.00188,   MAE: 0.00148,  MAPE: 0.74%\n",
      "[800 Epochs]    RMSE:0.00225,   MAE: 0.00220,  MAPE: 1.05%\n",
      "[900 Epochs]    RMSE:0.00297,   MAE: 0.00286,  MAPE: 1.35%\n",
      "[1000 Epochs]    RMSE:0.00383,   MAE: 0.00375,  MAPE: 1.79%\n",
      "[1100 Epochs]    RMSE:0.00237,   MAE: 0.00236,  MAPE: 1.13%\n",
      "[1200 Epochs]    RMSE:0.00075,   MAE: 0.00061,  MAPE: 0.29%\n",
      "[1300 Epochs]    RMSE:0.00106,   MAE: 0.00091,  MAPE: 0.42%\n",
      "[1400 Epochs]    RMSE:0.00136,   MAE: 0.00115,  MAPE: 0.57%\n",
      "[1500 Epochs]    RMSE:0.00203,   MAE: 0.00195,  MAPE: 0.92%\n",
      "[1600 Epochs]    RMSE:0.00112,   MAE: 0.00102,  MAPE: 0.48%\n",
      "[1700 Epochs]    RMSE:0.00391,   MAE: 0.00385,  MAPE: 1.83%\n",
      "[1800 Epochs]    RMSE:0.00127,   MAE: 0.00122,  MAPE: 0.58%\n",
      "[1900 Epochs]    RMSE:0.00268,   MAE: 0.00267,  MAPE: 1.28%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00138,   MAE: 0.00135,  MAPE: 0.64%\n",
      "\n",
      "\n",
      "Trial No.168\n",
      "Prediction :VS\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 130\n",
      "Hidden 2 neuron : 110\n",
      "[0 Epochs]    RMSE:0.24412,   MAE: 0.23562,  MAPE: 112.88%\n",
      "[100 Epochs]    RMSE:0.00535,   MAE: 0.00515,  MAPE: 2.43%\n",
      "[200 Epochs]    RMSE:0.00646,   MAE: 0.00628,  MAPE: 3.05%\n",
      "[300 Epochs]    RMSE:0.00375,   MAE: 0.00358,  MAPE: 1.69%\n",
      "[400 Epochs]    RMSE:0.00149,   MAE: 0.00132,  MAPE: 0.62%\n",
      "[500 Epochs]    RMSE:0.00131,   MAE: 0.00120,  MAPE: 0.57%\n",
      "[600 Epochs]    RMSE:0.00221,   MAE: 0.00202,  MAPE: 0.95%\n",
      "[700 Epochs]    RMSE:0.00858,   MAE: 0.00846,  MAPE: 4.02%\n",
      "[800 Epochs]    RMSE:0.00198,   MAE: 0.00173,  MAPE: 0.80%\n",
      "[900 Epochs]    RMSE:0.00414,   MAE: 0.00401,  MAPE: 1.93%\n",
      "[1000 Epochs]    RMSE:0.00221,   MAE: 0.00192,  MAPE: 0.89%\n",
      "[1100 Epochs]    RMSE:0.00270,   MAE: 0.00264,  MAPE: 1.26%\n",
      "[1200 Epochs]    RMSE:0.00438,   MAE: 0.00426,  MAPE: 2.02%\n",
      "[1300 Epochs]    RMSE:0.00112,   MAE: 0.00082,  MAPE: 0.39%\n",
      "[1400 Epochs]    RMSE:0.00074,   MAE: 0.00063,  MAPE: 0.31%\n",
      "[1500 Epochs]    RMSE:0.00173,   MAE: 0.00169,  MAPE: 0.81%\n",
      "[1600 Epochs]    RMSE:0.00289,   MAE: 0.00279,  MAPE: 1.32%\n",
      "[1700 Epochs]    RMSE:0.00223,   MAE: 0.00178,  MAPE: 0.82%\n",
      "[1800 Epochs]    RMSE:0.00207,   MAE: 0.00182,  MAPE: 0.85%\n",
      "[1900 Epochs]    RMSE:0.00537,   MAE: 0.00527,  MAPE: 2.50%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00125,   MAE: 0.00116,  MAPE: 0.57%\n"
     ]
    }
   ],
   "source": [
    "for M in range(1):\n",
    "    \n",
    "    Tr_result_temp = np.zeros((len(Lr)*len(N1)*len(N2) , 7)) # *len(N2)\n",
    "    cnt = 0\n",
    "    \n",
    "#     exec('Label_Trn = TrainLabel_%d'%(M+1))\n",
    "    print('\\n\\n\\n\\n################## Model %d (Predict :'%(M+1) + Model[M] + ') ##################')\n",
    "\n",
    "    for i in range(len(Lr)):\n",
    "        learningRate = Lr[i]\n",
    "\n",
    "        for j in range(len(N1)):\n",
    "            noOfNeuron1 = N1[j]\n",
    "            \n",
    "            for k in range(len(N2)):\n",
    "                noOfNeuron2 = N2[k]\n",
    "\n",
    "                print('\\n\\nTrial No.%d'%(cnt+1))\n",
    "                print('Prediction :' + Model[M])\n",
    "                print('Learning rate : {:.3}'.format(learningRate))\n",
    "                print('Hidden 1 neuron : %d'%(noOfNeuron1))\n",
    "                print('Hidden 2 neuron : %d'%(noOfNeuron2))\n",
    "\n",
    "                ################ 신경망 구조 재설계 ################\n",
    "\n",
    "                tf.keras.backend.clear_session()\n",
    "                def ANN_model(input_data):\n",
    "                    model = keras.Sequential()\n",
    "                    model.add(keras.layers.Dense(units = noOfNeuron_in,\n",
    "                                                 input_shape = (input_data.shape[1],), activation = 'relu'))  # Input  Layer\n",
    "                    model.add(keras.layers.Dense(units = noOfNeuron1,                  activation = 'relu'))  # Hidden Layer 1\n",
    "                    model.add(keras.layers.Dense(units = noOfNeuron2,                  activation = 'relu'))  # Hidden Layer 2\n",
    "                    model.add(keras.layers.Dense(units = noOfNeuron_out,             )) # Output Layer\n",
    "                    model.compile(optimizer= keras.optimizers.Adam(learning_rate = learningRate),\n",
    "                                  loss=keras.losses.mean_absolute_error,\n",
    "                                  metrics=['mse','mae','mape'])\n",
    "                    return model\n",
    "                model = ANN_model(TrainData)\n",
    "\n",
    "                ################ 신경망 학습 ################\n",
    "\n",
    "                hist = model.fit(TrainData, TrainLabel, epochs=Epoch, verbose=0, callbacks=[AccuracyPerEpoch()], batch_size=100)\n",
    "                print(\"\\n[Final Epochs]    RMSE:{:.5f},   MAE: {:.5f},  MAPE: {:.2f}%\"\n",
    "                      .format(np.sqrt(hist.history['mse'][-1]), hist.history['mae'][-1], hist.history['mape'][-1]))\n",
    "                \n",
    "                model.save('./27case_MLmodels_ANN_PRESM/Model_%d.h5'%(cnt+1))\n",
    "                \n",
    "                Tr_result_temp[cnt,0] = cnt+1\n",
    "                Tr_result_temp[cnt,1] = learningRate\n",
    "                Tr_result_temp[cnt,2] = noOfNeuron1\n",
    "                Tr_result_temp[cnt,3] = noOfNeuron2\n",
    "                Tr_result_temp[cnt,4] = np.sqrt(hist.history['mse'][-1])\n",
    "                Tr_result_temp[cnt,5] = hist.history['mae'][-1]\n",
    "                Tr_result_temp[cnt,6] = hist.history['mape'][-1]\n",
    "\n",
    "                cnt=cnt+1\n",
    "\n",
    "\n",
    "    Tr_result_temp_pd = pd.DataFrame(Tr_result_temp, columns=['Case', 'L.rate', 'Nr-HL1', 'Nr-HL2', 'RMSE', 'MAE', 'MAPE'])\n",
    "    Tr_result_temp_pd.to_csv('./27case_MLmodels_ANN_PRESM/Tr_result_epoch%d.csv'%(Epoch), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case</th>\n",
       "      <th>L.rate</th>\n",
       "      <th>Nr-HL1</th>\n",
       "      <th>Nr-HL2</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>1.114962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.464327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.601094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.321654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.913936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.910179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>1.283337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.379926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.266152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.422008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.309086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.263745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.509328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.349048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>80.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.222886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>80.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>1.194411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.350246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.451806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.547288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.285752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>80.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.748390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>90.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.216917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>90.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.359745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.563660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>1.833380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>2.421476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.520786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>90.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.368773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.901470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.413682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.201417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>1.367085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.270865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.473161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.400750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>110.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.421171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.423096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.446219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>110.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.393303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>110.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.255345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.232888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>110.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>1.879270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.329232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.490429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>1.816826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.228395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>1.107570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.423170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.280522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>130.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.192892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>130.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.528145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>130.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.622012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.216189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>130.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>1.016666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>130.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.845140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>130.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.392552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>2.195871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.324256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.003107</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>1.421473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>60.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.243914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>1.160351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.532258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.277110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>70.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.232339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.243951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>1.125594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.610012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>70.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.329605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.454165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>70.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.168656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>80.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.173938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>80.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.444965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.697845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>1.301125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.405643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>1.727930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>80.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.407115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>90.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.367313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>90.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.836505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.952982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.382792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>1.174958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.968217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>90.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.505266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.397356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.781249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.472181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.670399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.465913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>1.312869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.807626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>110.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.689362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.419899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.158362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>110.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.571894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>110.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>2.151254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>1.649915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>110.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.383256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>120.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>1.278503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>120.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.827587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>120.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.510719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>102.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.533306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.392253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>104.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.974752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>105.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>120.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>1.080126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>106.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>130.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.076804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>130.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>1.399883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>108.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>130.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.338021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>2.685189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>110.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>130.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>1.141363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>111.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>130.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>1.998603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>112.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>130.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>2.387343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>113.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.786941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>114.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>1.193413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>115.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.302754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>116.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>60.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.283688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.002855</td>\n",
       "      <td>1.339004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>118.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.112332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>119.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.124308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>70.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.170757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.005431</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>2.500420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>1.443725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>123.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.275219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>124.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>70.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.159138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>125.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.003108</td>\n",
       "      <td>1.486920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>126.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>70.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.614413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>127.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.268922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.204525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>129.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.271399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>130.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>1.727239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>131.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.543218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.502965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.002294</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.068798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>134.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>90.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.974951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>135.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>90.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.312051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>136.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.904558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>137.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.204173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>138.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.310160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>139.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.109196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>90.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.895982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>141.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.820400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>142.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.274704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>143.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.563311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>144.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1.311379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>145.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>1.020794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.919168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.196123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>110.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.542392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>1.723200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>1.038641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>151.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>110.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.462778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>152.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>110.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>1.112673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>153.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.313357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>154.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>110.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.412848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>155.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>120.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.959919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>156.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>120.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.197200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>120.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.709317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>158.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>1.050483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>159.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.885109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>160.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.402048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>161.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>120.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.779383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>162.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>130.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.491087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>163.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>130.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.441235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>164.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>130.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>1.054536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>165.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.155035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>166.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>130.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.496191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>167.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>130.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.643388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>130.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.565382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case  L.rate  Nr-HL1  Nr-HL2      RMSE       MAE      MAPE\n",
       "0      1.0   0.001    60.0    50.0  0.002432  0.002349  1.114962\n",
       "1      2.0   0.001    60.0    60.0  0.001188  0.000959  0.464327\n",
       "2      3.0   0.001    60.0    70.0  0.001449  0.001283  0.601094\n",
       "3      4.0   0.001    60.0    80.0  0.000910  0.000651  0.321654\n",
       "4      5.0   0.001    60.0    90.0  0.002411  0.001930  0.913936\n",
       "5      6.0   0.001    60.0   100.0  0.001974  0.001919  0.910179\n",
       "6      7.0   0.001    60.0   110.0  0.002840  0.002688  1.283337\n",
       "7      8.0   0.001    70.0    50.0  0.000939  0.000778  0.379926\n",
       "8      9.0   0.001    70.0    60.0  0.000748  0.000569  0.266152\n",
       "9     10.0   0.001    70.0    70.0  0.001034  0.000872  0.422008\n",
       "10    11.0   0.001    70.0    80.0  0.000781  0.000650  0.309086\n",
       "11    12.0   0.001    70.0    90.0  0.000652  0.000548  0.263745\n",
       "12    13.0   0.001    70.0   100.0  0.001283  0.001053  0.509328\n",
       "13    14.0   0.001    70.0   110.0  0.000929  0.000731  0.349048\n",
       "14    15.0   0.001    80.0    50.0  0.000597  0.000479  0.222886\n",
       "15    16.0   0.001    80.0    60.0  0.002676  0.002501  1.194411\n",
       "16    17.0   0.001    80.0    70.0  0.000929  0.000742  0.350246\n",
       "17    18.0   0.001    80.0    80.0  0.001216  0.000930  0.451806\n",
       "18    19.0   0.001    80.0    90.0  0.001477  0.001136  0.547288\n",
       "19    20.0   0.001    80.0   100.0  0.000762  0.000604  0.285752\n",
       "20    21.0   0.001    80.0   110.0  0.001753  0.001592  0.748390\n",
       "21    22.0   0.001    90.0    50.0  0.000580  0.000442  0.216917\n",
       "22    23.0   0.001    90.0    60.0  0.000906  0.000759  0.359745\n",
       "23    24.0   0.001    90.0    70.0  0.001365  0.001167  0.563660\n",
       "24    25.0   0.001    90.0    80.0  0.003953  0.003833  1.833380\n",
       "25    26.0   0.001    90.0    90.0  0.005221  0.005087  2.421476\n",
       "26    27.0   0.001    90.0   100.0  0.001234  0.001106  0.520786\n",
       "27    28.0   0.001    90.0   110.0  0.000944  0.000745  0.368773\n",
       "28    29.0   0.001   100.0    50.0  0.002196  0.001880  0.901470\n",
       "29    30.0   0.001   100.0    60.0  0.001267  0.000905  0.413682\n",
       "30    31.0   0.001   100.0    70.0  0.000488  0.000410  0.201417\n",
       "31    32.0   0.001   100.0    80.0  0.003210  0.002891  1.367085\n",
       "32    33.0   0.001   100.0    90.0  0.000732  0.000556  0.270865\n",
       "33    34.0   0.001   100.0   100.0  0.001164  0.000977  0.473161\n",
       "34    35.0   0.001   100.0   110.0  0.001024  0.000836  0.400750\n",
       "35    36.0   0.001   110.0    50.0  0.000962  0.000880  0.421171\n",
       "36    37.0   0.001   110.0    60.0  0.001178  0.000917  0.423096\n",
       "37    38.0   0.001   110.0    70.0  0.001245  0.000973  0.446219\n",
       "38    39.0   0.001   110.0    80.0  0.000965  0.000819  0.393303\n",
       "39    40.0   0.001   110.0    90.0  0.000633  0.000524  0.255345\n",
       "40    41.0   0.001   110.0   100.0  0.000753  0.000467  0.232888\n",
       "41    42.0   0.001   110.0   110.0  0.003983  0.003917  1.879270\n",
       "42    43.0   0.001   120.0    50.0  0.000945  0.000711  0.329232\n",
       "43    44.0   0.001   120.0    60.0  0.001086  0.001018  0.490429\n",
       "44    45.0   0.001   120.0    70.0  0.003883  0.003786  1.816826\n",
       "45    46.0   0.001   120.0    80.0  0.000621  0.000470  0.228395\n",
       "46    47.0   0.001   120.0    90.0  0.002488  0.002329  1.107570\n",
       "47    48.0   0.001   120.0   100.0  0.001121  0.000886  0.423170\n",
       "48    49.0   0.001   120.0   110.0  0.000684  0.000590  0.280522\n",
       "49    50.0   0.001   130.0    50.0  0.000478  0.000404  0.192892\n",
       "50    51.0   0.001   130.0    60.0  0.001277  0.001128  0.528145\n",
       "51    52.0   0.001   130.0    70.0  0.001570  0.001331  0.622012\n",
       "52    53.0   0.001   130.0    80.0  0.000545  0.000456  0.216189\n",
       "53    54.0   0.001   130.0    90.0  0.002325  0.002088  1.016666\n",
       "54    55.0   0.001   130.0   100.0  0.001897  0.001771  0.845140\n",
       "55    56.0   0.001   130.0   110.0  0.000963  0.000831  0.392552\n",
       "56    57.0   0.005    60.0    50.0  0.004681  0.004624  2.195871\n",
       "57    58.0   0.005    60.0    60.0  0.000784  0.000684  0.324256\n",
       "58    59.0   0.005    60.0    70.0  0.003107  0.003001  1.421473\n",
       "59    60.0   0.005    60.0    80.0  0.000596  0.000500  0.243914\n",
       "60    61.0   0.005    60.0    90.0  0.002466  0.002429  1.160351\n",
       "61    62.0   0.005    60.0   100.0  0.001297  0.001136  0.532258\n",
       "62    63.0   0.005    60.0   110.0  0.000658  0.000583  0.277110\n",
       "63    64.0   0.005    70.0    50.0  0.000552  0.000472  0.232339\n",
       "64    65.0   0.005    70.0    60.0  0.000741  0.000529  0.243951\n",
       "65    66.0   0.005    70.0    70.0  0.002636  0.002412  1.125594\n",
       "66    67.0   0.005    70.0    80.0  0.001375  0.001285  0.610012\n",
       "67    68.0   0.005    70.0    90.0  0.000821  0.000700  0.329605\n",
       "68    69.0   0.005    70.0   100.0  0.001038  0.000940  0.454165\n",
       "69    70.0   0.005    70.0   110.0  0.000460  0.000357  0.168656\n",
       "70    71.0   0.005    80.0    50.0  0.000461  0.000367  0.173938\n",
       "71    72.0   0.005    80.0    60.0  0.001035  0.000903  0.444965\n",
       "72    73.0   0.005    80.0    70.0  0.001535  0.001464  0.697845\n",
       "73    74.0   0.005    80.0    80.0  0.002756  0.002716  1.301125\n",
       "74    75.0   0.005    80.0    90.0  0.001030  0.000867  0.405643\n",
       "75    76.0   0.005    80.0   100.0  0.003877  0.003681  1.727930\n",
       "76    77.0   0.005    80.0   110.0  0.000958  0.000855  0.407115\n",
       "77    78.0   0.005    90.0    50.0  0.000801  0.000776  0.367313\n",
       "78    79.0   0.005    90.0    60.0  0.001782  0.001730  0.836505\n",
       "79    80.0   0.005    90.0    70.0  0.002018  0.001992  0.952982\n",
       "80    81.0   0.005    90.0    80.0  0.000891  0.000796  0.382792\n",
       "81    82.0   0.005    90.0    90.0  0.002482  0.002449  1.174958\n",
       "82    83.0   0.005    90.0   100.0  0.002060  0.002025  0.968217\n",
       "83    84.0   0.005    90.0   110.0  0.001252  0.001024  0.505266\n",
       "84    85.0   0.005   100.0    50.0  0.000954  0.000853  0.397356\n",
       "85    86.0   0.005   100.0    60.0  0.001673  0.001626  0.781249\n",
       "86    87.0   0.005   100.0    70.0  0.001177  0.001000  0.472181\n",
       "87    88.0   0.005   100.0    80.0  0.001465  0.001398  0.670399\n",
       "88    89.0   0.005   100.0    90.0  0.001175  0.001001  0.465913\n",
       "89    90.0   0.005   100.0   100.0  0.002836  0.002762  1.312869\n",
       "90    91.0   0.005   100.0   110.0  0.001706  0.001675  0.807626\n",
       "91    92.0   0.005   110.0    50.0  0.001485  0.001418  0.689362\n",
       "92    93.0   0.005   110.0    60.0  0.001032  0.000901  0.419899\n",
       "93    94.0   0.005   110.0    70.0  0.000430  0.000341  0.158362\n",
       "94    95.0   0.005   110.0    80.0  0.001316  0.001203  0.571894\n",
       "95    96.0   0.005   110.0    90.0  0.004514  0.004500  2.151254\n",
       "96    97.0   0.005   110.0   100.0  0.003466  0.003449  1.649915\n",
       "97    98.0   0.005   110.0   110.0  0.000893  0.000777  0.383256\n",
       "98    99.0   0.005   120.0    50.0  0.002820  0.002716  1.278503\n",
       "99   100.0   0.005   120.0    60.0  0.001752  0.001711  0.827587\n",
       "100  101.0   0.005   120.0    70.0  0.001291  0.001099  0.510719\n",
       "101  102.0   0.005   120.0    80.0  0.001354  0.001145  0.533306\n",
       "102  103.0   0.005   120.0    90.0  0.000869  0.000826  0.392253\n",
       "103  104.0   0.005   120.0   100.0  0.002074  0.002029  0.974752\n",
       "104  105.0   0.005   120.0   110.0  0.002595  0.002325  1.080126\n",
       "105  106.0   0.005   130.0    50.0  0.000215  0.000157  0.076804\n",
       "106  107.0   0.005   130.0    60.0  0.003022  0.002894  1.399883\n",
       "107  108.0   0.005   130.0    70.0  0.000823  0.000725  0.338021\n",
       "108  109.0   0.005   130.0    80.0  0.005801  0.005666  2.685189\n",
       "109  110.0   0.005   130.0    90.0  0.002484  0.002406  1.141363\n",
       "110  111.0   0.005   130.0   100.0  0.004253  0.004208  1.998603\n",
       "111  112.0   0.005   130.0   110.0  0.005102  0.005032  2.387343\n",
       "112  113.0   0.010    60.0    50.0  0.001787  0.001618  0.786941\n",
       "113  114.0   0.010    60.0    60.0  0.002503  0.002490  1.193413\n",
       "114  115.0   0.010    60.0    70.0  0.000744  0.000616  0.302754\n",
       "115  116.0   0.010    60.0    80.0  0.000661  0.000579  0.283688\n",
       "116  117.0   0.010    60.0    90.0  0.003099  0.002855  1.339004\n",
       "117  118.0   0.010    60.0   100.0  0.000296  0.000235  0.112332\n",
       "118  119.0   0.010    60.0   110.0  0.000358  0.000269  0.124308\n",
       "119  120.0   0.010    70.0    50.0  0.000413  0.000357  0.170757\n",
       "120  121.0   0.010    70.0    60.0  0.005431  0.005269  2.500420\n",
       "121  122.0   0.010    70.0    70.0  0.003046  0.003023  1.443725\n",
       "122  123.0   0.010    70.0    80.0  0.000692  0.000594  0.275219\n",
       "123  124.0   0.010    70.0    90.0  0.000410  0.000335  0.159138\n",
       "124  125.0   0.010    70.0   100.0  0.003115  0.003108  1.486920\n",
       "125  126.0   0.010    70.0   110.0  0.001464  0.001321  0.614413\n",
       "126  127.0   0.010    80.0    50.0  0.000649  0.000570  0.268922\n",
       "127  128.0   0.010    80.0    60.0  0.000503  0.000418  0.204525\n",
       "128  129.0   0.010    80.0    70.0  0.000728  0.000584  0.271399\n",
       "129  130.0   0.010    80.0    80.0  0.003645  0.003625  1.727239\n",
       "130  131.0   0.010    80.0    90.0  0.001338  0.001172  0.543218\n",
       "131  132.0   0.010    80.0   100.0  0.001077  0.001053  0.502965\n",
       "132  133.0   0.010    80.0   110.0  0.002294  0.002200  1.068798\n",
       "133  134.0   0.010    90.0    50.0  0.002065  0.002042  0.974951\n",
       "134  135.0   0.010    90.0    60.0  0.000787  0.000652  0.312051\n",
       "135  136.0   0.010    90.0    70.0  0.001994  0.001919  0.904558\n",
       "136  137.0   0.010    90.0    80.0  0.000524  0.000425  0.204173\n",
       "137  138.0   0.010    90.0    90.0  0.000873  0.000676  0.310160\n",
       "138  139.0   0.010    90.0   100.0  0.000289  0.000234  0.109196\n",
       "139  140.0   0.010    90.0   110.0  0.001906  0.001871  0.895982\n",
       "140  141.0   0.010   100.0    50.0  0.001876  0.001750  0.820400\n",
       "141  142.0   0.010   100.0    60.0  0.000680  0.000581  0.274704\n",
       "142  143.0   0.010   100.0    70.0  0.001232  0.001173  0.563311\n",
       "143  144.0   0.010   100.0    80.0  0.002785  0.002750  1.311379\n",
       "144  145.0   0.010   100.0    90.0  0.002185  0.002125  1.020794\n",
       "145  146.0   0.010   100.0   100.0  0.002172  0.001974  0.919168\n",
       "146  147.0   0.010   100.0   110.0  0.000482  0.000398  0.196123\n",
       "147  148.0   0.010   110.0    50.0  0.001201  0.001122  0.542392\n",
       "148  149.0   0.010   110.0    60.0  0.003615  0.003574  1.723200\n",
       "149  150.0   0.010   110.0    70.0  0.002197  0.002158  1.038641\n",
       "150  151.0   0.010   110.0    80.0  0.000992  0.000972  0.462778\n",
       "151  152.0   0.010   110.0    90.0  0.002328  0.002315  1.112673\n",
       "152  153.0   0.010   110.0   100.0  0.000794  0.000628  0.313357\n",
       "153  154.0   0.010   110.0   110.0  0.001101  0.000896  0.412848\n",
       "154  155.0   0.010   120.0    50.0  0.002144  0.002036  0.959919\n",
       "155  156.0   0.010   120.0    60.0  0.000481  0.000416  0.197200\n",
       "156  157.0   0.010   120.0    70.0  0.001527  0.001489  0.709317\n",
       "157  158.0   0.010   120.0    80.0  0.002200  0.002184  1.050483\n",
       "158  159.0   0.010   120.0    90.0  0.001869  0.001849  0.885109\n",
       "159  160.0   0.010   120.0   100.0  0.000915  0.000845  0.402048\n",
       "160  161.0   0.010   120.0   110.0  0.001659  0.001624  0.779383\n",
       "161  162.0   0.010   130.0    50.0  0.001180  0.001053  0.491087\n",
       "162  163.0   0.010   130.0    60.0  0.001003  0.000898  0.441235\n",
       "163  164.0   0.010   130.0    70.0  0.002259  0.002162  1.054536\n",
       "164  165.0   0.010   130.0    80.0  0.000415  0.000330  0.155035\n",
       "165  166.0   0.010   130.0    90.0  0.001133  0.001053  0.496191\n",
       "166  167.0   0.010   130.0   100.0  0.001384  0.001348  0.643388\n",
       "167  168.0   0.010   130.0   110.0  0.001247  0.001158  0.565382"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tr_result_temp_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case</th>\n",
       "      <th>L.rate</th>\n",
       "      <th>Nr-HL1</th>\n",
       "      <th>Nr-HL2</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>106.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>130.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.076804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>139.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.109196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>118.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.112332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>119.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.124308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>165.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.155035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.158362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>124.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>70.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.159138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>70.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.168656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>70.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.170757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>80.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.173938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>130.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.192892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.196123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>156.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>120.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.197200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.201417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>137.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.204173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.204525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.216189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>90.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.216917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>80.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.222886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.228395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>70.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.232339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.232888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>60.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.243914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.243951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>110.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.255345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.263745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.266152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>127.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.268922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.270865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>129.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.271399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>142.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.274704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>123.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.275219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.277110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.280522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>116.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>60.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.283688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.285752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>115.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.302754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.309086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>138.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.310160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>135.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>90.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.312051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>153.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.313357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.321654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.324256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.329232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>70.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.329605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>108.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>130.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.338021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.349048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.350246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>90.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.359745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>90.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.367313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>90.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.368773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.379926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.382792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>110.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.383256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.392253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>130.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.392552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>110.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.393303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.397356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.400750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>160.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.402048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.405643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>80.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.407115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>154.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>110.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.412848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.413682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.419899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>110.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.421171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.422008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.423096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.423170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>163.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>130.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.441235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>80.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.444965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.446219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.451806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.454165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>151.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>110.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.462778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.464327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.465913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.472181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.473161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.490429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>162.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>130.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.491087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>166.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>130.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.496191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.502965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>90.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.505266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.509328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>120.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.510719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.520786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>130.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.528145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.532258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>102.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.533306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>110.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.542392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>131.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.543218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.547288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>143.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.563311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.563660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>168.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>130.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.565382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>110.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.571894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.601094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.610012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>126.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>70.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.614413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>130.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.622012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>167.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>130.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.643388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.670399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>110.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.689362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.697845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>120.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.709317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>80.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.748390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>161.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>120.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.779383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.781249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>113.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.786941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.807626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>141.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.820400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>120.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.827587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>90.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.836505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>130.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.845140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>159.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.885109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>90.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.895982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.901470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>136.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.904558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.910179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.913936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.919168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.952982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>155.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>120.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.959919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.968217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>104.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.974752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>134.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>90.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.974951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>130.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>1.016666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>145.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>1.020794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>1.038641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>158.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>1.050483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>164.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>130.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>1.054536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.002294</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.068798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>105.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>120.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>1.080126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>1.107570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>152.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>110.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>1.112673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>1.114962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>1.125594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>110.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>130.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>1.141363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>1.160351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>1.174958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>114.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>1.193413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>80.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>1.194411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>120.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>1.278503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>1.283337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>1.301125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>144.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1.311379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>1.312869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.002855</td>\n",
       "      <td>1.339004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>1.367085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>130.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>1.399883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.003107</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>1.421473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>1.443725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>125.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.003108</td>\n",
       "      <td>1.486920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>1.649915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>1.723200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>130.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>1.727239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>1.727930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>1.816826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>1.833380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>110.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>1.879270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>111.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>130.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>1.998603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>110.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>2.151254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>2.195871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>112.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>130.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>2.387343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>2.421476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.005431</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>2.500420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>2.685189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case  L.rate  Nr-HL1  Nr-HL2      RMSE       MAE      MAPE\n",
       "105  106.0   0.005   130.0    50.0  0.000215  0.000157  0.076804\n",
       "138  139.0   0.010    90.0   100.0  0.000289  0.000234  0.109196\n",
       "117  118.0   0.010    60.0   100.0  0.000296  0.000235  0.112332\n",
       "118  119.0   0.010    60.0   110.0  0.000358  0.000269  0.124308\n",
       "164  165.0   0.010   130.0    80.0  0.000415  0.000330  0.155035\n",
       "93    94.0   0.005   110.0    70.0  0.000430  0.000341  0.158362\n",
       "123  124.0   0.010    70.0    90.0  0.000410  0.000335  0.159138\n",
       "69    70.0   0.005    70.0   110.0  0.000460  0.000357  0.168656\n",
       "119  120.0   0.010    70.0    50.0  0.000413  0.000357  0.170757\n",
       "70    71.0   0.005    80.0    50.0  0.000461  0.000367  0.173938\n",
       "49    50.0   0.001   130.0    50.0  0.000478  0.000404  0.192892\n",
       "146  147.0   0.010   100.0   110.0  0.000482  0.000398  0.196123\n",
       "155  156.0   0.010   120.0    60.0  0.000481  0.000416  0.197200\n",
       "30    31.0   0.001   100.0    70.0  0.000488  0.000410  0.201417\n",
       "136  137.0   0.010    90.0    80.0  0.000524  0.000425  0.204173\n",
       "127  128.0   0.010    80.0    60.0  0.000503  0.000418  0.204525\n",
       "52    53.0   0.001   130.0    80.0  0.000545  0.000456  0.216189\n",
       "21    22.0   0.001    90.0    50.0  0.000580  0.000442  0.216917\n",
       "14    15.0   0.001    80.0    50.0  0.000597  0.000479  0.222886\n",
       "45    46.0   0.001   120.0    80.0  0.000621  0.000470  0.228395\n",
       "63    64.0   0.005    70.0    50.0  0.000552  0.000472  0.232339\n",
       "40    41.0   0.001   110.0   100.0  0.000753  0.000467  0.232888\n",
       "59    60.0   0.005    60.0    80.0  0.000596  0.000500  0.243914\n",
       "64    65.0   0.005    70.0    60.0  0.000741  0.000529  0.243951\n",
       "39    40.0   0.001   110.0    90.0  0.000633  0.000524  0.255345\n",
       "11    12.0   0.001    70.0    90.0  0.000652  0.000548  0.263745\n",
       "8      9.0   0.001    70.0    60.0  0.000748  0.000569  0.266152\n",
       "126  127.0   0.010    80.0    50.0  0.000649  0.000570  0.268922\n",
       "32    33.0   0.001   100.0    90.0  0.000732  0.000556  0.270865\n",
       "128  129.0   0.010    80.0    70.0  0.000728  0.000584  0.271399\n",
       "141  142.0   0.010   100.0    60.0  0.000680  0.000581  0.274704\n",
       "122  123.0   0.010    70.0    80.0  0.000692  0.000594  0.275219\n",
       "62    63.0   0.005    60.0   110.0  0.000658  0.000583  0.277110\n",
       "48    49.0   0.001   120.0   110.0  0.000684  0.000590  0.280522\n",
       "115  116.0   0.010    60.0    80.0  0.000661  0.000579  0.283688\n",
       "19    20.0   0.001    80.0   100.0  0.000762  0.000604  0.285752\n",
       "114  115.0   0.010    60.0    70.0  0.000744  0.000616  0.302754\n",
       "10    11.0   0.001    70.0    80.0  0.000781  0.000650  0.309086\n",
       "137  138.0   0.010    90.0    90.0  0.000873  0.000676  0.310160\n",
       "134  135.0   0.010    90.0    60.0  0.000787  0.000652  0.312051\n",
       "152  153.0   0.010   110.0   100.0  0.000794  0.000628  0.313357\n",
       "3      4.0   0.001    60.0    80.0  0.000910  0.000651  0.321654\n",
       "57    58.0   0.005    60.0    60.0  0.000784  0.000684  0.324256\n",
       "42    43.0   0.001   120.0    50.0  0.000945  0.000711  0.329232\n",
       "67    68.0   0.005    70.0    90.0  0.000821  0.000700  0.329605\n",
       "107  108.0   0.005   130.0    70.0  0.000823  0.000725  0.338021\n",
       "13    14.0   0.001    70.0   110.0  0.000929  0.000731  0.349048\n",
       "16    17.0   0.001    80.0    70.0  0.000929  0.000742  0.350246\n",
       "22    23.0   0.001    90.0    60.0  0.000906  0.000759  0.359745\n",
       "77    78.0   0.005    90.0    50.0  0.000801  0.000776  0.367313\n",
       "27    28.0   0.001    90.0   110.0  0.000944  0.000745  0.368773\n",
       "7      8.0   0.001    70.0    50.0  0.000939  0.000778  0.379926\n",
       "80    81.0   0.005    90.0    80.0  0.000891  0.000796  0.382792\n",
       "97    98.0   0.005   110.0   110.0  0.000893  0.000777  0.383256\n",
       "102  103.0   0.005   120.0    90.0  0.000869  0.000826  0.392253\n",
       "55    56.0   0.001   130.0   110.0  0.000963  0.000831  0.392552\n",
       "38    39.0   0.001   110.0    80.0  0.000965  0.000819  0.393303\n",
       "84    85.0   0.005   100.0    50.0  0.000954  0.000853  0.397356\n",
       "34    35.0   0.001   100.0   110.0  0.001024  0.000836  0.400750\n",
       "159  160.0   0.010   120.0   100.0  0.000915  0.000845  0.402048\n",
       "74    75.0   0.005    80.0    90.0  0.001030  0.000867  0.405643\n",
       "76    77.0   0.005    80.0   110.0  0.000958  0.000855  0.407115\n",
       "153  154.0   0.010   110.0   110.0  0.001101  0.000896  0.412848\n",
       "29    30.0   0.001   100.0    60.0  0.001267  0.000905  0.413682\n",
       "92    93.0   0.005   110.0    60.0  0.001032  0.000901  0.419899\n",
       "35    36.0   0.001   110.0    50.0  0.000962  0.000880  0.421171\n",
       "9     10.0   0.001    70.0    70.0  0.001034  0.000872  0.422008\n",
       "36    37.0   0.001   110.0    60.0  0.001178  0.000917  0.423096\n",
       "47    48.0   0.001   120.0   100.0  0.001121  0.000886  0.423170\n",
       "162  163.0   0.010   130.0    60.0  0.001003  0.000898  0.441235\n",
       "71    72.0   0.005    80.0    60.0  0.001035  0.000903  0.444965\n",
       "37    38.0   0.001   110.0    70.0  0.001245  0.000973  0.446219\n",
       "17    18.0   0.001    80.0    80.0  0.001216  0.000930  0.451806\n",
       "68    69.0   0.005    70.0   100.0  0.001038  0.000940  0.454165\n",
       "150  151.0   0.010   110.0    80.0  0.000992  0.000972  0.462778\n",
       "1      2.0   0.001    60.0    60.0  0.001188  0.000959  0.464327\n",
       "88    89.0   0.005   100.0    90.0  0.001175  0.001001  0.465913\n",
       "86    87.0   0.005   100.0    70.0  0.001177  0.001000  0.472181\n",
       "33    34.0   0.001   100.0   100.0  0.001164  0.000977  0.473161\n",
       "43    44.0   0.001   120.0    60.0  0.001086  0.001018  0.490429\n",
       "161  162.0   0.010   130.0    50.0  0.001180  0.001053  0.491087\n",
       "165  166.0   0.010   130.0    90.0  0.001133  0.001053  0.496191\n",
       "131  132.0   0.010    80.0   100.0  0.001077  0.001053  0.502965\n",
       "83    84.0   0.005    90.0   110.0  0.001252  0.001024  0.505266\n",
       "12    13.0   0.001    70.0   100.0  0.001283  0.001053  0.509328\n",
       "100  101.0   0.005   120.0    70.0  0.001291  0.001099  0.510719\n",
       "26    27.0   0.001    90.0   100.0  0.001234  0.001106  0.520786\n",
       "50    51.0   0.001   130.0    60.0  0.001277  0.001128  0.528145\n",
       "61    62.0   0.005    60.0   100.0  0.001297  0.001136  0.532258\n",
       "101  102.0   0.005   120.0    80.0  0.001354  0.001145  0.533306\n",
       "147  148.0   0.010   110.0    50.0  0.001201  0.001122  0.542392\n",
       "130  131.0   0.010    80.0    90.0  0.001338  0.001172  0.543218\n",
       "18    19.0   0.001    80.0    90.0  0.001477  0.001136  0.547288\n",
       "142  143.0   0.010   100.0    70.0  0.001232  0.001173  0.563311\n",
       "23    24.0   0.001    90.0    70.0  0.001365  0.001167  0.563660\n",
       "167  168.0   0.010   130.0   110.0  0.001247  0.001158  0.565382\n",
       "94    95.0   0.005   110.0    80.0  0.001316  0.001203  0.571894\n",
       "2      3.0   0.001    60.0    70.0  0.001449  0.001283  0.601094\n",
       "66    67.0   0.005    70.0    80.0  0.001375  0.001285  0.610012\n",
       "125  126.0   0.010    70.0   110.0  0.001464  0.001321  0.614413\n",
       "51    52.0   0.001   130.0    70.0  0.001570  0.001331  0.622012\n",
       "166  167.0   0.010   130.0   100.0  0.001384  0.001348  0.643388\n",
       "87    88.0   0.005   100.0    80.0  0.001465  0.001398  0.670399\n",
       "91    92.0   0.005   110.0    50.0  0.001485  0.001418  0.689362\n",
       "72    73.0   0.005    80.0    70.0  0.001535  0.001464  0.697845\n",
       "156  157.0   0.010   120.0    70.0  0.001527  0.001489  0.709317\n",
       "20    21.0   0.001    80.0   110.0  0.001753  0.001592  0.748390\n",
       "160  161.0   0.010   120.0   110.0  0.001659  0.001624  0.779383\n",
       "85    86.0   0.005   100.0    60.0  0.001673  0.001626  0.781249\n",
       "112  113.0   0.010    60.0    50.0  0.001787  0.001618  0.786941\n",
       "90    91.0   0.005   100.0   110.0  0.001706  0.001675  0.807626\n",
       "140  141.0   0.010   100.0    50.0  0.001876  0.001750  0.820400\n",
       "99   100.0   0.005   120.0    60.0  0.001752  0.001711  0.827587\n",
       "78    79.0   0.005    90.0    60.0  0.001782  0.001730  0.836505\n",
       "54    55.0   0.001   130.0   100.0  0.001897  0.001771  0.845140\n",
       "158  159.0   0.010   120.0    90.0  0.001869  0.001849  0.885109\n",
       "139  140.0   0.010    90.0   110.0  0.001906  0.001871  0.895982\n",
       "28    29.0   0.001   100.0    50.0  0.002196  0.001880  0.901470\n",
       "135  136.0   0.010    90.0    70.0  0.001994  0.001919  0.904558\n",
       "5      6.0   0.001    60.0   100.0  0.001974  0.001919  0.910179\n",
       "4      5.0   0.001    60.0    90.0  0.002411  0.001930  0.913936\n",
       "145  146.0   0.010   100.0   100.0  0.002172  0.001974  0.919168\n",
       "79    80.0   0.005    90.0    70.0  0.002018  0.001992  0.952982\n",
       "154  155.0   0.010   120.0    50.0  0.002144  0.002036  0.959919\n",
       "82    83.0   0.005    90.0   100.0  0.002060  0.002025  0.968217\n",
       "103  104.0   0.005   120.0   100.0  0.002074  0.002029  0.974752\n",
       "133  134.0   0.010    90.0    50.0  0.002065  0.002042  0.974951\n",
       "53    54.0   0.001   130.0    90.0  0.002325  0.002088  1.016666\n",
       "144  145.0   0.010   100.0    90.0  0.002185  0.002125  1.020794\n",
       "149  150.0   0.010   110.0    70.0  0.002197  0.002158  1.038641\n",
       "157  158.0   0.010   120.0    80.0  0.002200  0.002184  1.050483\n",
       "163  164.0   0.010   130.0    70.0  0.002259  0.002162  1.054536\n",
       "132  133.0   0.010    80.0   110.0  0.002294  0.002200  1.068798\n",
       "104  105.0   0.005   120.0   110.0  0.002595  0.002325  1.080126\n",
       "46    47.0   0.001   120.0    90.0  0.002488  0.002329  1.107570\n",
       "151  152.0   0.010   110.0    90.0  0.002328  0.002315  1.112673\n",
       "0      1.0   0.001    60.0    50.0  0.002432  0.002349  1.114962\n",
       "65    66.0   0.005    70.0    70.0  0.002636  0.002412  1.125594\n",
       "109  110.0   0.005   130.0    90.0  0.002484  0.002406  1.141363\n",
       "60    61.0   0.005    60.0    90.0  0.002466  0.002429  1.160351\n",
       "81    82.0   0.005    90.0    90.0  0.002482  0.002449  1.174958\n",
       "113  114.0   0.010    60.0    60.0  0.002503  0.002490  1.193413\n",
       "15    16.0   0.001    80.0    60.0  0.002676  0.002501  1.194411\n",
       "98    99.0   0.005   120.0    50.0  0.002820  0.002716  1.278503\n",
       "6      7.0   0.001    60.0   110.0  0.002840  0.002688  1.283337\n",
       "73    74.0   0.005    80.0    80.0  0.002756  0.002716  1.301125\n",
       "143  144.0   0.010   100.0    80.0  0.002785  0.002750  1.311379\n",
       "89    90.0   0.005   100.0   100.0  0.002836  0.002762  1.312869\n",
       "116  117.0   0.010    60.0    90.0  0.003099  0.002855  1.339004\n",
       "31    32.0   0.001   100.0    80.0  0.003210  0.002891  1.367085\n",
       "106  107.0   0.005   130.0    60.0  0.003022  0.002894  1.399883\n",
       "58    59.0   0.005    60.0    70.0  0.003107  0.003001  1.421473\n",
       "121  122.0   0.010    70.0    70.0  0.003046  0.003023  1.443725\n",
       "124  125.0   0.010    70.0   100.0  0.003115  0.003108  1.486920\n",
       "96    97.0   0.005   110.0   100.0  0.003466  0.003449  1.649915\n",
       "148  149.0   0.010   110.0    60.0  0.003615  0.003574  1.723200\n",
       "129  130.0   0.010    80.0    80.0  0.003645  0.003625  1.727239\n",
       "75    76.0   0.005    80.0   100.0  0.003877  0.003681  1.727930\n",
       "44    45.0   0.001   120.0    70.0  0.003883  0.003786  1.816826\n",
       "24    25.0   0.001    90.0    80.0  0.003953  0.003833  1.833380\n",
       "41    42.0   0.001   110.0   110.0  0.003983  0.003917  1.879270\n",
       "110  111.0   0.005   130.0   100.0  0.004253  0.004208  1.998603\n",
       "95    96.0   0.005   110.0    90.0  0.004514  0.004500  2.151254\n",
       "56    57.0   0.005    60.0    50.0  0.004681  0.004624  2.195871\n",
       "111  112.0   0.005   130.0   110.0  0.005102  0.005032  2.387343\n",
       "25    26.0   0.001    90.0    90.0  0.005221  0.005087  2.421476\n",
       "120  121.0   0.010    70.0    60.0  0.005431  0.005269  2.500420\n",
       "108  109.0   0.005   130.0    80.0  0.005801  0.005666  2.685189"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tr_result_rank = Tr_result_temp_pd.loc[np.where(Tr_result_temp_pd['MAPE'] != 100)]\n",
    "Tr_result_rank = Tr_result_rank.sort_values(['MAPE'],ascending = True)\n",
    "Tr_result_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Fold 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27, 3), (27, 1))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData.shape, TrainLabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fold = 5\n",
    "FoldDataNo = int(TrainData.shape[0]/Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2\n",
       "20  1.0  0.0  1.0\n",
       "21  1.0  0.5  0.0\n",
       "22  1.0  0.5  0.5\n",
       "23  1.0  0.5  1.0\n",
       "24  1.0  1.0  0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validation dataset\n",
    "for i in range(Fold):\n",
    "    \n",
    "    temp_Valid_Data   = TrainData.iloc[FoldDataNo*i:FoldDataNo*(i+1) ,:]\n",
    "    s1 = 'ValidData_Fold%d = temp_Valid_Data'%(i+1)\n",
    "    exec(s1)\n",
    "    \n",
    "    temp_Valid_Label  =  TrainLabel.iloc[FoldDataNo*i:FoldDataNo*(i+1) ,:]\n",
    "    s2 = 'ValidLabel_Fold%d = temp_Valid_Label'%(i+1)\n",
    "    exec(s2)\n",
    "\n",
    "ValidData_Fold5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mold Temperature</th>\n",
       "      <th>Melt Temperature</th>\n",
       "      <th>Packing Pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mold Temperature  Melt Temperature  Packing Pressure\n",
       "0                0.0               0.0               0.0\n",
       "1                0.0               0.0               0.5\n",
       "2                0.0               0.0               1.0\n",
       "3                0.0               0.5               0.0\n",
       "4                0.0               0.5               0.5\n",
       "5                0.0               0.5               1.0\n",
       "6                0.0               1.0               0.0\n",
       "7                0.0               1.0               0.5\n",
       "8                0.0               1.0               1.0\n",
       "9                0.5               0.0               0.0\n",
       "10               0.5               0.0               0.5\n",
       "11               0.5               0.0               1.0\n",
       "12               0.5               0.5               0.0\n",
       "13               0.5               0.5               0.5\n",
       "14               0.5               0.5               1.0\n",
       "15               0.5               1.0               0.0\n",
       "16               0.5               1.0               0.5\n",
       "17               0.5               1.0               1.0\n",
       "18               1.0               0.0               0.0\n",
       "19               1.0               0.0               0.5\n",
       "20               1.0               0.0               1.0\n",
       "21               1.0               0.5               0.0\n",
       "22               1.0               0.5               0.5\n",
       "23               1.0               0.5               1.0\n",
       "24               1.0               1.0               0.0\n",
       "25               1.0               1.0               0.5\n",
       "26               1.0               1.0               1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test dataset\n",
    "testData   = TestData\n",
    "testLabel  = TestLabel\n",
    "        \n",
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22, 3), (22, 1))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training Dataset\n",
    "for i in range(Fold):\n",
    "    temp_Train_Data_Front = TrainData.iloc[:FoldDataNo*i,:]\n",
    "    temp_Train_Data_Back  = TrainData.iloc[FoldDataNo*(i+1):,:]\n",
    "    temp_Train_Data_Total = np.concatenate([temp_Train_Data_Front , temp_Train_Data_Back] , axis=0)\n",
    "    s1 ='TrainData_Fold%d  = temp_Train_Data_Total'%(i+1)\n",
    "    exec(s1)\n",
    "\n",
    "    temp_Train_Label_Front = TrainLabel.iloc[:FoldDataNo*i,:]\n",
    "    temp_Train_Label_Back  = TrainLabel.iloc[FoldDataNo*(i+1):,:]\n",
    "    temp_Train_Label_Total = np.concatenate([temp_Train_Label_Front , temp_Train_Label_Back] , axis=0)\n",
    "    s2 ='TrainLabel_Fold%d  = temp_Train_Label_Total'%(i+1)\n",
    "    exec(s2)\n",
    "    \n",
    "TrainData_Fold1.shape , TrainLabel_Fold1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최고성능 모델 재학습 및 모델 & 히스토리 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8036\\154191563.py:14: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  noOfNeuron1    = np.int(Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,2])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8036\\154191563.py:15: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  noOfNeuron2    = np.int(Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:1.78251,   MAE: 1.37887,  MAPE: 99.66%\n",
      "[100 Epochs]    RMSE:0.18433,   MAE: 0.10464,  MAPE: 7.96%\n",
      "[200 Epochs]    RMSE:0.02550,   MAE: 0.02037,  MAPE: 2.40%\n",
      "[300 Epochs]    RMSE:0.00877,   MAE: 0.00619,  MAPE: 0.61%\n",
      "[400 Epochs]    RMSE:0.03588,   MAE: 0.02929,  MAPE: 2.78%\n",
      "[500 Epochs]    RMSE:0.01670,   MAE: 0.01419,  MAPE: 1.30%\n",
      "[600 Epochs]    RMSE:0.01732,   MAE: 0.01549,  MAPE: 1.79%\n",
      "[700 Epochs]    RMSE:0.00652,   MAE: 0.00410,  MAPE: 0.27%\n",
      "[800 Epochs]    RMSE:0.00799,   MAE: 0.00617,  MAPE: 0.48%\n",
      "[900 Epochs]    RMSE:0.01669,   MAE: 0.01531,  MAPE: 1.82%\n",
      "[1000 Epochs]    RMSE:0.02623,   MAE: 0.02217,  MAPE: 2.12%\n",
      "[1100 Epochs]    RMSE:0.00456,   MAE: 0.00332,  MAPE: 0.35%\n",
      "[1200 Epochs]    RMSE:0.00375,   MAE: 0.00295,  MAPE: 0.42%\n",
      "[1300 Epochs]    RMSE:0.00554,   MAE: 0.00433,  MAPE: 0.36%\n",
      "[1400 Epochs]    RMSE:0.00714,   MAE: 0.00514,  MAPE: 0.49%\n",
      "[1500 Epochs]    RMSE:0.02134,   MAE: 0.01791,  MAPE: 1.63%\n",
      "[1600 Epochs]    RMSE:0.00589,   MAE: 0.00402,  MAPE: 0.31%\n",
      "[1700 Epochs]    RMSE:0.00282,   MAE: 0.00258,  MAPE: 0.39%\n",
      "[1800 Epochs]    RMSE:0.00628,   MAE: 0.00453,  MAPE: 0.62%\n",
      "[1900 Epochs]    RMSE:0.01502,   MAE: 0.01052,  MAPE: 0.84%\n",
      "[2000 Epochs]    RMSE:0.00513,   MAE: 0.00401,  MAPE: 0.47%\n",
      "[2100 Epochs]    RMSE:0.00444,   MAE: 0.00358,  MAPE: 0.43%\n",
      "[2200 Epochs]    RMSE:0.01070,   MAE: 0.00817,  MAPE: 0.59%\n",
      "[2300 Epochs]    RMSE:0.00891,   MAE: 0.00734,  MAPE: 0.85%\n",
      "[2400 Epochs]    RMSE:0.01185,   MAE: 0.00900,  MAPE: 0.64%\n",
      "[2500 Epochs]    RMSE:0.00842,   MAE: 0.00548,  MAPE: 0.49%\n",
      "[2600 Epochs]    RMSE:0.02164,   MAE: 0.01776,  MAPE: 1.60%\n",
      "[2700 Epochs]    RMSE:0.00923,   MAE: 0.00664,  MAPE: 0.44%\n",
      "[2800 Epochs]    RMSE:0.00663,   MAE: 0.00582,  MAPE: 0.85%\n",
      "[2900 Epochs]    RMSE:0.00927,   MAE: 0.00834,  MAPE: 0.93%\n",
      "[3000 Epochs]    RMSE:0.00695,   MAE: 0.00512,  MAPE: 0.33%\n",
      "[3100 Epochs]    RMSE:0.00339,   MAE: 0.00277,  MAPE: 0.41%\n",
      "[3200 Epochs]    RMSE:0.01996,   MAE: 0.01608,  MAPE: 1.34%\n",
      "[3300 Epochs]    RMSE:0.02317,   MAE: 0.01796,  MAPE: 1.38%\n",
      "[3400 Epochs]    RMSE:0.00552,   MAE: 0.00461,  MAPE: 0.53%\n",
      "[3500 Epochs]    RMSE:0.00742,   MAE: 0.00558,  MAPE: 0.47%\n",
      "[3600 Epochs]    RMSE:0.01175,   MAE: 0.01049,  MAPE: 1.15%\n",
      "[3700 Epochs]    RMSE:0.00452,   MAE: 0.00390,  MAPE: 0.72%\n",
      "[3800 Epochs]    RMSE:0.01179,   MAE: 0.00764,  MAPE: 0.47%\n",
      "[3900 Epochs]    RMSE:0.00689,   MAE: 0.00530,  MAPE: 0.46%\n",
      "[4000 Epochs]    RMSE:0.01067,   MAE: 0.00824,  MAPE: 0.72%\n",
      "[4100 Epochs]    RMSE:0.01929,   MAE: 0.01540,  MAPE: 1.12%\n",
      "[4200 Epochs]    RMSE:0.00252,   MAE: 0.00178,  MAPE: 0.17%\n",
      "[4300 Epochs]    RMSE:0.00494,   MAE: 0.00311,  MAPE: 0.25%\n",
      "[4400 Epochs]    RMSE:0.00474,   MAE: 0.00428,  MAPE: 0.55%\n",
      "[4500 Epochs]    RMSE:0.01094,   MAE: 0.00917,  MAPE: 1.05%\n",
      "[4600 Epochs]    RMSE:0.01183,   MAE: 0.00934,  MAPE: 0.65%\n",
      "[4700 Epochs]    RMSE:0.01629,   MAE: 0.01260,  MAPE: 0.83%\n",
      "[4800 Epochs]    RMSE:0.00989,   MAE: 0.00803,  MAPE: 0.60%\n",
      "[4900 Epochs]    RMSE:0.01290,   MAE: 0.01023,  MAPE: 0.82%\n",
      "[5000 Epochs]    RMSE:0.00685,   MAE: 0.00590,  MAPE: 0.70%\n",
      "[5100 Epochs]    RMSE:0.00811,   MAE: 0.00611,  MAPE: 0.56%\n",
      "[5200 Epochs]    RMSE:0.00285,   MAE: 0.00240,  MAPE: 0.31%\n",
      "[5300 Epochs]    RMSE:0.00565,   MAE: 0.00402,  MAPE: 0.34%\n",
      "[5400 Epochs]    RMSE:0.00344,   MAE: 0.00302,  MAPE: 0.48%\n",
      "[5500 Epochs]    RMSE:0.01101,   MAE: 0.00878,  MAPE: 0.71%\n",
      "[5600 Epochs]    RMSE:0.00746,   MAE: 0.00578,  MAPE: 0.49%\n",
      "[5700 Epochs]    RMSE:0.00619,   MAE: 0.00472,  MAPE: 0.40%\n",
      "[5800 Epochs]    RMSE:0.01687,   MAE: 0.01334,  MAPE: 0.97%\n",
      "[5900 Epochs]    RMSE:0.00369,   MAE: 0.00291,  MAPE: 0.37%\n",
      "[6000 Epochs]    RMSE:0.00929,   MAE: 0.00632,  MAPE: 0.39%\n",
      "[6100 Epochs]    RMSE:0.00266,   MAE: 0.00213,  MAPE: 0.18%\n",
      "[6200 Epochs]    RMSE:0.01729,   MAE: 0.01480,  MAPE: 1.35%\n",
      "[6300 Epochs]    RMSE:0.00682,   MAE: 0.00497,  MAPE: 0.48%\n",
      "[6400 Epochs]    RMSE:0.00387,   MAE: 0.00317,  MAPE: 0.27%\n",
      "[6500 Epochs]    RMSE:0.00353,   MAE: 0.00248,  MAPE: 0.46%\n",
      "[6600 Epochs]    RMSE:0.00625,   MAE: 0.00553,  MAPE: 0.66%\n",
      "[6700 Epochs]    RMSE:0.00304,   MAE: 0.00232,  MAPE: 0.26%\n",
      "[6800 Epochs]    RMSE:0.01047,   MAE: 0.00812,  MAPE: 0.67%\n",
      "[6900 Epochs]    RMSE:0.00567,   MAE: 0.00469,  MAPE: 0.41%\n",
      "[7000 Epochs]    RMSE:0.01182,   MAE: 0.00926,  MAPE: 0.68%\n",
      "[7100 Epochs]    RMSE:0.01060,   MAE: 0.00724,  MAPE: 0.52%\n",
      "[7200 Epochs]    RMSE:0.00336,   MAE: 0.00253,  MAPE: 0.25%\n",
      "[7300 Epochs]    RMSE:0.00779,   MAE: 0.00547,  MAPE: 0.42%\n",
      "[7400 Epochs]    RMSE:0.01395,   MAE: 0.01135,  MAPE: 0.88%\n",
      "[7500 Epochs]    RMSE:0.00868,   MAE: 0.00632,  MAPE: 0.63%\n",
      "[7600 Epochs]    RMSE:0.00495,   MAE: 0.00380,  MAPE: 0.35%\n",
      "[7700 Epochs]    RMSE:0.00566,   MAE: 0.00465,  MAPE: 0.54%\n",
      "[7800 Epochs]    RMSE:0.01610,   MAE: 0.01235,  MAPE: 0.83%\n",
      "[7900 Epochs]    RMSE:0.00896,   MAE: 0.00664,  MAPE: 0.39%\n",
      "[8000 Epochs]    RMSE:0.01548,   MAE: 0.01272,  MAPE: 1.04%\n",
      "[8100 Epochs]    RMSE:0.00715,   MAE: 0.00580,  MAPE: 0.66%\n",
      "[8200 Epochs]    RMSE:0.00405,   MAE: 0.00335,  MAPE: 0.35%\n",
      "[8300 Epochs]    RMSE:0.00302,   MAE: 0.00208,  MAPE: 0.18%\n",
      "[8400 Epochs]    RMSE:0.01170,   MAE: 0.00965,  MAPE: 0.87%\n",
      "[8500 Epochs]    RMSE:0.00302,   MAE: 0.00204,  MAPE: 0.21%\n",
      "[8600 Epochs]    RMSE:0.00658,   MAE: 0.00443,  MAPE: 0.29%\n",
      "[8700 Epochs]    RMSE:0.01460,   MAE: 0.01129,  MAPE: 0.78%\n",
      "[8800 Epochs]    RMSE:0.00433,   MAE: 0.00366,  MAPE: 0.43%\n",
      "[8900 Epochs]    RMSE:0.00337,   MAE: 0.00269,  MAPE: 0.32%\n",
      "[9000 Epochs]    RMSE:0.01325,   MAE: 0.01074,  MAPE: 0.96%\n",
      "[9100 Epochs]    RMSE:0.01120,   MAE: 0.00865,  MAPE: 0.61%\n",
      "[9200 Epochs]    RMSE:0.00497,   MAE: 0.00411,  MAPE: 0.46%\n",
      "[9300 Epochs]    RMSE:0.00887,   MAE: 0.00599,  MAPE: 0.43%\n",
      "[9400 Epochs]    RMSE:0.00504,   MAE: 0.00443,  MAPE: 0.51%\n",
      "[9500 Epochs]    RMSE:0.00527,   MAE: 0.00436,  MAPE: 0.38%\n",
      "[9600 Epochs]    RMSE:0.01319,   MAE: 0.01009,  MAPE: 0.77%\n",
      "[9700 Epochs]    RMSE:0.00819,   MAE: 0.00657,  MAPE: 0.60%\n",
      "[9800 Epochs]    RMSE:0.00787,   MAE: 0.00604,  MAPE: 0.70%\n",
      "[9900 Epochs]    RMSE:0.00673,   MAE: 0.00538,  MAPE: 0.45%\n",
      "[10000 Epochs]    RMSE:0.01269,   MAE: 0.01008,  MAPE: 0.77%\n",
      "[10100 Epochs]    RMSE:0.01102,   MAE: 0.00905,  MAPE: 0.85%\n",
      "[10200 Epochs]    RMSE:0.00692,   MAE: 0.00521,  MAPE: 0.52%\n",
      "[10300 Epochs]    RMSE:0.02015,   MAE: 0.01602,  MAPE: 1.18%\n",
      "[10400 Epochs]    RMSE:0.01020,   MAE: 0.00837,  MAPE: 0.70%\n",
      "[10500 Epochs]    RMSE:0.00306,   MAE: 0.00228,  MAPE: 0.18%\n",
      "[10600 Epochs]    RMSE:0.01478,   MAE: 0.01142,  MAPE: 0.86%\n",
      "[10700 Epochs]    RMSE:0.00639,   MAE: 0.00427,  MAPE: 0.50%\n",
      "[10800 Epochs]    RMSE:0.01087,   MAE: 0.00799,  MAPE: 0.45%\n",
      "[10900 Epochs]    RMSE:0.00659,   MAE: 0.00500,  MAPE: 0.37%\n",
      "[11000 Epochs]    RMSE:0.00332,   MAE: 0.00237,  MAPE: 0.20%\n",
      "[11100 Epochs]    RMSE:0.00169,   MAE: 0.00122,  MAPE: 0.13%\n",
      "[11200 Epochs]    RMSE:0.00900,   MAE: 0.00676,  MAPE: 0.46%\n",
      "[11300 Epochs]    RMSE:0.00396,   MAE: 0.00306,  MAPE: 0.33%\n",
      "[11400 Epochs]    RMSE:0.00658,   MAE: 0.00481,  MAPE: 0.34%\n",
      "[11500 Epochs]    RMSE:0.01493,   MAE: 0.01251,  MAPE: 1.13%\n",
      "[11600 Epochs]    RMSE:0.00219,   MAE: 0.00150,  MAPE: 0.16%\n",
      "[11700 Epochs]    RMSE:0.00727,   MAE: 0.00594,  MAPE: 0.50%\n",
      "[11800 Epochs]    RMSE:0.00633,   MAE: 0.00455,  MAPE: 0.50%\n",
      "[11900 Epochs]    RMSE:0.00585,   MAE: 0.00480,  MAPE: 0.40%\n",
      "[12000 Epochs]    RMSE:0.00638,   MAE: 0.00539,  MAPE: 0.63%\n",
      "[12100 Epochs]    RMSE:0.00317,   MAE: 0.00277,  MAPE: 0.32%\n",
      "[12200 Epochs]    RMSE:0.01243,   MAE: 0.00961,  MAPE: 0.68%\n",
      "[12300 Epochs]    RMSE:0.00260,   MAE: 0.00224,  MAPE: 0.36%\n",
      "[12400 Epochs]    RMSE:0.00328,   MAE: 0.00235,  MAPE: 0.15%\n",
      "[12500 Epochs]    RMSE:0.00994,   MAE: 0.00910,  MAPE: 1.10%\n",
      "[12600 Epochs]    RMSE:0.01015,   MAE: 0.00835,  MAPE: 0.85%\n",
      "[12700 Epochs]    RMSE:0.00648,   MAE: 0.00385,  MAPE: 0.26%\n",
      "[12800 Epochs]    RMSE:0.00282,   MAE: 0.00222,  MAPE: 0.32%\n",
      "[12900 Epochs]    RMSE:0.00526,   MAE: 0.00362,  MAPE: 0.35%\n",
      "[13000 Epochs]    RMSE:0.00789,   MAE: 0.00594,  MAPE: 0.50%\n",
      "[13100 Epochs]    RMSE:0.00506,   MAE: 0.00382,  MAPE: 0.26%\n",
      "[13200 Epochs]    RMSE:0.00640,   MAE: 0.00486,  MAPE: 0.48%\n",
      "[13300 Epochs]    RMSE:0.00323,   MAE: 0.00263,  MAPE: 0.24%\n",
      "[13400 Epochs]    RMSE:0.00480,   MAE: 0.00338,  MAPE: 0.29%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13500 Epochs]    RMSE:0.00448,   MAE: 0.00326,  MAPE: 0.28%\n",
      "[13600 Epochs]    RMSE:0.00408,   MAE: 0.00338,  MAPE: 0.32%\n",
      "[13700 Epochs]    RMSE:0.00786,   MAE: 0.00649,  MAPE: 0.64%\n",
      "[13800 Epochs]    RMSE:0.00777,   MAE: 0.00577,  MAPE: 0.47%\n",
      "[13900 Epochs]    RMSE:0.00279,   MAE: 0.00197,  MAPE: 0.18%\n",
      "[14000 Epochs]    RMSE:0.00277,   MAE: 0.00208,  MAPE: 0.21%\n",
      "[14100 Epochs]    RMSE:0.00727,   MAE: 0.00583,  MAPE: 0.65%\n",
      "[14200 Epochs]    RMSE:0.00842,   MAE: 0.00637,  MAPE: 0.42%\n",
      "[14300 Epochs]    RMSE:0.00359,   MAE: 0.00286,  MAPE: 0.32%\n",
      "[14400 Epochs]    RMSE:0.00277,   MAE: 0.00191,  MAPE: 0.15%\n",
      "[14500 Epochs]    RMSE:0.00572,   MAE: 0.00383,  MAPE: 0.35%\n",
      "[14600 Epochs]    RMSE:0.00192,   MAE: 0.00146,  MAPE: 0.17%\n",
      "[14700 Epochs]    RMSE:0.00638,   MAE: 0.00493,  MAPE: 0.46%\n",
      "[14800 Epochs]    RMSE:0.00295,   MAE: 0.00223,  MAPE: 0.22%\n",
      "[14900 Epochs]    RMSE:0.01912,   MAE: 0.01501,  MAPE: 1.35%\n",
      "[15000 Epochs]    RMSE:0.00167,   MAE: 0.00133,  MAPE: 0.24%\n",
      "[15100 Epochs]    RMSE:0.00721,   MAE: 0.00555,  MAPE: 0.45%\n",
      "[15200 Epochs]    RMSE:0.01750,   MAE: 0.01431,  MAPE: 1.14%\n",
      "[15300 Epochs]    RMSE:0.00672,   MAE: 0.00531,  MAPE: 0.46%\n",
      "[15400 Epochs]    RMSE:0.00206,   MAE: 0.00123,  MAPE: 0.08%\n",
      "[15500 Epochs]    RMSE:0.00921,   MAE: 0.00638,  MAPE: 0.41%\n",
      "[15600 Epochs]    RMSE:0.00771,   MAE: 0.00575,  MAPE: 0.63%\n",
      "[15700 Epochs]    RMSE:0.00456,   MAE: 0.00353,  MAPE: 0.33%\n",
      "[15800 Epochs]    RMSE:0.00495,   MAE: 0.00374,  MAPE: 0.25%\n",
      "[15900 Epochs]    RMSE:0.00781,   MAE: 0.00639,  MAPE: 0.54%\n",
      "[16000 Epochs]    RMSE:0.00575,   MAE: 0.00387,  MAPE: 0.24%\n",
      "[16100 Epochs]    RMSE:0.00452,   MAE: 0.00350,  MAPE: 0.33%\n",
      "[16200 Epochs]    RMSE:0.01852,   MAE: 0.01505,  MAPE: 1.19%\n",
      "[16300 Epochs]    RMSE:0.01491,   MAE: 0.01262,  MAPE: 1.27%\n",
      "[16400 Epochs]    RMSE:0.00360,   MAE: 0.00274,  MAPE: 0.26%\n",
      "[16500 Epochs]    RMSE:0.00398,   MAE: 0.00267,  MAPE: 0.23%\n",
      "[16600 Epochs]    RMSE:0.00879,   MAE: 0.00670,  MAPE: 0.47%\n",
      "[16700 Epochs]    RMSE:0.01025,   MAE: 0.00721,  MAPE: 0.42%\n",
      "[16800 Epochs]    RMSE:0.00575,   MAE: 0.00411,  MAPE: 0.25%\n",
      "[16900 Epochs]    RMSE:0.00267,   MAE: 0.00198,  MAPE: 0.19%\n",
      "[17000 Epochs]    RMSE:0.00398,   MAE: 0.00304,  MAPE: 0.34%\n",
      "[17100 Epochs]    RMSE:0.00684,   MAE: 0.00502,  MAPE: 0.35%\n",
      "[17200 Epochs]    RMSE:0.00775,   MAE: 0.00601,  MAPE: 0.43%\n",
      "[17300 Epochs]    RMSE:0.00261,   MAE: 0.00190,  MAPE: 0.17%\n",
      "[17400 Epochs]    RMSE:0.00674,   MAE: 0.00435,  MAPE: 0.28%\n",
      "[17500 Epochs]    RMSE:0.00346,   MAE: 0.00228,  MAPE: 0.23%\n",
      "[17600 Epochs]    RMSE:0.00205,   MAE: 0.00141,  MAPE: 0.14%\n",
      "[17700 Epochs]    RMSE:0.00371,   MAE: 0.00239,  MAPE: 0.25%\n",
      "[17800 Epochs]    RMSE:0.00858,   MAE: 0.00642,  MAPE: 0.47%\n",
      "[17900 Epochs]    RMSE:0.00794,   MAE: 0.00631,  MAPE: 0.51%\n",
      "[18000 Epochs]    RMSE:0.00308,   MAE: 0.00232,  MAPE: 0.19%\n",
      "[18100 Epochs]    RMSE:0.00540,   MAE: 0.00419,  MAPE: 0.45%\n",
      "[18200 Epochs]    RMSE:0.00271,   MAE: 0.00174,  MAPE: 0.13%\n",
      "[18300 Epochs]    RMSE:0.00473,   MAE: 0.00395,  MAPE: 0.44%\n",
      "[18400 Epochs]    RMSE:0.00849,   MAE: 0.00600,  MAPE: 0.42%\n",
      "[18500 Epochs]    RMSE:0.01007,   MAE: 0.00757,  MAPE: 0.50%\n",
      "[18600 Epochs]    RMSE:0.00364,   MAE: 0.00287,  MAPE: 0.36%\n",
      "[18700 Epochs]    RMSE:0.00462,   MAE: 0.00304,  MAPE: 0.35%\n",
      "[18800 Epochs]    RMSE:0.00524,   MAE: 0.00413,  MAPE: 0.38%\n",
      "[18900 Epochs]    RMSE:0.00469,   MAE: 0.00365,  MAPE: 0.25%\n",
      "[19000 Epochs]    RMSE:0.00939,   MAE: 0.00652,  MAPE: 0.48%\n",
      "[19100 Epochs]    RMSE:0.00286,   MAE: 0.00243,  MAPE: 0.36%\n",
      "[19200 Epochs]    RMSE:0.00538,   MAE: 0.00383,  MAPE: 0.36%\n",
      "[19300 Epochs]    RMSE:0.00383,   MAE: 0.00293,  MAPE: 0.27%\n",
      "[19400 Epochs]    RMSE:0.00315,   MAE: 0.00210,  MAPE: 0.23%\n",
      "[19500 Epochs]    RMSE:0.00256,   MAE: 0.00221,  MAPE: 0.31%\n",
      "[19600 Epochs]    RMSE:0.00427,   MAE: 0.00314,  MAPE: 0.24%\n",
      "[19700 Epochs]    RMSE:0.00633,   MAE: 0.00508,  MAPE: 0.44%\n",
      "[19800 Epochs]    RMSE:0.00478,   MAE: 0.00313,  MAPE: 0.26%\n",
      "[19900 Epochs]    RMSE:0.00321,   MAE: 0.00214,  MAPE: 0.21%\n",
      "\n",
      "[Final Epochs]    RMSE:0.01362,   MAE: 0.01083,  MAPE: 0.87%\n",
      "\n",
      "\n",
      "\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8036\\154191563.py:14: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  noOfNeuron1    = np.int(Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,2])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8036\\154191563.py:15: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  noOfNeuron2    = np.int(Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 Epochs]    RMSE:2.13051,   MAE: 1.69191,  MAPE: 92.97%\n",
      "[100 Epochs]    RMSE:0.19795,   MAE: 0.11085,  MAPE: 10.20%\n",
      "[200 Epochs]    RMSE:0.10509,   MAE: 0.04672,  MAPE: 2.54%\n",
      "[300 Epochs]    RMSE:0.04311,   MAE: 0.02373,  MAPE: 2.20%\n",
      "[400 Epochs]    RMSE:0.01648,   MAE: 0.01077,  MAPE: 0.97%\n",
      "[500 Epochs]    RMSE:0.01390,   MAE: 0.01066,  MAPE: 1.07%\n",
      "[600 Epochs]    RMSE:0.02164,   MAE: 0.01395,  MAPE: 1.06%\n",
      "[700 Epochs]    RMSE:0.01642,   MAE: 0.01553,  MAPE: 1.77%\n",
      "[800 Epochs]    RMSE:0.01681,   MAE: 0.01553,  MAPE: 2.00%\n",
      "[900 Epochs]    RMSE:0.01283,   MAE: 0.01169,  MAPE: 1.37%\n",
      "[1000 Epochs]    RMSE:0.00656,   MAE: 0.00543,  MAPE: 0.76%\n",
      "[1100 Epochs]    RMSE:0.00963,   MAE: 0.00753,  MAPE: 0.71%\n",
      "[1200 Epochs]    RMSE:0.00613,   MAE: 0.00485,  MAPE: 0.46%\n",
      "[1300 Epochs]    RMSE:0.00545,   MAE: 0.00414,  MAPE: 0.43%\n",
      "[1400 Epochs]    RMSE:0.00719,   MAE: 0.00618,  MAPE: 0.55%\n",
      "[1500 Epochs]    RMSE:0.00695,   MAE: 0.00594,  MAPE: 0.78%\n",
      "[1600 Epochs]    RMSE:0.01322,   MAE: 0.01218,  MAPE: 1.49%\n",
      "[1700 Epochs]    RMSE:0.00530,   MAE: 0.00441,  MAPE: 0.41%\n",
      "[1800 Epochs]    RMSE:0.00627,   MAE: 0.00477,  MAPE: 0.49%\n",
      "[1900 Epochs]    RMSE:0.02524,   MAE: 0.02170,  MAPE: 1.84%\n",
      "[2000 Epochs]    RMSE:0.03408,   MAE: 0.03080,  MAPE: 2.80%\n",
      "[2100 Epochs]    RMSE:0.01201,   MAE: 0.01013,  MAPE: 1.30%\n",
      "[2200 Epochs]    RMSE:0.00607,   MAE: 0.00517,  MAPE: 0.66%\n",
      "[2300 Epochs]    RMSE:0.00569,   MAE: 0.00484,  MAPE: 0.74%\n",
      "[2400 Epochs]    RMSE:0.00727,   MAE: 0.00468,  MAPE: 0.25%\n",
      "[2500 Epochs]    RMSE:0.00986,   MAE: 0.00884,  MAPE: 1.50%\n",
      "[2600 Epochs]    RMSE:0.00926,   MAE: 0.00788,  MAPE: 0.59%\n",
      "[2700 Epochs]    RMSE:0.00534,   MAE: 0.00488,  MAPE: 0.78%\n",
      "[2800 Epochs]    RMSE:0.01882,   MAE: 0.01716,  MAPE: 1.79%\n",
      "[2900 Epochs]    RMSE:0.00465,   MAE: 0.00333,  MAPE: 0.23%\n",
      "[3000 Epochs]    RMSE:0.02696,   MAE: 0.02464,  MAPE: 2.70%\n",
      "[3100 Epochs]    RMSE:0.01047,   MAE: 0.00975,  MAPE: 1.10%\n",
      "[3200 Epochs]    RMSE:0.00747,   MAE: 0.00587,  MAPE: 0.84%\n",
      "[3300 Epochs]    RMSE:0.01159,   MAE: 0.00988,  MAPE: 0.68%\n",
      "[3400 Epochs]    RMSE:0.01804,   MAE: 0.01501,  MAPE: 0.99%\n",
      "[3500 Epochs]    RMSE:0.00942,   MAE: 0.00749,  MAPE: 0.55%\n",
      "[3600 Epochs]    RMSE:0.00588,   MAE: 0.00503,  MAPE: 0.77%\n",
      "[3700 Epochs]    RMSE:0.00596,   MAE: 0.00502,  MAPE: 0.77%\n",
      "[3800 Epochs]    RMSE:0.01680,   MAE: 0.01393,  MAPE: 0.92%\n",
      "[3900 Epochs]    RMSE:0.00936,   MAE: 0.00811,  MAPE: 0.73%\n",
      "[4000 Epochs]    RMSE:0.01568,   MAE: 0.01245,  MAPE: 0.89%\n",
      "[4100 Epochs]    RMSE:0.00740,   MAE: 0.00520,  MAPE: 0.33%\n",
      "[4200 Epochs]    RMSE:0.00980,   MAE: 0.00924,  MAPE: 1.15%\n",
      "[4300 Epochs]    RMSE:0.00482,   MAE: 0.00390,  MAPE: 0.33%\n",
      "[4400 Epochs]    RMSE:0.01048,   MAE: 0.00787,  MAPE: 0.62%\n",
      "[4500 Epochs]    RMSE:0.00757,   MAE: 0.00590,  MAPE: 0.39%\n",
      "[4600 Epochs]    RMSE:0.01023,   MAE: 0.00733,  MAPE: 0.71%\n",
      "[4700 Epochs]    RMSE:0.01073,   MAE: 0.00872,  MAPE: 0.50%\n",
      "[4800 Epochs]    RMSE:0.00534,   MAE: 0.00488,  MAPE: 0.67%\n",
      "[4900 Epochs]    RMSE:0.00589,   MAE: 0.00481,  MAPE: 0.72%\n",
      "[5000 Epochs]    RMSE:0.00700,   MAE: 0.00529,  MAPE: 0.46%\n",
      "[5100 Epochs]    RMSE:0.01020,   MAE: 0.00867,  MAPE: 0.80%\n",
      "[5200 Epochs]    RMSE:0.00858,   MAE: 0.00826,  MAPE: 1.05%\n",
      "[5300 Epochs]    RMSE:0.00592,   MAE: 0.00524,  MAPE: 0.88%\n",
      "[5400 Epochs]    RMSE:0.01260,   MAE: 0.01168,  MAPE: 1.61%\n",
      "[5500 Epochs]    RMSE:0.00264,   MAE: 0.00211,  MAPE: 0.33%\n",
      "[5600 Epochs]    RMSE:0.01517,   MAE: 0.01369,  MAPE: 1.60%\n",
      "[5700 Epochs]    RMSE:0.01276,   MAE: 0.00993,  MAPE: 0.62%\n",
      "[5800 Epochs]    RMSE:0.01368,   MAE: 0.01158,  MAPE: 0.92%\n",
      "[5900 Epochs]    RMSE:0.01184,   MAE: 0.00873,  MAPE: 0.81%\n",
      "[6000 Epochs]    RMSE:0.00897,   MAE: 0.00822,  MAPE: 1.07%\n",
      "[6100 Epochs]    RMSE:0.00589,   MAE: 0.00447,  MAPE: 0.54%\n",
      "[6200 Epochs]    RMSE:0.00704,   MAE: 0.00600,  MAPE: 0.73%\n",
      "[6300 Epochs]    RMSE:0.00508,   MAE: 0.00385,  MAPE: 0.27%\n",
      "[6400 Epochs]    RMSE:0.00382,   MAE: 0.00333,  MAPE: 0.29%\n",
      "[6500 Epochs]    RMSE:0.01114,   MAE: 0.00911,  MAPE: 0.54%\n",
      "[6600 Epochs]    RMSE:0.01353,   MAE: 0.01208,  MAPE: 1.02%\n",
      "[6700 Epochs]    RMSE:0.00698,   MAE: 0.00572,  MAPE: 0.62%\n",
      "[6800 Epochs]    RMSE:0.00284,   MAE: 0.00239,  MAPE: 0.37%\n",
      "[6900 Epochs]    RMSE:0.01366,   MAE: 0.01016,  MAPE: 0.58%\n",
      "[7000 Epochs]    RMSE:0.00587,   MAE: 0.00497,  MAPE: 0.44%\n",
      "[7100 Epochs]    RMSE:0.01230,   MAE: 0.01088,  MAPE: 0.94%\n",
      "[7200 Epochs]    RMSE:0.00688,   MAE: 0.00559,  MAPE: 0.47%\n",
      "[7300 Epochs]    RMSE:0.01975,   MAE: 0.01564,  MAPE: 1.04%\n",
      "[7400 Epochs]    RMSE:0.01040,   MAE: 0.00824,  MAPE: 0.53%\n",
      "[7500 Epochs]    RMSE:0.00458,   MAE: 0.00355,  MAPE: 0.31%\n",
      "[7600 Epochs]    RMSE:0.01019,   MAE: 0.00751,  MAPE: 0.53%\n",
      "[7700 Epochs]    RMSE:0.00613,   MAE: 0.00502,  MAPE: 0.54%\n",
      "[7800 Epochs]    RMSE:0.00408,   MAE: 0.00343,  MAPE: 0.37%\n",
      "[7900 Epochs]    RMSE:0.00704,   MAE: 0.00617,  MAPE: 0.62%\n",
      "[8000 Epochs]    RMSE:0.00275,   MAE: 0.00216,  MAPE: 0.21%\n",
      "[8100 Epochs]    RMSE:0.00880,   MAE: 0.00789,  MAPE: 0.86%\n",
      "[8200 Epochs]    RMSE:0.01827,   MAE: 0.01512,  MAPE: 0.93%\n",
      "[8300 Epochs]    RMSE:0.01134,   MAE: 0.01029,  MAPE: 0.86%\n",
      "[8400 Epochs]    RMSE:0.00716,   MAE: 0.00598,  MAPE: 0.49%\n",
      "[8500 Epochs]    RMSE:0.00543,   MAE: 0.00501,  MAPE: 0.48%\n",
      "[8600 Epochs]    RMSE:0.00416,   MAE: 0.00330,  MAPE: 0.38%\n",
      "[8700 Epochs]    RMSE:0.00576,   MAE: 0.00445,  MAPE: 0.32%\n",
      "[8800 Epochs]    RMSE:0.00723,   MAE: 0.00571,  MAPE: 0.43%\n",
      "[8900 Epochs]    RMSE:0.00544,   MAE: 0.00385,  MAPE: 0.31%\n",
      "[9000 Epochs]    RMSE:0.00440,   MAE: 0.00341,  MAPE: 0.28%\n",
      "[9100 Epochs]    RMSE:0.00608,   MAE: 0.00524,  MAPE: 0.48%\n",
      "[9200 Epochs]    RMSE:0.00845,   MAE: 0.00724,  MAPE: 0.89%\n",
      "[9300 Epochs]    RMSE:0.01185,   MAE: 0.00946,  MAPE: 0.64%\n",
      "[9400 Epochs]    RMSE:0.01100,   MAE: 0.00927,  MAPE: 0.77%\n",
      "[9500 Epochs]    RMSE:0.01557,   MAE: 0.01393,  MAPE: 1.41%\n",
      "[9600 Epochs]    RMSE:0.00202,   MAE: 0.00173,  MAPE: 0.24%\n",
      "[9700 Epochs]    RMSE:0.00539,   MAE: 0.00428,  MAPE: 0.29%\n",
      "[9800 Epochs]    RMSE:0.00677,   MAE: 0.00441,  MAPE: 0.29%\n",
      "[9900 Epochs]    RMSE:0.01116,   MAE: 0.00919,  MAPE: 0.64%\n",
      "[10000 Epochs]    RMSE:0.00585,   MAE: 0.00472,  MAPE: 0.29%\n",
      "[10100 Epochs]    RMSE:0.00428,   MAE: 0.00344,  MAPE: 0.44%\n",
      "[10200 Epochs]    RMSE:0.01809,   MAE: 0.01510,  MAPE: 1.04%\n",
      "[10300 Epochs]    RMSE:0.00272,   MAE: 0.00197,  MAPE: 0.18%\n",
      "[10400 Epochs]    RMSE:0.01309,   MAE: 0.01136,  MAPE: 0.87%\n",
      "[10500 Epochs]    RMSE:0.01027,   MAE: 0.00822,  MAPE: 0.59%\n",
      "[10600 Epochs]    RMSE:0.00415,   MAE: 0.00329,  MAPE: 0.30%\n",
      "[10700 Epochs]    RMSE:0.01019,   MAE: 0.00873,  MAPE: 0.59%\n",
      "[10800 Epochs]    RMSE:0.00462,   MAE: 0.00395,  MAPE: 0.32%\n",
      "[10900 Epochs]    RMSE:0.00434,   MAE: 0.00370,  MAPE: 0.39%\n",
      "[11000 Epochs]    RMSE:0.00530,   MAE: 0.00442,  MAPE: 0.29%\n",
      "[11100 Epochs]    RMSE:0.00866,   MAE: 0.00727,  MAPE: 0.48%\n",
      "[11200 Epochs]    RMSE:0.00533,   MAE: 0.00461,  MAPE: 0.40%\n",
      "[11300 Epochs]    RMSE:0.00237,   MAE: 0.00205,  MAPE: 0.19%\n",
      "[11400 Epochs]    RMSE:0.00319,   MAE: 0.00236,  MAPE: 0.17%\n",
      "[11500 Epochs]    RMSE:0.00259,   MAE: 0.00202,  MAPE: 0.17%\n",
      "[11600 Epochs]    RMSE:0.01511,   MAE: 0.01336,  MAPE: 1.21%\n",
      "[11700 Epochs]    RMSE:0.00779,   MAE: 0.00693,  MAPE: 0.68%\n",
      "[11800 Epochs]    RMSE:0.00758,   MAE: 0.00635,  MAPE: 0.52%\n",
      "[11900 Epochs]    RMSE:0.00735,   MAE: 0.00505,  MAPE: 0.34%\n",
      "[12000 Epochs]    RMSE:0.00562,   MAE: 0.00428,  MAPE: 0.27%\n",
      "[12100 Epochs]    RMSE:0.00751,   MAE: 0.00600,  MAPE: 0.44%\n",
      "[12200 Epochs]    RMSE:0.01314,   MAE: 0.01087,  MAPE: 0.74%\n",
      "[12300 Epochs]    RMSE:0.00246,   MAE: 0.00178,  MAPE: 0.13%\n",
      "[12400 Epochs]    RMSE:0.00277,   MAE: 0.00215,  MAPE: 0.26%\n",
      "[12500 Epochs]    RMSE:0.00544,   MAE: 0.00459,  MAPE: 0.37%\n",
      "[12600 Epochs]    RMSE:0.00236,   MAE: 0.00191,  MAPE: 0.23%\n",
      "[12700 Epochs]    RMSE:0.01023,   MAE: 0.00841,  MAPE: 0.72%\n",
      "[12800 Epochs]    RMSE:0.00807,   MAE: 0.00650,  MAPE: 0.46%\n",
      "[12900 Epochs]    RMSE:0.00562,   MAE: 0.00476,  MAPE: 0.33%\n",
      "[13000 Epochs]    RMSE:0.00842,   MAE: 0.00617,  MAPE: 0.37%\n",
      "[13100 Epochs]    RMSE:0.00641,   MAE: 0.00466,  MAPE: 0.46%\n",
      "[13200 Epochs]    RMSE:0.00289,   MAE: 0.00228,  MAPE: 0.21%\n",
      "[13300 Epochs]    RMSE:0.00342,   MAE: 0.00263,  MAPE: 0.21%\n",
      "[13400 Epochs]    RMSE:0.00495,   MAE: 0.00397,  MAPE: 0.28%\n",
      "[13500 Epochs]    RMSE:0.00428,   MAE: 0.00372,  MAPE: 0.42%\n",
      "[13600 Epochs]    RMSE:0.00630,   MAE: 0.00503,  MAPE: 0.32%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13700 Epochs]    RMSE:0.00555,   MAE: 0.00483,  MAPE: 0.50%\n",
      "[13800 Epochs]    RMSE:0.01069,   MAE: 0.00861,  MAPE: 0.49%\n",
      "[13900 Epochs]    RMSE:0.00765,   MAE: 0.00650,  MAPE: 0.57%\n",
      "[14000 Epochs]    RMSE:0.01555,   MAE: 0.01292,  MAPE: 0.96%\n",
      "[14100 Epochs]    RMSE:0.00970,   MAE: 0.00832,  MAPE: 0.72%\n",
      "[14200 Epochs]    RMSE:0.00554,   MAE: 0.00463,  MAPE: 0.39%\n",
      "[14300 Epochs]    RMSE:0.01502,   MAE: 0.01201,  MAPE: 0.75%\n",
      "[14400 Epochs]    RMSE:0.01252,   MAE: 0.00975,  MAPE: 0.55%\n",
      "[14500 Epochs]    RMSE:0.00493,   MAE: 0.00375,  MAPE: 0.34%\n",
      "[14600 Epochs]    RMSE:0.00598,   MAE: 0.00464,  MAPE: 0.34%\n",
      "[14700 Epochs]    RMSE:0.00265,   MAE: 0.00221,  MAPE: 0.22%\n",
      "[14800 Epochs]    RMSE:0.00919,   MAE: 0.00816,  MAPE: 0.63%\n",
      "[14900 Epochs]    RMSE:0.01311,   MAE: 0.01090,  MAPE: 0.71%\n",
      "[15000 Epochs]    RMSE:0.00439,   MAE: 0.00337,  MAPE: 0.22%\n",
      "[15100 Epochs]    RMSE:0.00441,   MAE: 0.00275,  MAPE: 0.17%\n",
      "[15200 Epochs]    RMSE:0.00271,   MAE: 0.00201,  MAPE: 0.21%\n",
      "[15300 Epochs]    RMSE:0.00481,   MAE: 0.00395,  MAPE: 0.35%\n",
      "[15400 Epochs]    RMSE:0.00471,   MAE: 0.00375,  MAPE: 0.30%\n",
      "[15500 Epochs]    RMSE:0.00597,   MAE: 0.00490,  MAPE: 0.49%\n",
      "[15600 Epochs]    RMSE:0.00200,   MAE: 0.00166,  MAPE: 0.16%\n",
      "[15700 Epochs]    RMSE:0.00242,   MAE: 0.00210,  MAPE: 0.26%\n",
      "[15800 Epochs]    RMSE:0.01418,   MAE: 0.01216,  MAPE: 0.80%\n",
      "[15900 Epochs]    RMSE:0.00935,   MAE: 0.00752,  MAPE: 0.57%\n",
      "[16000 Epochs]    RMSE:0.01048,   MAE: 0.00894,  MAPE: 0.61%\n",
      "[16100 Epochs]    RMSE:0.00656,   MAE: 0.00507,  MAPE: 0.38%\n",
      "[16200 Epochs]    RMSE:0.00577,   MAE: 0.00407,  MAPE: 0.20%\n",
      "[16300 Epochs]    RMSE:0.00560,   MAE: 0.00462,  MAPE: 0.29%\n",
      "[16400 Epochs]    RMSE:0.00825,   MAE: 0.00712,  MAPE: 0.46%\n",
      "[16500 Epochs]    RMSE:0.00964,   MAE: 0.00740,  MAPE: 0.51%\n",
      "[16600 Epochs]    RMSE:0.01084,   MAE: 0.00924,  MAPE: 0.66%\n",
      "[16700 Epochs]    RMSE:0.01358,   MAE: 0.01197,  MAPE: 0.93%\n",
      "[16800 Epochs]    RMSE:0.00913,   MAE: 0.00768,  MAPE: 0.61%\n",
      "[16900 Epochs]    RMSE:0.01361,   MAE: 0.01205,  MAPE: 0.85%\n",
      "[17000 Epochs]    RMSE:0.00851,   MAE: 0.00715,  MAPE: 0.45%\n",
      "[17100 Epochs]    RMSE:0.00619,   MAE: 0.00477,  MAPE: 0.30%\n",
      "[17200 Epochs]    RMSE:0.00676,   MAE: 0.00552,  MAPE: 0.42%\n",
      "[17300 Epochs]    RMSE:0.00326,   MAE: 0.00279,  MAPE: 0.27%\n",
      "[17400 Epochs]    RMSE:0.00833,   MAE: 0.00655,  MAPE: 0.49%\n",
      "[17500 Epochs]    RMSE:0.00378,   MAE: 0.00310,  MAPE: 0.33%\n",
      "[17600 Epochs]    RMSE:0.00807,   MAE: 0.00686,  MAPE: 0.55%\n",
      "[17700 Epochs]    RMSE:0.00351,   MAE: 0.00268,  MAPE: 0.19%\n",
      "[17800 Epochs]    RMSE:0.00963,   MAE: 0.00824,  MAPE: 0.59%\n",
      "[17900 Epochs]    RMSE:0.00513,   MAE: 0.00439,  MAPE: 0.34%\n",
      "[18000 Epochs]    RMSE:0.00693,   MAE: 0.00470,  MAPE: 0.28%\n",
      "[18100 Epochs]    RMSE:0.00232,   MAE: 0.00173,  MAPE: 0.14%\n",
      "[18200 Epochs]    RMSE:0.00461,   MAE: 0.00390,  MAPE: 0.41%\n",
      "[18300 Epochs]    RMSE:0.00485,   MAE: 0.00404,  MAPE: 0.35%\n",
      "[18400 Epochs]    RMSE:0.00368,   MAE: 0.00283,  MAPE: 0.24%\n",
      "[18500 Epochs]    RMSE:0.00319,   MAE: 0.00235,  MAPE: 0.16%\n",
      "[18600 Epochs]    RMSE:0.00469,   MAE: 0.00400,  MAPE: 0.30%\n",
      "[18700 Epochs]    RMSE:0.00628,   MAE: 0.00513,  MAPE: 0.33%\n",
      "[18800 Epochs]    RMSE:0.00547,   MAE: 0.00412,  MAPE: 0.36%\n",
      "[18900 Epochs]    RMSE:0.00915,   MAE: 0.00654,  MAPE: 0.32%\n",
      "[19000 Epochs]    RMSE:0.00269,   MAE: 0.00210,  MAPE: 0.23%\n",
      "[19100 Epochs]    RMSE:0.00275,   MAE: 0.00202,  MAPE: 0.14%\n",
      "[19200 Epochs]    RMSE:0.00481,   MAE: 0.00407,  MAPE: 0.34%\n",
      "[19300 Epochs]    RMSE:0.00589,   MAE: 0.00435,  MAPE: 0.27%\n",
      "[19400 Epochs]    RMSE:0.00885,   MAE: 0.00789,  MAPE: 0.69%\n",
      "[19500 Epochs]    RMSE:0.00324,   MAE: 0.00252,  MAPE: 0.18%\n",
      "[19600 Epochs]    RMSE:0.01005,   MAE: 0.00845,  MAPE: 0.61%\n",
      "[19700 Epochs]    RMSE:0.00227,   MAE: 0.00188,  MAPE: 0.20%\n",
      "[19800 Epochs]    RMSE:0.00343,   MAE: 0.00293,  MAPE: 0.25%\n",
      "[19900 Epochs]    RMSE:0.00533,   MAE: 0.00428,  MAPE: 0.31%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00397,   MAE: 0.00352,  MAPE: 0.32%\n",
      "\n",
      "\n",
      "\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8036\\154191563.py:14: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  noOfNeuron1    = np.int(Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,2])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8036\\154191563.py:15: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  noOfNeuron2    = np.int(Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 Epochs]    RMSE:1.95156,   MAE: 1.59867,  MAPE: 139.72%\n",
      "[100 Epochs]    RMSE:0.11649,   MAE: 0.08817,  MAPE: 12.28%\n",
      "[200 Epochs]    RMSE:0.05090,   MAE: 0.03942,  MAPE: 5.21%\n",
      "[300 Epochs]    RMSE:0.01757,   MAE: 0.01324,  MAPE: 1.46%\n",
      "[400 Epochs]    RMSE:0.01203,   MAE: 0.01064,  MAPE: 1.97%\n",
      "[500 Epochs]    RMSE:0.02352,   MAE: 0.02026,  MAPE: 2.30%\n",
      "[600 Epochs]    RMSE:0.00743,   MAE: 0.00630,  MAPE: 0.99%\n",
      "[700 Epochs]    RMSE:0.00875,   MAE: 0.00620,  MAPE: 0.63%\n",
      "[800 Epochs]    RMSE:0.00763,   MAE: 0.00635,  MAPE: 0.89%\n",
      "[900 Epochs]    RMSE:0.01829,   MAE: 0.01634,  MAPE: 1.83%\n",
      "[1000 Epochs]    RMSE:0.00869,   MAE: 0.00690,  MAPE: 0.60%\n",
      "[1100 Epochs]    RMSE:0.00488,   MAE: 0.00395,  MAPE: 0.71%\n",
      "[1200 Epochs]    RMSE:0.01203,   MAE: 0.00945,  MAPE: 0.78%\n",
      "[1300 Epochs]    RMSE:0.00617,   MAE: 0.00510,  MAPE: 1.06%\n",
      "[1400 Epochs]    RMSE:0.03649,   MAE: 0.03401,  MAPE: 4.25%\n",
      "[1500 Epochs]    RMSE:0.01080,   MAE: 0.00964,  MAPE: 1.52%\n",
      "[1600 Epochs]    RMSE:0.00392,   MAE: 0.00300,  MAPE: 0.27%\n",
      "[1700 Epochs]    RMSE:0.00269,   MAE: 0.00219,  MAPE: 0.34%\n",
      "[1800 Epochs]    RMSE:0.01312,   MAE: 0.00990,  MAPE: 0.93%\n",
      "[1900 Epochs]    RMSE:0.00607,   MAE: 0.00497,  MAPE: 0.53%\n",
      "[2000 Epochs]    RMSE:0.00762,   MAE: 0.00697,  MAPE: 1.17%\n",
      "[2100 Epochs]    RMSE:0.01378,   MAE: 0.01077,  MAPE: 0.83%\n",
      "[2200 Epochs]    RMSE:0.00718,   MAE: 0.00478,  MAPE: 0.42%\n",
      "[2300 Epochs]    RMSE:0.00889,   MAE: 0.00705,  MAPE: 1.00%\n",
      "[2400 Epochs]    RMSE:0.00847,   MAE: 0.00714,  MAPE: 1.49%\n",
      "[2500 Epochs]    RMSE:0.00753,   MAE: 0.00678,  MAPE: 1.22%\n",
      "[2600 Epochs]    RMSE:0.00887,   MAE: 0.00834,  MAPE: 1.20%\n",
      "[2700 Epochs]    RMSE:0.02594,   MAE: 0.02382,  MAPE: 2.97%\n",
      "[2800 Epochs]    RMSE:0.00343,   MAE: 0.00280,  MAPE: 0.50%\n",
      "[2900 Epochs]    RMSE:0.00901,   MAE: 0.00699,  MAPE: 0.51%\n",
      "[3000 Epochs]    RMSE:0.02127,   MAE: 0.01935,  MAPE: 2.56%\n",
      "[3100 Epochs]    RMSE:0.00830,   MAE: 0.00717,  MAPE: 1.12%\n",
      "[3200 Epochs]    RMSE:0.00875,   MAE: 0.00687,  MAPE: 0.47%\n",
      "[3300 Epochs]    RMSE:0.00759,   MAE: 0.00654,  MAPE: 1.34%\n",
      "[3400 Epochs]    RMSE:0.01871,   MAE: 0.01673,  MAPE: 1.75%\n",
      "[3500 Epochs]    RMSE:0.01232,   MAE: 0.01102,  MAPE: 1.50%\n",
      "[3600 Epochs]    RMSE:0.01101,   MAE: 0.00917,  MAPE: 1.31%\n",
      "[3700 Epochs]    RMSE:0.00404,   MAE: 0.00317,  MAPE: 0.31%\n",
      "[3800 Epochs]    RMSE:0.01037,   MAE: 0.00813,  MAPE: 0.70%\n",
      "[3900 Epochs]    RMSE:0.01218,   MAE: 0.01137,  MAPE: 1.67%\n",
      "[4000 Epochs]    RMSE:0.00367,   MAE: 0.00281,  MAPE: 0.31%\n",
      "[4100 Epochs]    RMSE:0.00582,   MAE: 0.00515,  MAPE: 1.08%\n",
      "[4200 Epochs]    RMSE:0.01693,   MAE: 0.01483,  MAPE: 1.75%\n",
      "[4300 Epochs]    RMSE:0.00388,   MAE: 0.00345,  MAPE: 0.63%\n",
      "[4400 Epochs]    RMSE:0.00595,   MAE: 0.00474,  MAPE: 0.55%\n",
      "[4500 Epochs]    RMSE:0.00586,   MAE: 0.00505,  MAPE: 0.79%\n",
      "[4600 Epochs]    RMSE:0.00461,   MAE: 0.00356,  MAPE: 0.37%\n",
      "[4700 Epochs]    RMSE:0.01010,   MAE: 0.00733,  MAPE: 0.55%\n",
      "[4800 Epochs]    RMSE:0.01192,   MAE: 0.01066,  MAPE: 1.23%\n",
      "[4900 Epochs]    RMSE:0.00340,   MAE: 0.00292,  MAPE: 0.44%\n",
      "[5000 Epochs]    RMSE:0.00871,   MAE: 0.00619,  MAPE: 0.53%\n",
      "[5100 Epochs]    RMSE:0.00756,   MAE: 0.00679,  MAPE: 0.82%\n",
      "[5200 Epochs]    RMSE:0.00932,   MAE: 0.00798,  MAPE: 0.86%\n",
      "[5300 Epochs]    RMSE:0.00557,   MAE: 0.00369,  MAPE: 0.25%\n",
      "[5400 Epochs]    RMSE:0.00209,   MAE: 0.00187,  MAPE: 0.34%\n",
      "[5500 Epochs]    RMSE:0.01053,   MAE: 0.00788,  MAPE: 0.67%\n",
      "[5600 Epochs]    RMSE:0.00590,   MAE: 0.00404,  MAPE: 0.29%\n",
      "[5700 Epochs]    RMSE:0.01083,   MAE: 0.00949,  MAPE: 1.14%\n",
      "[5800 Epochs]    RMSE:0.00646,   MAE: 0.00471,  MAPE: 0.47%\n",
      "[5900 Epochs]    RMSE:0.01340,   MAE: 0.01115,  MAPE: 1.06%\n",
      "[6000 Epochs]    RMSE:0.00278,   MAE: 0.00224,  MAPE: 0.28%\n",
      "[6100 Epochs]    RMSE:0.00887,   MAE: 0.00764,  MAPE: 0.79%\n",
      "[6200 Epochs]    RMSE:0.01746,   MAE: 0.01557,  MAPE: 1.95%\n",
      "[6300 Epochs]    RMSE:0.00749,   MAE: 0.00495,  MAPE: 0.76%\n",
      "[6400 Epochs]    RMSE:0.01033,   MAE: 0.00877,  MAPE: 0.96%\n",
      "[6500 Epochs]    RMSE:0.00502,   MAE: 0.00368,  MAPE: 0.49%\n",
      "[6600 Epochs]    RMSE:0.00958,   MAE: 0.00783,  MAPE: 0.66%\n",
      "[6700 Epochs]    RMSE:0.00286,   MAE: 0.00217,  MAPE: 0.22%\n",
      "[6800 Epochs]    RMSE:0.00319,   MAE: 0.00262,  MAPE: 0.45%\n",
      "[6900 Epochs]    RMSE:0.00333,   MAE: 0.00265,  MAPE: 0.51%\n",
      "[7000 Epochs]    RMSE:0.00284,   MAE: 0.00237,  MAPE: 0.34%\n",
      "[7100 Epochs]    RMSE:0.01162,   MAE: 0.00985,  MAPE: 0.93%\n",
      "[7200 Epochs]    RMSE:0.00392,   MAE: 0.00340,  MAPE: 0.54%\n",
      "[7300 Epochs]    RMSE:0.00213,   MAE: 0.00176,  MAPE: 0.28%\n",
      "[7400 Epochs]    RMSE:0.00430,   MAE: 0.00315,  MAPE: 0.30%\n",
      "[7500 Epochs]    RMSE:0.01043,   MAE: 0.00869,  MAPE: 0.81%\n",
      "[7600 Epochs]    RMSE:0.00826,   MAE: 0.00721,  MAPE: 0.72%\n",
      "[7700 Epochs]    RMSE:0.00675,   MAE: 0.00510,  MAPE: 0.41%\n",
      "[7800 Epochs]    RMSE:0.00461,   MAE: 0.00379,  MAPE: 0.43%\n",
      "[7900 Epochs]    RMSE:0.00538,   MAE: 0.00434,  MAPE: 0.46%\n",
      "[8000 Epochs]    RMSE:0.00294,   MAE: 0.00242,  MAPE: 0.30%\n",
      "[8100 Epochs]    RMSE:0.01484,   MAE: 0.01364,  MAPE: 1.60%\n",
      "[8200 Epochs]    RMSE:0.00473,   MAE: 0.00361,  MAPE: 0.43%\n",
      "[8300 Epochs]    RMSE:0.00939,   MAE: 0.00796,  MAPE: 0.97%\n",
      "[8400 Epochs]    RMSE:0.00795,   MAE: 0.00700,  MAPE: 0.78%\n",
      "[8500 Epochs]    RMSE:0.00815,   MAE: 0.00709,  MAPE: 0.94%\n",
      "[8600 Epochs]    RMSE:0.01124,   MAE: 0.00957,  MAPE: 0.90%\n",
      "[8700 Epochs]    RMSE:0.00261,   MAE: 0.00176,  MAPE: 0.18%\n",
      "[8800 Epochs]    RMSE:0.00738,   MAE: 0.00559,  MAPE: 0.52%\n",
      "[8900 Epochs]    RMSE:0.00873,   MAE: 0.00667,  MAPE: 0.67%\n",
      "[9000 Epochs]    RMSE:0.00478,   MAE: 0.00378,  MAPE: 0.56%\n",
      "[9100 Epochs]    RMSE:0.00467,   MAE: 0.00382,  MAPE: 0.42%\n",
      "[9200 Epochs]    RMSE:0.00192,   MAE: 0.00148,  MAPE: 0.15%\n",
      "[9300 Epochs]    RMSE:0.00538,   MAE: 0.00320,  MAPE: 0.41%\n",
      "[9400 Epochs]    RMSE:0.00485,   MAE: 0.00390,  MAPE: 0.44%\n",
      "[9500 Epochs]    RMSE:0.00343,   MAE: 0.00273,  MAPE: 0.35%\n",
      "[9600 Epochs]    RMSE:0.00775,   MAE: 0.00615,  MAPE: 0.76%\n",
      "[9700 Epochs]    RMSE:0.00967,   MAE: 0.00679,  MAPE: 0.47%\n",
      "[9800 Epochs]    RMSE:0.00542,   MAE: 0.00410,  MAPE: 0.34%\n",
      "[9900 Epochs]    RMSE:0.00500,   MAE: 0.00403,  MAPE: 0.43%\n",
      "[10000 Epochs]    RMSE:0.00780,   MAE: 0.00501,  MAPE: 0.33%\n",
      "[10100 Epochs]    RMSE:0.00457,   MAE: 0.00336,  MAPE: 0.38%\n",
      "[10200 Epochs]    RMSE:0.01526,   MAE: 0.01218,  MAPE: 0.95%\n",
      "[10300 Epochs]    RMSE:0.00320,   MAE: 0.00195,  MAPE: 0.16%\n",
      "[10400 Epochs]    RMSE:0.00369,   MAE: 0.00302,  MAPE: 0.45%\n",
      "[10500 Epochs]    RMSE:0.01011,   MAE: 0.00832,  MAPE: 0.99%\n",
      "[10600 Epochs]    RMSE:0.00546,   MAE: 0.00362,  MAPE: 0.35%\n",
      "[10700 Epochs]    RMSE:0.00555,   MAE: 0.00375,  MAPE: 0.39%\n",
      "[10800 Epochs]    RMSE:0.03051,   MAE: 0.02475,  MAPE: 2.04%\n",
      "[10900 Epochs]    RMSE:0.01754,   MAE: 0.01407,  MAPE: 1.10%\n",
      "[11000 Epochs]    RMSE:0.00596,   MAE: 0.00483,  MAPE: 0.40%\n",
      "[11100 Epochs]    RMSE:0.00613,   MAE: 0.00551,  MAPE: 0.88%\n",
      "[11200 Epochs]    RMSE:0.00358,   MAE: 0.00305,  MAPE: 0.29%\n",
      "[11300 Epochs]    RMSE:0.00742,   MAE: 0.00612,  MAPE: 0.85%\n",
      "[11400 Epochs]    RMSE:0.00427,   MAE: 0.00315,  MAPE: 0.26%\n",
      "[11500 Epochs]    RMSE:0.00218,   MAE: 0.00145,  MAPE: 0.20%\n",
      "[11600 Epochs]    RMSE:0.00461,   MAE: 0.00337,  MAPE: 0.29%\n",
      "[11700 Epochs]    RMSE:0.01282,   MAE: 0.01070,  MAPE: 1.07%\n",
      "[11800 Epochs]    RMSE:0.00238,   MAE: 0.00178,  MAPE: 0.24%\n",
      "[11900 Epochs]    RMSE:0.02200,   MAE: 0.01788,  MAPE: 1.29%\n",
      "[12000 Epochs]    RMSE:0.01138,   MAE: 0.00931,  MAPE: 0.78%\n",
      "[12100 Epochs]    RMSE:0.00350,   MAE: 0.00277,  MAPE: 0.31%\n",
      "[12200 Epochs]    RMSE:0.00603,   MAE: 0.00401,  MAPE: 0.28%\n",
      "[12300 Epochs]    RMSE:0.00602,   MAE: 0.00435,  MAPE: 0.33%\n",
      "[12400 Epochs]    RMSE:0.00722,   MAE: 0.00591,  MAPE: 0.52%\n",
      "[12500 Epochs]    RMSE:0.00421,   MAE: 0.00296,  MAPE: 0.23%\n",
      "[12600 Epochs]    RMSE:0.00248,   MAE: 0.00156,  MAPE: 0.16%\n",
      "[12700 Epochs]    RMSE:0.01007,   MAE: 0.00846,  MAPE: 0.83%\n",
      "[12800 Epochs]    RMSE:0.00367,   MAE: 0.00317,  MAPE: 0.40%\n",
      "[12900 Epochs]    RMSE:0.00711,   MAE: 0.00509,  MAPE: 0.40%\n",
      "[13000 Epochs]    RMSE:0.00861,   MAE: 0.00718,  MAPE: 0.65%\n",
      "[13100 Epochs]    RMSE:0.00221,   MAE: 0.00167,  MAPE: 0.18%\n",
      "[13200 Epochs]    RMSE:0.00704,   MAE: 0.00552,  MAPE: 0.73%\n",
      "[13300 Epochs]    RMSE:0.00592,   MAE: 0.00409,  MAPE: 0.29%\n",
      "[13400 Epochs]    RMSE:0.00487,   MAE: 0.00317,  MAPE: 0.22%\n",
      "[13500 Epochs]    RMSE:0.00792,   MAE: 0.00592,  MAPE: 0.38%\n",
      "[13600 Epochs]    RMSE:0.00703,   MAE: 0.00591,  MAPE: 0.58%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13700 Epochs]    RMSE:0.00530,   MAE: 0.00359,  MAPE: 0.30%\n",
      "[13800 Epochs]    RMSE:0.00457,   MAE: 0.00319,  MAPE: 0.21%\n",
      "[13900 Epochs]    RMSE:0.00547,   MAE: 0.00419,  MAPE: 0.39%\n",
      "[14000 Epochs]    RMSE:0.00653,   MAE: 0.00547,  MAPE: 0.50%\n",
      "[14100 Epochs]    RMSE:0.00480,   MAE: 0.00398,  MAPE: 0.39%\n",
      "[14200 Epochs]    RMSE:0.00243,   MAE: 0.00164,  MAPE: 0.13%\n",
      "[14300 Epochs]    RMSE:0.00409,   MAE: 0.00314,  MAPE: 0.31%\n",
      "[14400 Epochs]    RMSE:0.00192,   MAE: 0.00156,  MAPE: 0.17%\n",
      "[14500 Epochs]    RMSE:0.00183,   MAE: 0.00149,  MAPE: 0.19%\n",
      "[14600 Epochs]    RMSE:0.00246,   MAE: 0.00185,  MAPE: 0.21%\n",
      "[14700 Epochs]    RMSE:0.00291,   MAE: 0.00220,  MAPE: 0.26%\n",
      "[14800 Epochs]    RMSE:0.00850,   MAE: 0.00615,  MAPE: 0.40%\n",
      "[14900 Epochs]    RMSE:0.00222,   MAE: 0.00154,  MAPE: 0.20%\n",
      "[15000 Epochs]    RMSE:0.00420,   MAE: 0.00303,  MAPE: 0.23%\n",
      "[15100 Epochs]    RMSE:0.00507,   MAE: 0.00341,  MAPE: 0.36%\n",
      "[15200 Epochs]    RMSE:0.00335,   MAE: 0.00250,  MAPE: 0.30%\n",
      "[15300 Epochs]    RMSE:0.00683,   MAE: 0.00539,  MAPE: 0.48%\n",
      "[15400 Epochs]    RMSE:0.00361,   MAE: 0.00299,  MAPE: 0.34%\n",
      "[15500 Epochs]    RMSE:0.00155,   MAE: 0.00088,  MAPE: 0.10%\n",
      "[15600 Epochs]    RMSE:0.00735,   MAE: 0.00586,  MAPE: 0.55%\n",
      "[15700 Epochs]    RMSE:0.00645,   MAE: 0.00515,  MAPE: 0.52%\n",
      "[15800 Epochs]    RMSE:0.00797,   MAE: 0.00516,  MAPE: 0.37%\n",
      "[15900 Epochs]    RMSE:0.01245,   MAE: 0.01062,  MAPE: 0.96%\n",
      "[16000 Epochs]    RMSE:0.00166,   MAE: 0.00135,  MAPE: 0.15%\n",
      "[16100 Epochs]    RMSE:0.00405,   MAE: 0.00272,  MAPE: 0.33%\n",
      "[16200 Epochs]    RMSE:0.00684,   MAE: 0.00547,  MAPE: 0.46%\n",
      "[16300 Epochs]    RMSE:0.00243,   MAE: 0.00181,  MAPE: 0.21%\n",
      "[16400 Epochs]    RMSE:0.01729,   MAE: 0.01389,  MAPE: 1.05%\n",
      "[16500 Epochs]    RMSE:0.00435,   MAE: 0.00308,  MAPE: 0.38%\n",
      "[16600 Epochs]    RMSE:0.00231,   MAE: 0.00162,  MAPE: 0.14%\n",
      "[16700 Epochs]    RMSE:0.00556,   MAE: 0.00396,  MAPE: 0.31%\n",
      "[16800 Epochs]    RMSE:0.00271,   MAE: 0.00183,  MAPE: 0.24%\n",
      "[16900 Epochs]    RMSE:0.00197,   MAE: 0.00160,  MAPE: 0.38%\n",
      "[17000 Epochs]    RMSE:0.00552,   MAE: 0.00429,  MAPE: 0.38%\n",
      "[17100 Epochs]    RMSE:0.00566,   MAE: 0.00444,  MAPE: 0.39%\n",
      "[17200 Epochs]    RMSE:0.00652,   MAE: 0.00525,  MAPE: 0.44%\n",
      "[17300 Epochs]    RMSE:0.00403,   MAE: 0.00232,  MAPE: 0.24%\n",
      "[17400 Epochs]    RMSE:0.00673,   MAE: 0.00504,  MAPE: 0.39%\n",
      "[17500 Epochs]    RMSE:0.00429,   MAE: 0.00345,  MAPE: 0.32%\n",
      "[17600 Epochs]    RMSE:0.00383,   MAE: 0.00283,  MAPE: 0.31%\n",
      "[17700 Epochs]    RMSE:0.01552,   MAE: 0.01266,  MAPE: 1.01%\n",
      "[17800 Epochs]    RMSE:0.00325,   MAE: 0.00264,  MAPE: 0.29%\n",
      "[17900 Epochs]    RMSE:0.00543,   MAE: 0.00431,  MAPE: 0.47%\n",
      "[18000 Epochs]    RMSE:0.00297,   MAE: 0.00206,  MAPE: 0.26%\n",
      "[18100 Epochs]    RMSE:0.00297,   MAE: 0.00240,  MAPE: 0.36%\n",
      "[18200 Epochs]    RMSE:0.00118,   MAE: 0.00089,  MAPE: 0.09%\n",
      "[18300 Epochs]    RMSE:0.00454,   MAE: 0.00374,  MAPE: 0.35%\n",
      "[18400 Epochs]    RMSE:0.00220,   MAE: 0.00168,  MAPE: 0.17%\n",
      "[18500 Epochs]    RMSE:0.00280,   MAE: 0.00237,  MAPE: 0.33%\n",
      "[18600 Epochs]    RMSE:0.00518,   MAE: 0.00411,  MAPE: 0.30%\n",
      "[18700 Epochs]    RMSE:0.00193,   MAE: 0.00155,  MAPE: 0.16%\n",
      "[18800 Epochs]    RMSE:0.00290,   MAE: 0.00208,  MAPE: 0.22%\n",
      "[18900 Epochs]    RMSE:0.00234,   MAE: 0.00187,  MAPE: 0.16%\n",
      "[19000 Epochs]    RMSE:0.00147,   MAE: 0.00113,  MAPE: 0.12%\n",
      "[19100 Epochs]    RMSE:0.01063,   MAE: 0.00845,  MAPE: 0.74%\n",
      "[19200 Epochs]    RMSE:0.00926,   MAE: 0.00579,  MAPE: 0.38%\n",
      "[19300 Epochs]    RMSE:0.00547,   MAE: 0.00436,  MAPE: 0.33%\n",
      "[19400 Epochs]    RMSE:0.00483,   MAE: 0.00381,  MAPE: 0.34%\n",
      "[19500 Epochs]    RMSE:0.00381,   MAE: 0.00282,  MAPE: 0.24%\n",
      "[19600 Epochs]    RMSE:0.00510,   MAE: 0.00380,  MAPE: 0.31%\n",
      "[19700 Epochs]    RMSE:0.00241,   MAE: 0.00165,  MAPE: 0.12%\n",
      "[19800 Epochs]    RMSE:0.00813,   MAE: 0.00678,  MAPE: 0.65%\n",
      "[19900 Epochs]    RMSE:0.00506,   MAE: 0.00439,  MAPE: 0.71%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00344,   MAE: 0.00267,  MAPE: 0.35%\n",
      "\n",
      "\n",
      "\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8036\\154191563.py:14: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  noOfNeuron1    = np.int(Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,2])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8036\\154191563.py:15: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  noOfNeuron2    = np.int(Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 Epochs]    RMSE:2.20903,   MAE: 1.79688,  MAPE: 111.64%\n",
      "[100 Epochs]    RMSE:0.18626,   MAE: 0.11386,  MAPE: 10.34%\n",
      "[200 Epochs]    RMSE:0.02801,   MAE: 0.02522,  MAPE: 2.79%\n",
      "[300 Epochs]    RMSE:0.00847,   MAE: 0.00759,  MAPE: 1.17%\n",
      "[400 Epochs]    RMSE:0.01505,   MAE: 0.01216,  MAPE: 1.01%\n",
      "[500 Epochs]    RMSE:0.00869,   MAE: 0.00822,  MAPE: 1.20%\n",
      "[600 Epochs]    RMSE:0.02019,   MAE: 0.01838,  MAPE: 2.07%\n",
      "[700 Epochs]    RMSE:0.01518,   MAE: 0.01181,  MAPE: 0.94%\n",
      "[800 Epochs]    RMSE:0.00504,   MAE: 0.00444,  MAPE: 0.44%\n",
      "[900 Epochs]    RMSE:0.02326,   MAE: 0.02160,  MAPE: 2.90%\n",
      "[1000 Epochs]    RMSE:0.01034,   MAE: 0.00916,  MAPE: 1.57%\n",
      "[1100 Epochs]    RMSE:0.00917,   MAE: 0.00715,  MAPE: 0.61%\n",
      "[1200 Epochs]    RMSE:0.01238,   MAE: 0.01128,  MAPE: 1.17%\n",
      "[1300 Epochs]    RMSE:0.00524,   MAE: 0.00438,  MAPE: 0.56%\n",
      "[1400 Epochs]    RMSE:0.02332,   MAE: 0.02095,  MAPE: 1.94%\n",
      "[1500 Epochs]    RMSE:0.01095,   MAE: 0.00896,  MAPE: 1.39%\n",
      "[1600 Epochs]    RMSE:0.01577,   MAE: 0.01388,  MAPE: 1.29%\n",
      "[1700 Epochs]    RMSE:0.02759,   MAE: 0.02271,  MAPE: 1.66%\n",
      "[1800 Epochs]    RMSE:0.01792,   MAE: 0.01485,  MAPE: 1.18%\n",
      "[1900 Epochs]    RMSE:0.02280,   MAE: 0.02005,  MAPE: 1.84%\n",
      "[2000 Epochs]    RMSE:0.01164,   MAE: 0.00937,  MAPE: 0.79%\n",
      "[2100 Epochs]    RMSE:0.00337,   MAE: 0.00290,  MAPE: 0.37%\n",
      "[2200 Epochs]    RMSE:0.00585,   MAE: 0.00518,  MAPE: 0.74%\n",
      "[2300 Epochs]    RMSE:0.01171,   MAE: 0.00979,  MAPE: 0.86%\n",
      "[2400 Epochs]    RMSE:0.01137,   MAE: 0.01023,  MAPE: 1.04%\n",
      "[2500 Epochs]    RMSE:0.00689,   MAE: 0.00585,  MAPE: 0.65%\n",
      "[2600 Epochs]    RMSE:0.01180,   MAE: 0.00885,  MAPE: 0.64%\n",
      "[2700 Epochs]    RMSE:0.01560,   MAE: 0.01322,  MAPE: 1.04%\n",
      "[2800 Epochs]    RMSE:0.01969,   MAE: 0.01608,  MAPE: 1.25%\n",
      "[2900 Epochs]    RMSE:0.00810,   MAE: 0.00652,  MAPE: 0.79%\n",
      "[3000 Epochs]    RMSE:0.00894,   MAE: 0.00813,  MAPE: 1.09%\n",
      "[3100 Epochs]    RMSE:0.00947,   MAE: 0.00718,  MAPE: 0.45%\n",
      "[3200 Epochs]    RMSE:0.00281,   MAE: 0.00229,  MAPE: 0.32%\n",
      "[3300 Epochs]    RMSE:0.02597,   MAE: 0.02280,  MAPE: 1.78%\n",
      "[3400 Epochs]    RMSE:0.01659,   MAE: 0.01491,  MAPE: 1.38%\n",
      "[3500 Epochs]    RMSE:0.01329,   MAE: 0.01102,  MAPE: 0.88%\n",
      "[3600 Epochs]    RMSE:0.01413,   MAE: 0.01190,  MAPE: 0.78%\n",
      "[3700 Epochs]    RMSE:0.00934,   MAE: 0.00682,  MAPE: 0.52%\n",
      "[3800 Epochs]    RMSE:0.01053,   MAE: 0.00938,  MAPE: 1.04%\n",
      "[3900 Epochs]    RMSE:0.02216,   MAE: 0.01881,  MAPE: 1.39%\n",
      "[4000 Epochs]    RMSE:0.00682,   MAE: 0.00577,  MAPE: 0.68%\n",
      "[4100 Epochs]    RMSE:0.00895,   MAE: 0.00840,  MAPE: 0.90%\n",
      "[4200 Epochs]    RMSE:0.01147,   MAE: 0.00738,  MAPE: 0.38%\n",
      "[4300 Epochs]    RMSE:0.01245,   MAE: 0.01076,  MAPE: 1.47%\n",
      "[4400 Epochs]    RMSE:0.00803,   MAE: 0.00668,  MAPE: 0.64%\n",
      "[4500 Epochs]    RMSE:0.01155,   MAE: 0.00951,  MAPE: 1.09%\n",
      "[4600 Epochs]    RMSE:0.00451,   MAE: 0.00388,  MAPE: 0.50%\n",
      "[4700 Epochs]    RMSE:0.00856,   MAE: 0.00745,  MAPE: 0.55%\n",
      "[4800 Epochs]    RMSE:0.00990,   MAE: 0.00824,  MAPE: 0.67%\n",
      "[4900 Epochs]    RMSE:0.00648,   MAE: 0.00526,  MAPE: 0.47%\n",
      "[5000 Epochs]    RMSE:0.00940,   MAE: 0.00738,  MAPE: 0.63%\n",
      "[5100 Epochs]    RMSE:0.00404,   MAE: 0.00292,  MAPE: 0.26%\n",
      "[5200 Epochs]    RMSE:0.02434,   MAE: 0.02121,  MAPE: 1.95%\n",
      "[5300 Epochs]    RMSE:0.00547,   MAE: 0.00417,  MAPE: 0.34%\n",
      "[5400 Epochs]    RMSE:0.00548,   MAE: 0.00501,  MAPE: 0.65%\n",
      "[5500 Epochs]    RMSE:0.00558,   MAE: 0.00511,  MAPE: 0.65%\n",
      "[5600 Epochs]    RMSE:0.00487,   MAE: 0.00415,  MAPE: 0.49%\n",
      "[5700 Epochs]    RMSE:0.00806,   MAE: 0.00743,  MAPE: 0.79%\n",
      "[5800 Epochs]    RMSE:0.01025,   MAE: 0.00803,  MAPE: 0.90%\n",
      "[5900 Epochs]    RMSE:0.01140,   MAE: 0.00963,  MAPE: 0.76%\n",
      "[6000 Epochs]    RMSE:0.00571,   MAE: 0.00475,  MAPE: 0.53%\n",
      "[6100 Epochs]    RMSE:0.00589,   MAE: 0.00466,  MAPE: 0.34%\n",
      "[6200 Epochs]    RMSE:0.00410,   MAE: 0.00331,  MAPE: 0.34%\n",
      "[6300 Epochs]    RMSE:0.00678,   MAE: 0.00510,  MAPE: 0.49%\n",
      "[6400 Epochs]    RMSE:0.00794,   MAE: 0.00612,  MAPE: 0.55%\n",
      "[6500 Epochs]    RMSE:0.01417,   MAE: 0.01264,  MAPE: 1.22%\n",
      "[6600 Epochs]    RMSE:0.01592,   MAE: 0.01413,  MAPE: 1.39%\n",
      "[6700 Epochs]    RMSE:0.02038,   MAE: 0.01708,  MAPE: 1.45%\n",
      "[6800 Epochs]    RMSE:0.01474,   MAE: 0.01086,  MAPE: 0.62%\n",
      "[6900 Epochs]    RMSE:0.00922,   MAE: 0.00792,  MAPE: 1.06%\n",
      "[7000 Epochs]    RMSE:0.01531,   MAE: 0.01377,  MAPE: 1.42%\n",
      "[7100 Epochs]    RMSE:0.00779,   MAE: 0.00584,  MAPE: 0.53%\n",
      "[7200 Epochs]    RMSE:0.00573,   MAE: 0.00460,  MAPE: 0.49%\n",
      "[7300 Epochs]    RMSE:0.01150,   MAE: 0.00918,  MAPE: 0.80%\n",
      "[7400 Epochs]    RMSE:0.00811,   MAE: 0.00702,  MAPE: 0.78%\n",
      "[7500 Epochs]    RMSE:0.00937,   MAE: 0.00783,  MAPE: 0.83%\n",
      "[7600 Epochs]    RMSE:0.00814,   MAE: 0.00682,  MAPE: 0.60%\n",
      "[7700 Epochs]    RMSE:0.00325,   MAE: 0.00275,  MAPE: 0.42%\n",
      "[7800 Epochs]    RMSE:0.01422,   MAE: 0.01284,  MAPE: 1.15%\n",
      "[7900 Epochs]    RMSE:0.00444,   MAE: 0.00389,  MAPE: 0.39%\n",
      "[8000 Epochs]    RMSE:0.00541,   MAE: 0.00424,  MAPE: 0.31%\n",
      "[8100 Epochs]    RMSE:0.01045,   MAE: 0.00763,  MAPE: 0.39%\n",
      "[8200 Epochs]    RMSE:0.00468,   MAE: 0.00373,  MAPE: 0.51%\n",
      "[8300 Epochs]    RMSE:0.00971,   MAE: 0.00696,  MAPE: 0.51%\n",
      "[8400 Epochs]    RMSE:0.01043,   MAE: 0.00981,  MAPE: 0.97%\n",
      "[8500 Epochs]    RMSE:0.00479,   MAE: 0.00350,  MAPE: 0.25%\n",
      "[8600 Epochs]    RMSE:0.00442,   MAE: 0.00350,  MAPE: 0.45%\n",
      "[8700 Epochs]    RMSE:0.00760,   MAE: 0.00655,  MAPE: 0.97%\n",
      "[8800 Epochs]    RMSE:0.01126,   MAE: 0.00996,  MAPE: 0.78%\n",
      "[8900 Epochs]    RMSE:0.00350,   MAE: 0.00289,  MAPE: 0.34%\n",
      "[9000 Epochs]    RMSE:0.01619,   MAE: 0.01390,  MAPE: 1.03%\n",
      "[9100 Epochs]    RMSE:0.00815,   MAE: 0.00625,  MAPE: 0.49%\n",
      "[9200 Epochs]    RMSE:0.01302,   MAE: 0.01091,  MAPE: 0.76%\n",
      "[9300 Epochs]    RMSE:0.00518,   MAE: 0.00353,  MAPE: 0.31%\n",
      "[9400 Epochs]    RMSE:0.00882,   MAE: 0.00604,  MAPE: 0.37%\n",
      "[9500 Epochs]    RMSE:0.01841,   MAE: 0.01454,  MAPE: 0.86%\n",
      "[9600 Epochs]    RMSE:0.01871,   MAE: 0.01521,  MAPE: 0.84%\n",
      "[9700 Epochs]    RMSE:0.00855,   MAE: 0.00787,  MAPE: 0.66%\n",
      "[9800 Epochs]    RMSE:0.01005,   MAE: 0.00716,  MAPE: 0.44%\n",
      "[9900 Epochs]    RMSE:0.00466,   MAE: 0.00398,  MAPE: 0.61%\n",
      "[10000 Epochs]    RMSE:0.00575,   MAE: 0.00444,  MAPE: 0.38%\n",
      "[10100 Epochs]    RMSE:0.00407,   MAE: 0.00343,  MAPE: 0.30%\n",
      "[10200 Epochs]    RMSE:0.00908,   MAE: 0.00787,  MAPE: 0.56%\n",
      "[10300 Epochs]    RMSE:0.01071,   MAE: 0.00926,  MAPE: 0.67%\n",
      "[10400 Epochs]    RMSE:0.01739,   MAE: 0.01360,  MAPE: 0.80%\n",
      "[10500 Epochs]    RMSE:0.00715,   MAE: 0.00568,  MAPE: 0.43%\n",
      "[10600 Epochs]    RMSE:0.00812,   MAE: 0.00678,  MAPE: 0.57%\n",
      "[10700 Epochs]    RMSE:0.00584,   MAE: 0.00457,  MAPE: 0.35%\n",
      "[10800 Epochs]    RMSE:0.00319,   MAE: 0.00226,  MAPE: 0.24%\n",
      "[10900 Epochs]    RMSE:0.00654,   MAE: 0.00492,  MAPE: 0.42%\n",
      "[11000 Epochs]    RMSE:0.01568,   MAE: 0.01147,  MAPE: 0.66%\n",
      "[11100 Epochs]    RMSE:0.00578,   MAE: 0.00478,  MAPE: 0.47%\n",
      "[11200 Epochs]    RMSE:0.00494,   MAE: 0.00359,  MAPE: 0.25%\n",
      "[11300 Epochs]    RMSE:0.01865,   MAE: 0.01586,  MAPE: 1.27%\n",
      "[11400 Epochs]    RMSE:0.00761,   MAE: 0.00602,  MAPE: 0.41%\n",
      "[11500 Epochs]    RMSE:0.01472,   MAE: 0.01275,  MAPE: 0.92%\n",
      "[11600 Epochs]    RMSE:0.00820,   MAE: 0.00581,  MAPE: 0.47%\n",
      "[11700 Epochs]    RMSE:0.01072,   MAE: 0.00858,  MAPE: 0.57%\n",
      "[11800 Epochs]    RMSE:0.00802,   MAE: 0.00631,  MAPE: 0.42%\n",
      "[11900 Epochs]    RMSE:0.01147,   MAE: 0.00877,  MAPE: 0.57%\n",
      "[12000 Epochs]    RMSE:0.01029,   MAE: 0.00691,  MAPE: 0.48%\n",
      "[12100 Epochs]    RMSE:0.00642,   MAE: 0.00487,  MAPE: 0.53%\n",
      "[12200 Epochs]    RMSE:0.00470,   MAE: 0.00405,  MAPE: 0.45%\n",
      "[12300 Epochs]    RMSE:0.00551,   MAE: 0.00458,  MAPE: 0.56%\n",
      "[12400 Epochs]    RMSE:0.01238,   MAE: 0.00902,  MAPE: 0.65%\n",
      "[12500 Epochs]    RMSE:0.01270,   MAE: 0.01124,  MAPE: 0.92%\n",
      "[12600 Epochs]    RMSE:0.00911,   MAE: 0.00681,  MAPE: 0.44%\n",
      "[12700 Epochs]    RMSE:0.00233,   MAE: 0.00193,  MAPE: 0.24%\n",
      "[12800 Epochs]    RMSE:0.00262,   MAE: 0.00174,  MAPE: 0.15%\n",
      "[12900 Epochs]    RMSE:0.00300,   MAE: 0.00212,  MAPE: 0.17%\n",
      "[13000 Epochs]    RMSE:0.00211,   MAE: 0.00161,  MAPE: 0.22%\n",
      "[13100 Epochs]    RMSE:0.01602,   MAE: 0.01299,  MAPE: 0.96%\n",
      "[13200 Epochs]    RMSE:0.00908,   MAE: 0.00677,  MAPE: 0.43%\n",
      "[13300 Epochs]    RMSE:0.00253,   MAE: 0.00201,  MAPE: 0.19%\n",
      "[13400 Epochs]    RMSE:0.00938,   MAE: 0.00731,  MAPE: 0.55%\n",
      "[13500 Epochs]    RMSE:0.00915,   MAE: 0.00716,  MAPE: 0.66%\n",
      "[13600 Epochs]    RMSE:0.01480,   MAE: 0.01146,  MAPE: 0.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13700 Epochs]    RMSE:0.00459,   MAE: 0.00341,  MAPE: 0.24%\n",
      "[13800 Epochs]    RMSE:0.00983,   MAE: 0.00591,  MAPE: 0.31%\n",
      "[13900 Epochs]    RMSE:0.00292,   MAE: 0.00226,  MAPE: 0.14%\n",
      "[14000 Epochs]    RMSE:0.00775,   MAE: 0.00626,  MAPE: 0.48%\n",
      "[14100 Epochs]    RMSE:0.00453,   MAE: 0.00354,  MAPE: 0.24%\n",
      "[14200 Epochs]    RMSE:0.00773,   MAE: 0.00630,  MAPE: 0.44%\n",
      "[14300 Epochs]    RMSE:0.01385,   MAE: 0.01116,  MAPE: 0.72%\n",
      "[14400 Epochs]    RMSE:0.00309,   MAE: 0.00238,  MAPE: 0.20%\n",
      "[14500 Epochs]    RMSE:0.01089,   MAE: 0.00787,  MAPE: 0.37%\n",
      "[14600 Epochs]    RMSE:0.01620,   MAE: 0.01306,  MAPE: 0.70%\n",
      "[14700 Epochs]    RMSE:0.00270,   MAE: 0.00221,  MAPE: 0.22%\n",
      "[14800 Epochs]    RMSE:0.01091,   MAE: 0.00885,  MAPE: 0.73%\n",
      "[14900 Epochs]    RMSE:0.00701,   MAE: 0.00537,  MAPE: 0.31%\n",
      "[15000 Epochs]    RMSE:0.00497,   MAE: 0.00386,  MAPE: 0.26%\n",
      "[15100 Epochs]    RMSE:0.00593,   MAE: 0.00454,  MAPE: 0.37%\n",
      "[15200 Epochs]    RMSE:0.00369,   MAE: 0.00312,  MAPE: 0.36%\n",
      "[15300 Epochs]    RMSE:0.00400,   MAE: 0.00267,  MAPE: 0.22%\n",
      "[15400 Epochs]    RMSE:0.00752,   MAE: 0.00543,  MAPE: 0.40%\n",
      "[15500 Epochs]    RMSE:0.01685,   MAE: 0.01408,  MAPE: 1.02%\n",
      "[15600 Epochs]    RMSE:0.01198,   MAE: 0.00979,  MAPE: 0.68%\n",
      "[15700 Epochs]    RMSE:0.01579,   MAE: 0.01175,  MAPE: 0.57%\n",
      "[15800 Epochs]    RMSE:0.00798,   MAE: 0.00626,  MAPE: 0.52%\n",
      "[15900 Epochs]    RMSE:0.00542,   MAE: 0.00389,  MAPE: 0.22%\n",
      "[16000 Epochs]    RMSE:0.00489,   MAE: 0.00401,  MAPE: 0.29%\n",
      "[16100 Epochs]    RMSE:0.00303,   MAE: 0.00241,  MAPE: 0.28%\n",
      "[16200 Epochs]    RMSE:0.01235,   MAE: 0.01107,  MAPE: 1.22%\n",
      "[16300 Epochs]    RMSE:0.01712,   MAE: 0.01332,  MAPE: 0.69%\n",
      "[16400 Epochs]    RMSE:0.01518,   MAE: 0.01227,  MAPE: 0.77%\n",
      "[16500 Epochs]    RMSE:0.00936,   MAE: 0.00755,  MAPE: 0.66%\n",
      "[16600 Epochs]    RMSE:0.00276,   MAE: 0.00235,  MAPE: 0.24%\n",
      "[16700 Epochs]    RMSE:0.01125,   MAE: 0.00969,  MAPE: 0.77%\n",
      "[16800 Epochs]    RMSE:0.00819,   MAE: 0.00574,  MAPE: 0.40%\n",
      "[16900 Epochs]    RMSE:0.00841,   MAE: 0.00644,  MAPE: 0.39%\n",
      "[17000 Epochs]    RMSE:0.00835,   MAE: 0.00634,  MAPE: 0.43%\n",
      "[17100 Epochs]    RMSE:0.01418,   MAE: 0.01137,  MAPE: 0.74%\n",
      "[17200 Epochs]    RMSE:0.00421,   MAE: 0.00336,  MAPE: 0.38%\n",
      "[17300 Epochs]    RMSE:0.00908,   MAE: 0.00653,  MAPE: 0.46%\n",
      "[17400 Epochs]    RMSE:0.00622,   MAE: 0.00465,  MAPE: 0.31%\n",
      "[17500 Epochs]    RMSE:0.01500,   MAE: 0.01243,  MAPE: 0.85%\n",
      "[17600 Epochs]    RMSE:0.00534,   MAE: 0.00458,  MAPE: 0.44%\n",
      "[17700 Epochs]    RMSE:0.01108,   MAE: 0.00956,  MAPE: 0.78%\n",
      "[17800 Epochs]    RMSE:0.01430,   MAE: 0.01230,  MAPE: 0.78%\n",
      "[17900 Epochs]    RMSE:0.00303,   MAE: 0.00246,  MAPE: 0.20%\n",
      "[18000 Epochs]    RMSE:0.01130,   MAE: 0.00787,  MAPE: 0.48%\n",
      "[18100 Epochs]    RMSE:0.00640,   MAE: 0.00545,  MAPE: 0.40%\n",
      "[18200 Epochs]    RMSE:0.00682,   MAE: 0.00553,  MAPE: 0.35%\n",
      "[18300 Epochs]    RMSE:0.01320,   MAE: 0.01128,  MAPE: 0.79%\n",
      "[18400 Epochs]    RMSE:0.00634,   MAE: 0.00497,  MAPE: 0.55%\n",
      "[18500 Epochs]    RMSE:0.00837,   MAE: 0.00647,  MAPE: 0.42%\n",
      "[18600 Epochs]    RMSE:0.00924,   MAE: 0.00657,  MAPE: 0.47%\n",
      "[18700 Epochs]    RMSE:0.00400,   MAE: 0.00305,  MAPE: 0.29%\n",
      "[18800 Epochs]    RMSE:0.00545,   MAE: 0.00434,  MAPE: 0.29%\n",
      "[18900 Epochs]    RMSE:0.00216,   MAE: 0.00168,  MAPE: 0.17%\n",
      "[19000 Epochs]    RMSE:0.00953,   MAE: 0.00865,  MAPE: 0.82%\n",
      "[19100 Epochs]    RMSE:0.00785,   MAE: 0.00643,  MAPE: 0.41%\n",
      "[19200 Epochs]    RMSE:0.00348,   MAE: 0.00293,  MAPE: 0.24%\n",
      "[19300 Epochs]    RMSE:0.02020,   MAE: 0.01630,  MAPE: 0.96%\n",
      "[19400 Epochs]    RMSE:0.00403,   MAE: 0.00306,  MAPE: 0.28%\n",
      "[19500 Epochs]    RMSE:0.00980,   MAE: 0.00667,  MAPE: 0.35%\n",
      "[19600 Epochs]    RMSE:0.00639,   MAE: 0.00506,  MAPE: 0.36%\n",
      "[19700 Epochs]    RMSE:0.00786,   MAE: 0.00620,  MAPE: 0.37%\n",
      "[19800 Epochs]    RMSE:0.00659,   MAE: 0.00573,  MAPE: 0.63%\n",
      "[19900 Epochs]    RMSE:0.00728,   MAE: 0.00609,  MAPE: 0.45%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00474,   MAE: 0.00368,  MAPE: 0.26%\n",
      "\n",
      "\n",
      "\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8036\\154191563.py:14: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  noOfNeuron1    = np.int(Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,2])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8036\\154191563.py:15: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  noOfNeuron2    = np.int(Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 Epochs]    RMSE:2.11382,   MAE: 1.65290,  MAPE: 98.47%\n",
      "[100 Epochs]    RMSE:0.09567,   MAE: 0.06338,  MAPE: 4.87%\n",
      "[200 Epochs]    RMSE:0.03047,   MAE: 0.01929,  MAPE: 1.86%\n",
      "[300 Epochs]    RMSE:0.02152,   MAE: 0.01684,  MAPE: 1.42%\n",
      "[400 Epochs]    RMSE:0.01943,   MAE: 0.01750,  MAPE: 1.89%\n",
      "[500 Epochs]    RMSE:0.03535,   MAE: 0.02963,  MAPE: 2.49%\n",
      "[600 Epochs]    RMSE:0.02471,   MAE: 0.02375,  MAPE: 3.02%\n",
      "[700 Epochs]    RMSE:0.02003,   MAE: 0.01752,  MAPE: 1.81%\n",
      "[800 Epochs]    RMSE:0.03284,   MAE: 0.02554,  MAPE: 1.53%\n",
      "[900 Epochs]    RMSE:0.00355,   MAE: 0.00294,  MAPE: 0.43%\n",
      "[1000 Epochs]    RMSE:0.00306,   MAE: 0.00238,  MAPE: 0.26%\n",
      "[1100 Epochs]    RMSE:0.01112,   MAE: 0.00946,  MAPE: 0.87%\n",
      "[1200 Epochs]    RMSE:0.01511,   MAE: 0.01229,  MAPE: 1.48%\n",
      "[1300 Epochs]    RMSE:0.02236,   MAE: 0.02068,  MAPE: 2.66%\n",
      "[1400 Epochs]    RMSE:0.00798,   MAE: 0.00579,  MAPE: 0.41%\n",
      "[1500 Epochs]    RMSE:0.00880,   MAE: 0.00720,  MAPE: 0.67%\n",
      "[1600 Epochs]    RMSE:0.00565,   MAE: 0.00480,  MAPE: 0.66%\n",
      "[1700 Epochs]    RMSE:0.00816,   MAE: 0.00737,  MAPE: 1.27%\n",
      "[1800 Epochs]    RMSE:0.01313,   MAE: 0.01126,  MAPE: 1.08%\n",
      "[1900 Epochs]    RMSE:0.00529,   MAE: 0.00431,  MAPE: 0.68%\n",
      "[2000 Epochs]    RMSE:0.01568,   MAE: 0.01364,  MAPE: 1.25%\n",
      "[2100 Epochs]    RMSE:0.01623,   MAE: 0.01345,  MAPE: 1.18%\n",
      "[2200 Epochs]    RMSE:0.01158,   MAE: 0.00885,  MAPE: 1.10%\n",
      "[2300 Epochs]    RMSE:0.00742,   MAE: 0.00637,  MAPE: 0.77%\n",
      "[2400 Epochs]    RMSE:0.00871,   MAE: 0.00757,  MAPE: 1.04%\n",
      "[2500 Epochs]    RMSE:0.01205,   MAE: 0.01042,  MAPE: 1.50%\n",
      "[2600 Epochs]    RMSE:0.03289,   MAE: 0.02896,  MAPE: 2.95%\n",
      "[2700 Epochs]    RMSE:0.01569,   MAE: 0.01211,  MAPE: 1.01%\n",
      "[2800 Epochs]    RMSE:0.01193,   MAE: 0.00941,  MAPE: 1.08%\n",
      "[2900 Epochs]    RMSE:0.01354,   MAE: 0.01280,  MAPE: 1.66%\n",
      "[3000 Epochs]    RMSE:0.00815,   MAE: 0.00686,  MAPE: 0.79%\n",
      "[3100 Epochs]    RMSE:0.00837,   MAE: 0.00659,  MAPE: 0.64%\n",
      "[3200 Epochs]    RMSE:0.00521,   MAE: 0.00432,  MAPE: 0.55%\n",
      "[3300 Epochs]    RMSE:0.01108,   MAE: 0.00849,  MAPE: 0.46%\n",
      "[3400 Epochs]    RMSE:0.02274,   MAE: 0.02021,  MAPE: 2.12%\n",
      "[3500 Epochs]    RMSE:0.00507,   MAE: 0.00400,  MAPE: 0.37%\n",
      "[3600 Epochs]    RMSE:0.01157,   MAE: 0.00988,  MAPE: 1.24%\n",
      "[3700 Epochs]    RMSE:0.00756,   MAE: 0.00568,  MAPE: 0.62%\n",
      "[3800 Epochs]    RMSE:0.01091,   MAE: 0.00736,  MAPE: 0.41%\n",
      "[3900 Epochs]    RMSE:0.01206,   MAE: 0.01037,  MAPE: 1.05%\n",
      "[4000 Epochs]    RMSE:0.00931,   MAE: 0.00710,  MAPE: 0.54%\n",
      "[4100 Epochs]    RMSE:0.00258,   MAE: 0.00205,  MAPE: 0.29%\n",
      "[4200 Epochs]    RMSE:0.01173,   MAE: 0.00927,  MAPE: 0.91%\n",
      "[4300 Epochs]    RMSE:0.00448,   MAE: 0.00364,  MAPE: 0.44%\n",
      "[4400 Epochs]    RMSE:0.00196,   MAE: 0.00171,  MAPE: 0.20%\n",
      "[4500 Epochs]    RMSE:0.04014,   MAE: 0.03344,  MAPE: 2.68%\n",
      "[4600 Epochs]    RMSE:0.00429,   MAE: 0.00335,  MAPE: 0.48%\n",
      "[4700 Epochs]    RMSE:0.00462,   MAE: 0.00347,  MAPE: 0.30%\n",
      "[4800 Epochs]    RMSE:0.00396,   MAE: 0.00318,  MAPE: 0.51%\n",
      "[4900 Epochs]    RMSE:0.01150,   MAE: 0.00892,  MAPE: 0.77%\n",
      "[5000 Epochs]    RMSE:0.00454,   MAE: 0.00375,  MAPE: 0.49%\n",
      "[5100 Epochs]    RMSE:0.00799,   MAE: 0.00658,  MAPE: 0.63%\n",
      "[5200 Epochs]    RMSE:0.01027,   MAE: 0.00814,  MAPE: 0.61%\n",
      "[5300 Epochs]    RMSE:0.00370,   MAE: 0.00317,  MAPE: 0.35%\n",
      "[5400 Epochs]    RMSE:0.00861,   MAE: 0.00746,  MAPE: 0.80%\n",
      "[5500 Epochs]    RMSE:0.00749,   MAE: 0.00552,  MAPE: 0.45%\n",
      "[5600 Epochs]    RMSE:0.01591,   MAE: 0.01132,  MAPE: 0.66%\n",
      "[5700 Epochs]    RMSE:0.01088,   MAE: 0.00700,  MAPE: 0.58%\n",
      "[5800 Epochs]    RMSE:0.00556,   MAE: 0.00466,  MAPE: 0.53%\n",
      "[5900 Epochs]    RMSE:0.01179,   MAE: 0.00923,  MAPE: 0.69%\n",
      "[6000 Epochs]    RMSE:0.00386,   MAE: 0.00337,  MAPE: 0.48%\n",
      "[6100 Epochs]    RMSE:0.00408,   MAE: 0.00350,  MAPE: 0.41%\n",
      "[6200 Epochs]    RMSE:0.00798,   MAE: 0.00571,  MAPE: 0.49%\n",
      "[6300 Epochs]    RMSE:0.00415,   MAE: 0.00299,  MAPE: 0.24%\n",
      "[6400 Epochs]    RMSE:0.00743,   MAE: 0.00628,  MAPE: 0.95%\n",
      "[6500 Epochs]    RMSE:0.00701,   MAE: 0.00547,  MAPE: 0.61%\n",
      "[6600 Epochs]    RMSE:0.00727,   MAE: 0.00573,  MAPE: 0.53%\n",
      "[6700 Epochs]    RMSE:0.00871,   MAE: 0.00671,  MAPE: 0.54%\n",
      "[6800 Epochs]    RMSE:0.01341,   MAE: 0.01162,  MAPE: 1.14%\n",
      "[6900 Epochs]    RMSE:0.01439,   MAE: 0.01276,  MAPE: 1.31%\n",
      "[7000 Epochs]    RMSE:0.01188,   MAE: 0.01039,  MAPE: 1.42%\n",
      "[7100 Epochs]    RMSE:0.01461,   MAE: 0.01354,  MAPE: 1.51%\n",
      "[7200 Epochs]    RMSE:0.01212,   MAE: 0.01132,  MAPE: 1.42%\n",
      "[7300 Epochs]    RMSE:0.00697,   MAE: 0.00655,  MAPE: 0.75%\n",
      "[7400 Epochs]    RMSE:0.00773,   MAE: 0.00732,  MAPE: 0.98%\n",
      "[7500 Epochs]    RMSE:0.00655,   MAE: 0.00562,  MAPE: 0.46%\n",
      "[7600 Epochs]    RMSE:0.00914,   MAE: 0.00626,  MAPE: 0.45%\n",
      "[7700 Epochs]    RMSE:0.00319,   MAE: 0.00251,  MAPE: 0.26%\n",
      "[7800 Epochs]    RMSE:0.00741,   MAE: 0.00653,  MAPE: 0.77%\n",
      "[7900 Epochs]    RMSE:0.00365,   MAE: 0.00328,  MAPE: 0.45%\n",
      "[8000 Epochs]    RMSE:0.00346,   MAE: 0.00302,  MAPE: 0.37%\n",
      "[8100 Epochs]    RMSE:0.00346,   MAE: 0.00270,  MAPE: 0.33%\n",
      "[8200 Epochs]    RMSE:0.01025,   MAE: 0.00694,  MAPE: 0.35%\n",
      "[8300 Epochs]    RMSE:0.00761,   MAE: 0.00634,  MAPE: 0.50%\n",
      "[8400 Epochs]    RMSE:0.01862,   MAE: 0.01596,  MAPE: 1.25%\n",
      "[8500 Epochs]    RMSE:0.00917,   MAE: 0.00654,  MAPE: 0.45%\n",
      "[8600 Epochs]    RMSE:0.00503,   MAE: 0.00373,  MAPE: 0.40%\n",
      "[8700 Epochs]    RMSE:0.00556,   MAE: 0.00461,  MAPE: 0.67%\n",
      "[8800 Epochs]    RMSE:0.02155,   MAE: 0.01928,  MAPE: 1.84%\n",
      "[8900 Epochs]    RMSE:0.00688,   MAE: 0.00588,  MAPE: 0.48%\n",
      "[9000 Epochs]    RMSE:0.00519,   MAE: 0.00463,  MAPE: 0.73%\n",
      "[9100 Epochs]    RMSE:0.00515,   MAE: 0.00381,  MAPE: 0.26%\n",
      "[9200 Epochs]    RMSE:0.01685,   MAE: 0.01444,  MAPE: 1.13%\n",
      "[9300 Epochs]    RMSE:0.00345,   MAE: 0.00233,  MAPE: 0.26%\n",
      "[9400 Epochs]    RMSE:0.00541,   MAE: 0.00398,  MAPE: 0.42%\n",
      "[9500 Epochs]    RMSE:0.00318,   MAE: 0.00245,  MAPE: 0.24%\n",
      "[9600 Epochs]    RMSE:0.00445,   MAE: 0.00318,  MAPE: 0.34%\n",
      "[9700 Epochs]    RMSE:0.01680,   MAE: 0.01392,  MAPE: 1.00%\n",
      "[9800 Epochs]    RMSE:0.02333,   MAE: 0.02002,  MAPE: 1.65%\n",
      "[9900 Epochs]    RMSE:0.00851,   MAE: 0.00606,  MAPE: 0.54%\n",
      "[10000 Epochs]    RMSE:0.01368,   MAE: 0.01147,  MAPE: 0.99%\n",
      "[10100 Epochs]    RMSE:0.00970,   MAE: 0.00738,  MAPE: 0.51%\n",
      "[10200 Epochs]    RMSE:0.00816,   MAE: 0.00608,  MAPE: 0.46%\n",
      "[10300 Epochs]    RMSE:0.01731,   MAE: 0.01446,  MAPE: 1.13%\n",
      "[10400 Epochs]    RMSE:0.00687,   MAE: 0.00531,  MAPE: 0.36%\n",
      "[10500 Epochs]    RMSE:0.01161,   MAE: 0.01045,  MAPE: 1.31%\n",
      "[10600 Epochs]    RMSE:0.00965,   MAE: 0.00706,  MAPE: 0.49%\n",
      "[10700 Epochs]    RMSE:0.00893,   MAE: 0.00699,  MAPE: 0.47%\n",
      "[10800 Epochs]    RMSE:0.00611,   MAE: 0.00524,  MAPE: 0.61%\n",
      "[10900 Epochs]    RMSE:0.00451,   MAE: 0.00349,  MAPE: 0.50%\n",
      "[11000 Epochs]    RMSE:0.00675,   MAE: 0.00542,  MAPE: 0.38%\n",
      "[11100 Epochs]    RMSE:0.01079,   MAE: 0.00881,  MAPE: 0.75%\n",
      "[11200 Epochs]    RMSE:0.00436,   MAE: 0.00307,  MAPE: 0.29%\n",
      "[11300 Epochs]    RMSE:0.00937,   MAE: 0.00794,  MAPE: 0.64%\n",
      "[11400 Epochs]    RMSE:0.00288,   MAE: 0.00224,  MAPE: 0.21%\n",
      "[11500 Epochs]    RMSE:0.00790,   MAE: 0.00609,  MAPE: 0.45%\n",
      "[11600 Epochs]    RMSE:0.00438,   MAE: 0.00395,  MAPE: 0.57%\n",
      "[11700 Epochs]    RMSE:0.00693,   MAE: 0.00556,  MAPE: 0.83%\n",
      "[11800 Epochs]    RMSE:0.01803,   MAE: 0.01612,  MAPE: 1.42%\n",
      "[11900 Epochs]    RMSE:0.01290,   MAE: 0.00964,  MAPE: 0.56%\n",
      "[12000 Epochs]    RMSE:0.01861,   MAE: 0.01618,  MAPE: 1.46%\n",
      "[12100 Epochs]    RMSE:0.00452,   MAE: 0.00344,  MAPE: 0.23%\n",
      "[12200 Epochs]    RMSE:0.00387,   MAE: 0.00292,  MAPE: 0.29%\n",
      "[12300 Epochs]    RMSE:0.00497,   MAE: 0.00418,  MAPE: 0.56%\n",
      "[12400 Epochs]    RMSE:0.00607,   MAE: 0.00424,  MAPE: 0.27%\n",
      "[12500 Epochs]    RMSE:0.00966,   MAE: 0.00787,  MAPE: 0.80%\n",
      "[12600 Epochs]    RMSE:0.00877,   MAE: 0.00656,  MAPE: 0.49%\n",
      "[12700 Epochs]    RMSE:0.00483,   MAE: 0.00399,  MAPE: 0.32%\n",
      "[12800 Epochs]    RMSE:0.01334,   MAE: 0.01013,  MAPE: 0.75%\n",
      "[12900 Epochs]    RMSE:0.00426,   MAE: 0.00349,  MAPE: 0.32%\n",
      "[13000 Epochs]    RMSE:0.00422,   MAE: 0.00363,  MAPE: 0.39%\n",
      "[13100 Epochs]    RMSE:0.00505,   MAE: 0.00434,  MAPE: 0.44%\n",
      "[13200 Epochs]    RMSE:0.01012,   MAE: 0.00734,  MAPE: 0.56%\n",
      "[13300 Epochs]    RMSE:0.00902,   MAE: 0.00754,  MAPE: 0.64%\n",
      "[13400 Epochs]    RMSE:0.00532,   MAE: 0.00427,  MAPE: 0.33%\n",
      "[13500 Epochs]    RMSE:0.00475,   MAE: 0.00347,  MAPE: 0.25%\n",
      "[13600 Epochs]    RMSE:0.00460,   MAE: 0.00325,  MAPE: 0.22%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13700 Epochs]    RMSE:0.00655,   MAE: 0.00512,  MAPE: 0.32%\n",
      "[13800 Epochs]    RMSE:0.00480,   MAE: 0.00398,  MAPE: 0.63%\n",
      "[13900 Epochs]    RMSE:0.00906,   MAE: 0.00796,  MAPE: 0.71%\n",
      "[14000 Epochs]    RMSE:0.00467,   MAE: 0.00381,  MAPE: 0.38%\n",
      "[14100 Epochs]    RMSE:0.00680,   MAE: 0.00450,  MAPE: 0.41%\n",
      "[14200 Epochs]    RMSE:0.01350,   MAE: 0.01006,  MAPE: 0.55%\n",
      "[14300 Epochs]    RMSE:0.00265,   MAE: 0.00223,  MAPE: 0.29%\n",
      "[14400 Epochs]    RMSE:0.00541,   MAE: 0.00399,  MAPE: 0.28%\n",
      "[14500 Epochs]    RMSE:0.00968,   MAE: 0.00698,  MAPE: 0.37%\n",
      "[14600 Epochs]    RMSE:0.01706,   MAE: 0.01345,  MAPE: 1.08%\n",
      "[14700 Epochs]    RMSE:0.00230,   MAE: 0.00165,  MAPE: 0.18%\n",
      "[14800 Epochs]    RMSE:0.00528,   MAE: 0.00407,  MAPE: 0.46%\n",
      "[14900 Epochs]    RMSE:0.02189,   MAE: 0.01889,  MAPE: 1.54%\n",
      "[15000 Epochs]    RMSE:0.00324,   MAE: 0.00235,  MAPE: 0.15%\n",
      "[15100 Epochs]    RMSE:0.00627,   MAE: 0.00474,  MAPE: 0.32%\n",
      "[15200 Epochs]    RMSE:0.01091,   MAE: 0.00840,  MAPE: 0.59%\n",
      "[15300 Epochs]    RMSE:0.00696,   MAE: 0.00534,  MAPE: 0.38%\n",
      "[15400 Epochs]    RMSE:0.01075,   MAE: 0.00794,  MAPE: 0.64%\n",
      "[15500 Epochs]    RMSE:0.01223,   MAE: 0.00957,  MAPE: 0.56%\n",
      "[15600 Epochs]    RMSE:0.01643,   MAE: 0.01346,  MAPE: 0.82%\n",
      "[15700 Epochs]    RMSE:0.00937,   MAE: 0.00638,  MAPE: 0.37%\n",
      "[15800 Epochs]    RMSE:0.01625,   MAE: 0.01451,  MAPE: 1.39%\n",
      "[15900 Epochs]    RMSE:0.00370,   MAE: 0.00262,  MAPE: 0.19%\n",
      "[16000 Epochs]    RMSE:0.00970,   MAE: 0.00791,  MAPE: 0.62%\n",
      "[16100 Epochs]    RMSE:0.00539,   MAE: 0.00413,  MAPE: 0.33%\n",
      "[16200 Epochs]    RMSE:0.00441,   MAE: 0.00383,  MAPE: 0.68%\n",
      "[16300 Epochs]    RMSE:0.01358,   MAE: 0.01089,  MAPE: 0.78%\n",
      "[16400 Epochs]    RMSE:0.00805,   MAE: 0.00702,  MAPE: 0.77%\n",
      "[16500 Epochs]    RMSE:0.00541,   MAE: 0.00373,  MAPE: 0.23%\n",
      "[16600 Epochs]    RMSE:0.01941,   MAE: 0.01619,  MAPE: 1.10%\n",
      "[16700 Epochs]    RMSE:0.00363,   MAE: 0.00293,  MAPE: 0.47%\n",
      "[16800 Epochs]    RMSE:0.00662,   MAE: 0.00536,  MAPE: 0.53%\n",
      "[16900 Epochs]    RMSE:0.00301,   MAE: 0.00253,  MAPE: 0.25%\n",
      "[17000 Epochs]    RMSE:0.00715,   MAE: 0.00566,  MAPE: 0.41%\n",
      "[17100 Epochs]    RMSE:0.00359,   MAE: 0.00288,  MAPE: 0.33%\n",
      "[17200 Epochs]    RMSE:0.00527,   MAE: 0.00412,  MAPE: 0.39%\n",
      "[17300 Epochs]    RMSE:0.00993,   MAE: 0.00767,  MAPE: 0.63%\n",
      "[17400 Epochs]    RMSE:0.00381,   MAE: 0.00280,  MAPE: 0.23%\n",
      "[17500 Epochs]    RMSE:0.01159,   MAE: 0.00830,  MAPE: 0.46%\n",
      "[17600 Epochs]    RMSE:0.00542,   MAE: 0.00442,  MAPE: 0.38%\n",
      "[17700 Epochs]    RMSE:0.00582,   MAE: 0.00388,  MAPE: 0.24%\n",
      "[17800 Epochs]    RMSE:0.00508,   MAE: 0.00312,  MAPE: 0.26%\n",
      "[17900 Epochs]    RMSE:0.01627,   MAE: 0.01391,  MAPE: 1.01%\n",
      "[18000 Epochs]    RMSE:0.00749,   MAE: 0.00514,  MAPE: 0.39%\n",
      "[18100 Epochs]    RMSE:0.00490,   MAE: 0.00399,  MAPE: 0.39%\n",
      "[18200 Epochs]    RMSE:0.00396,   MAE: 0.00274,  MAPE: 0.19%\n",
      "[18300 Epochs]    RMSE:0.00561,   MAE: 0.00371,  MAPE: 0.20%\n",
      "[18400 Epochs]    RMSE:0.01405,   MAE: 0.01126,  MAPE: 0.68%\n",
      "[18500 Epochs]    RMSE:0.00416,   MAE: 0.00354,  MAPE: 0.36%\n",
      "[18600 Epochs]    RMSE:0.01433,   MAE: 0.01086,  MAPE: 0.62%\n",
      "[18700 Epochs]    RMSE:0.00515,   MAE: 0.00400,  MAPE: 0.25%\n",
      "[18800 Epochs]    RMSE:0.00929,   MAE: 0.00766,  MAPE: 0.63%\n",
      "[18900 Epochs]    RMSE:0.00341,   MAE: 0.00276,  MAPE: 0.43%\n",
      "[19000 Epochs]    RMSE:0.00479,   MAE: 0.00380,  MAPE: 0.43%\n",
      "[19100 Epochs]    RMSE:0.00283,   MAE: 0.00220,  MAPE: 0.14%\n",
      "[19200 Epochs]    RMSE:0.00955,   MAE: 0.00743,  MAPE: 0.39%\n",
      "[19300 Epochs]    RMSE:0.01127,   MAE: 0.00862,  MAPE: 0.59%\n",
      "[19400 Epochs]    RMSE:0.01461,   MAE: 0.01188,  MAPE: 0.93%\n",
      "[19500 Epochs]    RMSE:0.00530,   MAE: 0.00414,  MAPE: 0.26%\n",
      "[19600 Epochs]    RMSE:0.01433,   MAE: 0.01190,  MAPE: 0.79%\n",
      "[19700 Epochs]    RMSE:0.00923,   MAE: 0.00684,  MAPE: 0.39%\n",
      "[19800 Epochs]    RMSE:0.00551,   MAE: 0.00456,  MAPE: 0.32%\n",
      "[19900 Epochs]    RMSE:0.00616,   MAE: 0.00505,  MAPE: 0.43%\n",
      "\n",
      "[Final Epochs]    RMSE:0.00161,   MAE: 0.00125,  MAPE: 0.13%\n"
     ]
    }
   ],
   "source": [
    "for F in range(Fold):\n",
    "    s1 = 'TrainData  = TrainData_Fold%d'%(F+1)\n",
    "    exec(s1)\n",
    "    s2 = 'TrainLabel = TrainLabel_Fold%d'%(F+1)\n",
    "    exec(s2)\n",
    "    s3 = 'ValidData  = ValidData_Fold%d'%(F+1)\n",
    "    exec(s3)\n",
    "    s4 = 'ValidLabel  = ValidLabel_Fold%d'%(F+1)\n",
    "    exec(s4)\n",
    "    for M in range(1):\n",
    "\n",
    "        Tr_result_temp = pd.read_csv('./27case_ANN_prediction/Tr_result_epoch2000.csv', sep=',')\n",
    "        learningRate   = Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,1]\n",
    "        noOfNeuron1    = np.int(Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,2])\n",
    "        noOfNeuron2    = np.int(Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,3])\n",
    "        Epoch          = 20000\n",
    "\n",
    "        print('\\n\\n\\nPrediction :' + Model[M])\n",
    "        print('Learning rate : {:.3}'.format(learningRate))\n",
    "        print('Hidden 1 neuron : %d'%(noOfNeuron1))\n",
    "        print('Hidden 2 neuron : %d'%(noOfNeuron2))\n",
    "\n",
    "    #     exec('Label_Trn = TrainLabel_%d'%(M+1))\n",
    "\n",
    "        ################ 신경망 구조 재설계 ################\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        def ANN_model(input_data):\n",
    "            model = keras.Sequential()\n",
    "            model.add(keras.layers.Dense(units = noOfNeuron_in,\n",
    "                                         input_shape = (input_data.shape[1],), activation = 'relu'))  # Input  Layer\n",
    "            model.add(keras.layers.Dense(units = noOfNeuron1,                  activation = 'relu'))  # Hidden Layer 1\n",
    "            model.add(keras.layers.Dense(units = noOfNeuron2,                  activation = 'relu'))  # Hidden Layer 2\n",
    "            model.add(keras.layers.Dense(units = noOfNeuron_out,               )) # Output Layer\n",
    "            model.compile(optimizer= keras.optimizers.Adam(learning_rate = learningRate),\n",
    "                          loss=keras.losses.mean_absolute_error,\n",
    "                          metrics=['mse','mae','mape'])\n",
    "            return model\n",
    "        model = ANN_model(TrainData)\n",
    "\n",
    "        ################ 신경망 학습 ################\n",
    "\n",
    "        BestModel_temp = model.fit(TrainData, TrainLabel, epochs=Epoch, verbose=0, callbacks=[AccuracyPerEpoch()], batch_size=100, validation_data=(ValidData, ValidLabel))\n",
    "        print(\"\\n[Final Epochs]    RMSE:{:.5f},   MAE: {:.5f},  MAPE: {:.2f}%\"\n",
    "              .format(np.sqrt(BestModel_temp.history['mse'][-1]), BestModel_temp.history['mae'][-1], BestModel_temp.history['mape'][-1]))\n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        # 모델 저장\n",
    "        model.save('./27case_ANNmodels_kfold/BestModel_M%d_Fold%d.h5'%(M+1,F+1))\n",
    "\n",
    "        # 히스토리 저장\n",
    "        RMSE  = np.sqrt(np.array(BestModel_temp.history['mse'])[:, np.newaxis])\n",
    "        MAE   = np.array(BestModel_temp.history['mae'])[:, np.newaxis]\n",
    "        MAPE  = np.array(BestModel_temp.history['mape'])[:, np.newaxis]\n",
    "\n",
    "        History_temp = pd.DataFrame(np.concatenate([RMSE,MAE,MAPE],axis=1))\n",
    "        History_temp.to_csv(\"./27case_ANNmodels_kfold/BestModel_M%d_Fold%d_history.csv\"%(M+1,F+1), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 20.0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = pd.read_csv('./27case_ANNmodels_kfold/BestModel_M1_Fold1_history.csv', sep = \",\")\n",
    "plt.plot(graph.iloc[:,2])\n",
    "plt.ylim(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 20.0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = pd.read_csv('./27case_ANNmodels_kfold/BestModel_M1_Fold3_history.csv', sep = \",\")\n",
    "plt.plot(graph.iloc[:,2])\n",
    "plt.ylim(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mape (%)')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(BestModel_temp.history['mape'])\n",
    "plt.ylim(0,20)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('mape (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for F in range(Fold):\n",
    "    s = \"Model_Fold%d = keras.models.load_model('./27case_ANNmodels_kfold/BestModel_M1_Fold%d.h5')\"%(F+1,F+1)\n",
    "    exec(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                200       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 70)                3570      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 80)                5680      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,531\n",
      "Trainable params: 9,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model_Fold1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CF5E1B3670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    }
   ],
   "source": [
    "for i in range (Fold):\n",
    "    s1 = \"real2 = ValidLabel_Fold%d\"%(i+1)\n",
    "    exec(s1)\n",
    "    real3 = real2.sub(0.5)\n",
    "    real4 = real3.mul(max_VS - min_VS)\n",
    "    real = real4 + min_VS\n",
    "    \n",
    "    s2 = \"predict2 = Model_Fold%d.predict(ValidData_Fold%d)\"%(i+1,i+1)\n",
    "    exec(s2)\n",
    "    predict2 = pd.DataFrame(predict2)\n",
    "    predict3 = predict2.sub(0.5)\n",
    "    predict4 = predict3.mul(max_VS - min_VS)\n",
    "    predict = predict4 + min_VS\n",
    "    \n",
    "    s3 = 'Result_Fold%d =  pd.DataFrame(np.concatenate((real,predict), axis = 1))'%(i+1)\n",
    "    exec(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predict</th>\n",
       "      <th>Error</th>\n",
       "      <th>absError</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.805868</td>\n",
       "      <td>8.868258</td>\n",
       "      <td>-13.610139</td>\n",
       "      <td>13.610139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.367308</td>\n",
       "      <td>14.017777</td>\n",
       "      <td>-13.345422</td>\n",
       "      <td>13.345422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.029634</td>\n",
       "      <td>17.805134</td>\n",
       "      <td>1.245173</td>\n",
       "      <td>1.245173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.933022</td>\n",
       "      <td>1.280447</td>\n",
       "      <td>56.343760</td>\n",
       "      <td>56.343760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.840932</td>\n",
       "      <td>3.567870</td>\n",
       "      <td>26.297862</td>\n",
       "      <td>26.297862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.411128</td>\n",
       "      <td>9.589552</td>\n",
       "      <td>-29.393959</td>\n",
       "      <td>29.393959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.852096</td>\n",
       "      <td>0.065904</td>\n",
       "      <td>107.734298</td>\n",
       "      <td>107.734298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.558234</td>\n",
       "      <td>0.465700</td>\n",
       "      <td>183.423712</td>\n",
       "      <td>183.423712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.216126</td>\n",
       "      <td>1.764127</td>\n",
       "      <td>916.249215</td>\n",
       "      <td>916.249215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.485690</td>\n",
       "      <td>7.682308</td>\n",
       "      <td>-2.626581</td>\n",
       "      <td>2.626581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.139236</td>\n",
       "      <td>9.971560</td>\n",
       "      <td>17.856771</td>\n",
       "      <td>17.856771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17.047170</td>\n",
       "      <td>14.055691</td>\n",
       "      <td>17.548245</td>\n",
       "      <td>17.548245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.511966</td>\n",
       "      <td>2.261705</td>\n",
       "      <td>9.962738</td>\n",
       "      <td>9.962738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.630404</td>\n",
       "      <td>3.209069</td>\n",
       "      <td>30.695691</td>\n",
       "      <td>30.695691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.012002</td>\n",
       "      <td>5.675483</td>\n",
       "      <td>19.060445</td>\n",
       "      <td>19.060445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.878412</td>\n",
       "      <td>-0.803486</td>\n",
       "      <td>8.529739</td>\n",
       "      <td>8.529739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.571392</td>\n",
       "      <td>-0.752829</td>\n",
       "      <td>-31.753541</td>\n",
       "      <td>31.753541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.001212</td>\n",
       "      <td>-0.183595</td>\n",
       "      <td>-15048.104909</td>\n",
       "      <td>15048.104909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.893580</td>\n",
       "      <td>6.188747</td>\n",
       "      <td>10.224485</td>\n",
       "      <td>10.224485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.757630</td>\n",
       "      <td>8.065330</td>\n",
       "      <td>7.905112</td>\n",
       "      <td>7.905112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11.152386</td>\n",
       "      <td>14.452027</td>\n",
       "      <td>-29.586864</td>\n",
       "      <td>29.586864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.354070</td>\n",
       "      <td>2.137050</td>\n",
       "      <td>9.218931</td>\n",
       "      <td>9.218931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.147936</td>\n",
       "      <td>3.110789</td>\n",
       "      <td>1.180056</td>\n",
       "      <td>1.180056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.783914</td>\n",
       "      <td>5.274678</td>\n",
       "      <td>-10.258634</td>\n",
       "      <td>10.258634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1.207362</td>\n",
       "      <td>-0.874263</td>\n",
       "      <td>27.588997</td>\n",
       "      <td>27.588997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Real    Predict         Error      absError\n",
       "0    7.805868   8.868258    -13.610139     13.610139\n",
       "1   12.367308  14.017777    -13.345422     13.345422\n",
       "2   18.029634  17.805134      1.245173      1.245173\n",
       "3    2.933022   1.280447     56.343760     56.343760\n",
       "4    4.840932   3.567870     26.297862     26.297862\n",
       "5    7.411128   9.589552    -29.393959     29.393959\n",
       "6   -0.852096   0.065904    107.734298    107.734298\n",
       "7   -0.558234   0.465700    183.423712    183.423712\n",
       "8   -0.216126   1.764127    916.249215    916.249215\n",
       "9    7.485690   7.682308     -2.626581      2.626581\n",
       "10  12.139236   9.971560     17.856771     17.856771\n",
       "11  17.047170  14.055691     17.548245     17.548245\n",
       "12   2.511966   2.261705      9.962738      9.962738\n",
       "13   4.630404   3.209069     30.695691     30.695691\n",
       "14   7.012002   5.675483     19.060445     19.060445\n",
       "15  -0.878412  -0.803486      8.529739      8.529739\n",
       "16  -0.571392  -0.752829    -31.753541     31.753541\n",
       "17  -0.001212  -0.183595 -15048.104909  15048.104909\n",
       "18   6.893580   6.188747     10.224485     10.224485\n",
       "19   8.757630   8.065330      7.905112      7.905112\n",
       "20  11.152386  14.452027    -29.586864     29.586864\n",
       "21   2.354070   2.137050      9.218931      9.218931\n",
       "22   3.147936   3.110789      1.180056      1.180056\n",
       "23   4.783914   5.274678    -10.258634     10.258634\n",
       "24  -1.207362  -0.874263     27.588997     27.588997"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(Fold):\n",
    "    a1 = 'Error%d = pd.DataFrame(((Result_Fold%d.iloc[:,0]-Result_Fold%d.iloc[:,1])/Result_Fold%d.iloc[:,0])*100)'%(i+1,i+1,i+1,i+1)\n",
    "    exec(a1)\n",
    "    a2 = 'absError%d = np.abs(Error%d)'%(i+1,i+1)\n",
    "    exec(a2)\n",
    "    a3 = 'Result%d = pd.DataFrame(np.concatenate((Result_Fold%d,Error%d,absError%d),axis = 1))'%(i+1,i+1,i+1,i+1)\n",
    "    exec(a3)\n",
    "    \n",
    "Result_total = pd.concat([Result1,Result2,Result3,Result4,Result5])\n",
    "Result_total.columns = ['Real', 'Predict', 'Error' , 'absError']\n",
    "pd.set_option('display.max_rows', None)\n",
    "Result_total.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error :  665.1898112323495\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Error : \", np.mean(Result_total.iloc[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error :  22.16847135418168\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Error : \", np.mean(Result1.iloc[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error :  247.88555286480005\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Error : \", np.mean(Result2.iloc[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error :  19.02477807873698\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Error : \", np.mean(Result3.iloc[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error :  3021.303557260814\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Error : \", np.mean(Result4.iloc[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error :  15.566696603213789\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Error : \", np.mean(Result5.iloc[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.18195794038066"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 100 - 6.8180420596193505\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 학습 후 train data로 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mold Temperature</th>\n",
       "      <th>Melt Temperature</th>\n",
       "      <th>Packing Pressure</th>\n",
       "      <th>VS</th>\n",
       "      <th>VMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>195</td>\n",
       "      <td>50</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.001106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>195</td>\n",
       "      <td>70</td>\n",
       "      <td>3.278</td>\n",
       "      <td>0.001952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>195</td>\n",
       "      <td>90</td>\n",
       "      <td>4.569</td>\n",
       "      <td>0.002951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>210</td>\n",
       "      <td>50</td>\n",
       "      <td>1.127</td>\n",
       "      <td>0.000467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "      <td>1.562</td>\n",
       "      <td>0.000762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>210</td>\n",
       "      <td>90</td>\n",
       "      <td>2.148</td>\n",
       "      <td>0.001119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>225</td>\n",
       "      <td>50</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.000172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>225</td>\n",
       "      <td>70</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>225</td>\n",
       "      <td>90</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40</td>\n",
       "      <td>195</td>\n",
       "      <td>50</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0.001185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "      <td>195</td>\n",
       "      <td>70</td>\n",
       "      <td>3.226</td>\n",
       "      <td>0.002059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40</td>\n",
       "      <td>195</td>\n",
       "      <td>90</td>\n",
       "      <td>4.345</td>\n",
       "      <td>0.003153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>40</td>\n",
       "      <td>210</td>\n",
       "      <td>50</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.000466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "      <td>1.514</td>\n",
       "      <td>0.000770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>40</td>\n",
       "      <td>210</td>\n",
       "      <td>90</td>\n",
       "      <td>2.057</td>\n",
       "      <td>0.001147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40</td>\n",
       "      <td>225</td>\n",
       "      <td>50</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>40</td>\n",
       "      <td>225</td>\n",
       "      <td>70</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.000174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40</td>\n",
       "      <td>225</td>\n",
       "      <td>90</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.000205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50</td>\n",
       "      <td>195</td>\n",
       "      <td>50</td>\n",
       "      <td>2.030</td>\n",
       "      <td>0.001583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>50</td>\n",
       "      <td>195</td>\n",
       "      <td>70</td>\n",
       "      <td>2.455</td>\n",
       "      <td>0.002711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50</td>\n",
       "      <td>195</td>\n",
       "      <td>90</td>\n",
       "      <td>3.001</td>\n",
       "      <td>0.004118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50</td>\n",
       "      <td>210</td>\n",
       "      <td>50</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.000606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.001026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50</td>\n",
       "      <td>210</td>\n",
       "      <td>90</td>\n",
       "      <td>1.549</td>\n",
       "      <td>0.001552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50</td>\n",
       "      <td>225</td>\n",
       "      <td>50</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50</td>\n",
       "      <td>225</td>\n",
       "      <td>70</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50</td>\n",
       "      <td>225</td>\n",
       "      <td>90</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.000218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mold Temperature  Melt Temperature  Packing Pressure     VS       VMS\n",
       "0                 30               195                50  2.238  0.001106\n",
       "1                 30               195                70  3.278  0.001952\n",
       "2                 30               195                90  4.569  0.002951\n",
       "3                 30               210                50  1.127  0.000467\n",
       "4                 30               210                70  1.562  0.000762\n",
       "5                 30               210                90  2.148  0.001119\n",
       "6                 30               225                50  0.264  0.000172\n",
       "7                 30               225                70  0.331  0.000197\n",
       "8                 30               225                90  0.409  0.000228\n",
       "9                 40               195                50  2.165  0.001185\n",
       "10                40               195                70  3.226  0.002059\n",
       "11                40               195                90  4.345  0.003153\n",
       "12                40               210                50  1.031  0.000466\n",
       "13                40               210                70  1.514  0.000770\n",
       "14                40               210                90  2.057  0.001147\n",
       "15                40               225                50  0.258  0.000148\n",
       "16                40               225                70  0.328  0.000174\n",
       "17                40               225                90  0.458  0.000205\n",
       "18                50               195                50  2.030  0.001583\n",
       "19                50               195                70  2.455  0.002711\n",
       "20                50               195                90  3.001  0.004118\n",
       "21                50               210                50  0.995  0.000606\n",
       "22                50               210                70  1.176  0.001026\n",
       "23                50               210                90  1.549  0.001552\n",
       "24                50               225                50  0.183  0.000137\n",
       "25                50               225                70  0.275  0.000173\n",
       "26                50               225                90  0.325  0.000218"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData = inputdataRaw.iloc[:,:-2]\n",
    "\n",
    "TrainLabel = pd.DataFrame(inputdataRaw.iloc[:,3])\n",
    "TrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       VS\n",
       "0   2.238\n",
       "1   3.278\n",
       "2   4.569\n",
       "3   1.127\n",
       "4   1.562\n",
       "5   2.148\n",
       "6   0.264\n",
       "7   0.331\n",
       "8   0.409\n",
       "9   2.165\n",
       "10  3.226\n",
       "11  4.345\n",
       "12  1.031\n",
       "13  1.514\n",
       "14  2.057\n",
       "15  0.258\n",
       "16  0.328\n",
       "17  0.458\n",
       "18  2.030\n",
       "19  2.455\n",
       "20  3.001\n",
       "21  0.995\n",
       "22  1.176\n",
       "23  1.549\n",
       "24  0.183\n",
       "25  0.275\n",
       "26  0.325"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainLabel = TrainLabel_before.add(0.5)\n",
    "# TrainLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8036\\3858350740.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  noOfNeuron1    = np.int(Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,2])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8036\\3858350740.py:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  noOfNeuron2    = np.int(Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Prediction :VS\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 80\n",
      "[0 Epochs]    RMSE:19.11935,   MAE: 18.95445,  MAPE: 3039.18%\n",
      "[100 Epochs]    RMSE:0.93794,   MAE: 0.74371,  MAPE: 80.71%\n",
      "[200 Epochs]    RMSE:1.62638,   MAE: 1.59891,  MAPE: 223.12%\n",
      "[300 Epochs]    RMSE:0.90613,   MAE: 0.87298,  MAPE: 114.71%\n",
      "[400 Epochs]    RMSE:0.29854,   MAE: 0.26534,  MAPE: 50.21%\n",
      "[500 Epochs]    RMSE:0.22359,   MAE: 0.18303,  MAPE: 18.96%\n",
      "[600 Epochs]    RMSE:0.17681,   MAE: 0.14697,  MAPE: 27.56%\n",
      "[700 Epochs]    RMSE:1.49226,   MAE: 1.48823,  MAPE: 225.50%\n",
      "[800 Epochs]    RMSE:0.22787,   MAE: 0.19414,  MAPE: 38.30%\n",
      "[900 Epochs]    RMSE:0.39614,   MAE: 0.35524,  MAPE: 61.31%\n",
      "[1000 Epochs]    RMSE:0.71458,   MAE: 0.70763,  MAPE: 101.82%\n",
      "[1100 Epochs]    RMSE:0.22078,   MAE: 0.19536,  MAPE: 34.03%\n",
      "[1200 Epochs]    RMSE:0.98558,   MAE: 0.96790,  MAPE: 162.21%\n",
      "[1300 Epochs]    RMSE:0.83668,   MAE: 0.81146,  MAPE: 133.11%\n",
      "[1400 Epochs]    RMSE:0.49434,   MAE: 0.46875,  MAPE: 83.02%\n",
      "[1500 Epochs]    RMSE:0.51363,   MAE: 0.48850,  MAPE: 85.97%\n",
      "[1600 Epochs]    RMSE:0.17466,   MAE: 0.15383,  MAPE: 15.99%\n",
      "[1700 Epochs]    RMSE:0.26070,   MAE: 0.24504,  MAPE: 42.47%\n",
      "[1800 Epochs]    RMSE:0.38076,   MAE: 0.37318,  MAPE: 60.50%\n",
      "[1900 Epochs]    RMSE:0.26552,   MAE: 0.26007,  MAPE: 38.16%\n",
      "[2000 Epochs]    RMSE:0.23452,   MAE: 0.22746,  MAPE: 32.34%\n",
      "[2100 Epochs]    RMSE:0.50937,   MAE: 0.49042,  MAPE: 81.10%\n",
      "[2200 Epochs]    RMSE:0.39212,   MAE: 0.35572,  MAPE: 64.30%\n",
      "[2300 Epochs]    RMSE:0.10271,   MAE: 0.09358,  MAPE: 15.89%\n",
      "[2400 Epochs]    RMSE:0.16689,   MAE: 0.15257,  MAPE: 24.77%\n",
      "[2500 Epochs]    RMSE:0.04617,   MAE: 0.03862,  MAPE: 6.35%\n",
      "[2600 Epochs]    RMSE:0.37908,   MAE: 0.37486,  MAPE: 57.69%\n",
      "[2700 Epochs]    RMSE:0.16277,   MAE: 0.14327,  MAPE: 25.50%\n",
      "[2800 Epochs]    RMSE:0.15462,   MAE: 0.15035,  MAPE: 23.47%\n",
      "[2900 Epochs]    RMSE:0.35681,   MAE: 0.32283,  MAPE: 58.35%\n",
      "[3000 Epochs]    RMSE:0.29846,   MAE: 0.28243,  MAPE: 48.05%\n",
      "[3100 Epochs]    RMSE:0.43624,   MAE: 0.42475,  MAPE: 68.07%\n",
      "[3200 Epochs]    RMSE:0.15990,   MAE: 0.14827,  MAPE: 25.64%\n",
      "[3300 Epochs]    RMSE:0.11609,   MAE: 0.11288,  MAPE: 16.89%\n",
      "[3400 Epochs]    RMSE:0.12755,   MAE: 0.11623,  MAPE: 22.49%\n",
      "[3500 Epochs]    RMSE:0.15742,   MAE: 0.15297,  MAPE: 22.00%\n",
      "[3600 Epochs]    RMSE:0.09689,   MAE: 0.09158,  MAPE: 15.13%\n",
      "[3700 Epochs]    RMSE:0.11398,   MAE: 0.10391,  MAPE: 12.64%\n",
      "[3800 Epochs]    RMSE:0.18383,   MAE: 0.17233,  MAPE: 29.88%\n",
      "[3900 Epochs]    RMSE:0.08126,   MAE: 0.07362,  MAPE: 13.48%\n",
      "[4000 Epochs]    RMSE:0.04662,   MAE: 0.04004,  MAPE: 6.20%\n",
      "[4100 Epochs]    RMSE:0.10408,   MAE: 0.09295,  MAPE: 17.88%\n",
      "[4200 Epochs]    RMSE:0.10706,   MAE: 0.09188,  MAPE: 17.04%\n",
      "[4300 Epochs]    RMSE:0.07107,   MAE: 0.06595,  MAPE: 11.50%\n",
      "[4400 Epochs]    RMSE:0.06290,   MAE: 0.05544,  MAPE: 9.08%\n",
      "[4500 Epochs]    RMSE:0.09076,   MAE: 0.08616,  MAPE: 10.92%\n",
      "[4600 Epochs]    RMSE:0.09476,   MAE: 0.08690,  MAPE: 13.70%\n",
      "[4700 Epochs]    RMSE:0.21739,   MAE: 0.21223,  MAPE: 31.44%\n",
      "[4800 Epochs]    RMSE:0.10973,   MAE: 0.10201,  MAPE: 18.20%\n",
      "[4900 Epochs]    RMSE:0.05994,   MAE: 0.04878,  MAPE: 8.85%\n",
      "[5000 Epochs]    RMSE:0.10036,   MAE: 0.09653,  MAPE: 14.39%\n",
      "[5100 Epochs]    RMSE:0.04209,   MAE: 0.03474,  MAPE: 7.94%\n",
      "[5200 Epochs]    RMSE:0.15090,   MAE: 0.14381,  MAPE: 25.74%\n",
      "[5300 Epochs]    RMSE:0.06329,   MAE: 0.05275,  MAPE: 6.06%\n",
      "[5400 Epochs]    RMSE:0.15922,   MAE: 0.15585,  MAPE: 23.89%\n",
      "[5500 Epochs]    RMSE:0.09612,   MAE: 0.09165,  MAPE: 14.73%\n",
      "[5600 Epochs]    RMSE:0.04310,   MAE: 0.03631,  MAPE: 5.92%\n",
      "[5700 Epochs]    RMSE:0.14366,   MAE: 0.12611,  MAPE: 25.70%\n",
      "[5800 Epochs]    RMSE:0.10646,   MAE: 0.09652,  MAPE: 18.35%\n",
      "[5900 Epochs]    RMSE:0.03960,   MAE: 0.03100,  MAPE: 5.16%\n",
      "[6000 Epochs]    RMSE:0.15195,   MAE: 0.13906,  MAPE: 25.86%\n",
      "[6100 Epochs]    RMSE:0.11405,   MAE: 0.10775,  MAPE: 19.62%\n",
      "[6200 Epochs]    RMSE:0.11848,   MAE: 0.10622,  MAPE: 11.34%\n",
      "[6300 Epochs]    RMSE:0.02639,   MAE: 0.01887,  MAPE: 2.17%\n",
      "[6400 Epochs]    RMSE:0.05975,   MAE: 0.04888,  MAPE: 5.66%\n",
      "[6500 Epochs]    RMSE:0.08326,   MAE: 0.07135,  MAPE: 12.38%\n",
      "[6600 Epochs]    RMSE:0.08388,   MAE: 0.07748,  MAPE: 13.31%\n",
      "[6700 Epochs]    RMSE:0.14947,   MAE: 0.14324,  MAPE: 20.26%\n",
      "[6800 Epochs]    RMSE:0.05231,   MAE: 0.04536,  MAPE: 6.55%\n",
      "[6900 Epochs]    RMSE:0.08173,   MAE: 0.07063,  MAPE: 12.85%\n",
      "[7000 Epochs]    RMSE:0.11569,   MAE: 0.11273,  MAPE: 14.90%\n",
      "[7100 Epochs]    RMSE:0.03319,   MAE: 0.02833,  MAPE: 5.09%\n",
      "[7200 Epochs]    RMSE:0.19529,   MAE: 0.18952,  MAPE: 29.31%\n",
      "[7300 Epochs]    RMSE:0.03126,   MAE: 0.02602,  MAPE: 3.13%\n",
      "[7400 Epochs]    RMSE:0.05129,   MAE: 0.04706,  MAPE: 7.94%\n",
      "[7500 Epochs]    RMSE:0.07695,   MAE: 0.06811,  MAPE: 7.63%\n",
      "[7600 Epochs]    RMSE:0.03985,   MAE: 0.03619,  MAPE: 6.09%\n",
      "[7700 Epochs]    RMSE:0.06203,   MAE: 0.05525,  MAPE: 9.65%\n",
      "[7800 Epochs]    RMSE:0.10423,   MAE: 0.09905,  MAPE: 15.32%\n",
      "[7900 Epochs]    RMSE:0.04927,   MAE: 0.04041,  MAPE: 6.42%\n",
      "[8000 Epochs]    RMSE:0.09791,   MAE: 0.08706,  MAPE: 8.10%\n",
      "[8100 Epochs]    RMSE:0.03839,   MAE: 0.03171,  MAPE: 2.81%\n",
      "[8200 Epochs]    RMSE:0.04206,   MAE: 0.03748,  MAPE: 4.24%\n",
      "[8300 Epochs]    RMSE:0.06909,   MAE: 0.05958,  MAPE: 6.51%\n",
      "[8400 Epochs]    RMSE:0.07918,   MAE: 0.07095,  MAPE: 12.50%\n",
      "[8500 Epochs]    RMSE:0.04267,   MAE: 0.03680,  MAPE: 5.52%\n",
      "[8600 Epochs]    RMSE:0.05073,   MAE: 0.04485,  MAPE: 6.71%\n",
      "[8700 Epochs]    RMSE:0.03467,   MAE: 0.03004,  MAPE: 4.75%\n",
      "[8800 Epochs]    RMSE:0.05057,   MAE: 0.03906,  MAPE: 3.79%\n",
      "[8900 Epochs]    RMSE:0.04878,   MAE: 0.04445,  MAPE: 6.07%\n",
      "[9000 Epochs]    RMSE:0.01994,   MAE: 0.01631,  MAPE: 2.96%\n",
      "[9100 Epochs]    RMSE:0.03645,   MAE: 0.03000,  MAPE: 5.31%\n",
      "[9200 Epochs]    RMSE:0.09411,   MAE: 0.09085,  MAPE: 13.59%\n",
      "[9300 Epochs]    RMSE:0.09362,   MAE: 0.08345,  MAPE: 17.09%\n",
      "[9400 Epochs]    RMSE:0.06064,   MAE: 0.05020,  MAPE: 4.95%\n",
      "[9500 Epochs]    RMSE:0.03227,   MAE: 0.02966,  MAPE: 4.33%\n",
      "[9600 Epochs]    RMSE:0.01834,   MAE: 0.01538,  MAPE: 3.21%\n",
      "[9700 Epochs]    RMSE:0.02387,   MAE: 0.01904,  MAPE: 3.30%\n",
      "[9800 Epochs]    RMSE:0.04985,   MAE: 0.03842,  MAPE: 8.09%\n",
      "[9900 Epochs]    RMSE:0.15548,   MAE: 0.13193,  MAPE: 11.56%\n",
      "\n",
      "[Final Epochs]    RMSE:0.09019,   MAE: 0.08472,  MAPE: 11.50%\n"
     ]
    }
   ],
   "source": [
    "for M in range(1):\n",
    "    Tr_result_temp = pd.read_csv('./27case_ANN_prediction/Tr_result_epoch2000.csv', sep=',')\n",
    "    learningRate   = Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,1]\n",
    "    noOfNeuron1    = np.int(Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,2])\n",
    "    noOfNeuron2    = np.int(Tr_result_temp.sort_values(['MAPE'],ascending=True).iloc[0,3])\n",
    "    Epoch          = 10000\n",
    "\n",
    "    print('\\n\\n\\nPrediction :' + Model[M])\n",
    "    print('Learning rate : {:.3}'.format(learningRate))\n",
    "    print('Hidden 1 neuron : %d'%(noOfNeuron1))\n",
    "    print('Hidden 2 neuron : %d'%(noOfNeuron2))\n",
    "\n",
    "    #     exec('Label_Trn = TrainLabel_%d'%(M+1))\n",
    "\n",
    "        ################ 신경망 구조 재설계 ################\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    def ANN_model(input_data):\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron_in, \n",
    "                                     input_shape = (input_data.shape[1],), activation = 'relu'))  # Input  Layer\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron1,                  activation = 'relu'))  # Hidden Layer 1\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron2,                  activation = 'relu'))  # Hidden Layer 2\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron_out,               )) # Output Layer\n",
    "        model.compile(optimizer= keras.optimizers.Adam(learning_rate = learningRate),\n",
    "                      loss=keras.losses.mean_absolute_error,\n",
    "                      metrics=['mse','mae','mape'])\n",
    "        return model\n",
    "    model = ANN_model(TrainData)\n",
    "\n",
    "        ################ 신경망 학습 ################\n",
    "\n",
    "    BestModel_temp = model.fit(TrainData, TrainLabel, epochs=Epoch, verbose=0, callbacks=[AccuracyPerEpoch()], batch_size=100)\n",
    "    print(\"\\n[Final Epochs]    RMSE:{:.5f},   MAE: {:.5f},  MAPE: {:.2f}%\"\n",
    "          .format(np.sqrt(BestModel_temp.history['mse'][-1]), BestModel_temp.history['mae'][-1], BestModel_temp.history['mape'][-1]))\n",
    "            \n",
    "            \n",
    "            \n",
    "        # 모델 저장\n",
    "    model.save('./27case_ANNmodels_AllData/BestModel_M%d.h5'%(M+1))\n",
    "\n",
    "        # 히스토리 저장\n",
    "    RMSE  = np.sqrt(np.array(BestModel_temp.history['mse'])[:, np.newaxis])\n",
    "    MAE   = np.array(BestModel_temp.history['mae'])[:, np.newaxis]\n",
    "    MAPE  = np.array(BestModel_temp.history['mape'])[:, np.newaxis]\n",
    "\n",
    "    History_temp = pd.DataFrame(np.concatenate([RMSE,MAE,MAPE],axis=1))\n",
    "    History_temp.to_csv(\"./27case_ANNmodels_AllData/BestModel_M%d_history.csv\"%(M+1), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 20.0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = pd.read_csv('./27case_ANNmodels_AllData/BestModel_M1_history.csv', sep = \",\")\n",
    "plt.plot(graph.iloc[:,2])\n",
    "plt.ylim(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_test = keras.models.load_model('./27case_ANNmodels_AllData/BestModel_M1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 5), found shape=(None, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m real \u001b[38;5;241m=\u001b[39m TestLabel\n\u001b[1;32m----> 2\u001b[0m predict2 \u001b[38;5;241m=\u001b[39m \u001b[43mModel_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTestData\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m predict3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(predict2)\n\u001b[0;32m      4\u001b[0m predict4 \u001b[38;5;241m=\u001b[39m predict3\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;241m0.5\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file7zal9kdi.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 5), found shape=(None, 3)\n"
     ]
    }
   ],
   "source": [
    "real = TestLabel\n",
    "predict2 = Model_test.predict(TestData)\n",
    "predict3 = pd.DataFrame(predict2)\n",
    "predict4 = predict3.sub(0.5)\n",
    "predict5 = predict4.mul(max_VS - min_VS)\n",
    "predict = predict5 + min_VS\n",
    "Result_test = pd.DataFrame(np.concatenate((real,predict), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Result_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Error \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(((\u001b[43mResult_test\u001b[49m\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39mResult_test\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m/\u001b[39mResult_test\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      2\u001b[0m absError \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(Error)\n\u001b[0;32m      3\u001b[0m Result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39mconcatenate((Result_test,Error,absError), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Result_test' is not defined"
     ]
    }
   ],
   "source": [
    "Error = pd.DataFrame(((Result_test.iloc[:,0]-Result_test.iloc[:,1])/Result_test.iloc[:,0])*100)\n",
    "absError = np.abs(Error)\n",
    "Result = pd.DataFrame(np.concatenate((Result_test,Error,absError), axis=1))\n",
    "\n",
    "Result.columns = ['Real', 'Predict', 'Error' , 'absError']\n",
    "pd.set_option('display.max_rows', None)\n",
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Error : \u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mResult\u001b[49m\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m3\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Result' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Average Error : \", np.mean(Result.iloc[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 100 - 0.2505445699074594\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
