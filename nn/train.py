import itertools
from inspect import signature
import json
from pathlib import Path
from typing import Any, Iterable, Iterator, Optional, Tuple, Type

import numpy as np
import pandas as pd
from tensorflow import keras

from .ann import ANN
from .callbacks import AccuracyPerEpoch
from .config import ANNConfig
from .logger import ApiLogger

logger = ApiLogger(__name__)


def train(
    model_class: Type[ANN],
    model_config: ANNConfig,
    case: int,
    model_name: Optional[str] = None,
    **kwargs: Any,
) -> dict[str, Any]:
    # Resets all state generated by Keras.
    output = {"case": case, **kwargs}
    logger.info(f"Start training: {output}")
    keras.backend.clear_session()
    callback = AccuracyPerEpoch(print_per_epoch=model_config.print_per_epoch)
    model = model_class(
        model_config,
        **{
            key: value
            for key, value in kwargs.items()
            if key in signature(model_class.__init__).parameters
        },
    )

    hist = model.fit(
        model_config.train_data,
        model_config.train_label,
        epochs=model_config.epochs,
        verbose=0,  # type: ignore
        callbacks=[callback],
        batch_size=model_config.batch_size,
    )
    model.save(f"./cases/{model_name or model_class.__name__}_{case}.keras")
    histories = {
        metric: hist.history[metric][-1] for metric in model_config.metrics
    }  # type: dict[str, Any]
    if "mse" in histories:
        histories["rmse"] = np.sqrt(histories["mse"])
        histories.pop("mse")
    output.update(histories)
    logger.info(f"End training: {output}")
    return output


def hyper_train(
    model_class: Type[ANN],
    model_config: ANNConfig,
    model_name: Optional[str] = None,
    **hyper_params: Iterable[int | float],
) -> None:
    model_name = model_name or model_class.__name__
    product = tuple(itertools.product(*hyper_params.values()))
    logger.critical(f"model: {model_name} with {len(product)} cases")
    buffer = []  # type: list[dict[str, Any]]
    for case, combined_hyper_params in enumerate(product, start=1):
        buffer.append(
            train(
                model_class,
                model_config,
                case,
                model_name,
                **dict(zip(hyper_params, combined_hyper_params)),
            )
        )
    path = Path("./cases")
    path.mkdir(exist_ok=True, parents=True)
    (path / f"{model_name}_epochs_{model_config.epochs}.json").write_text(
        json.dumps(buffer, indent=2)
    )


def dataset_iterator(
    x_data: pd.DataFrame, y_data: pd.DataFrame, batch_size: int = 1
) -> Iterator[Tuple[pd.DataFrame, pd.DataFrame]]:
    dataset_size = min(len(x_data), len(y_data))
    for batch_start in range(0, dataset_size, batch_size):
        batch_end = min(dataset_size, batch_start + batch_size)
        yield x_data[batch_start:batch_end], y_data[batch_start:batch_end]
