from dataclasses import dataclass
import itertools
import json
import multiprocessing
from inspect import signature
from pathlib import Path
from typing import Any, Iterable, Optional, Type

import numpy as np
from tensorflow import keras

from .callbacks import AccuracyPerEpoch
from .config import ANNConfig
from .dataloader import dataset_kfold_iterator, dump_pickle
from .logger import ApiLogger

logger = ApiLogger(__name__)


def get_checkpoint_filename(
    model_name: str,
    model_config: ANNConfig,
    case: int,
    kfold_case: Optional[int] = None,
) -> str:
    if kfold_case is None:
        return f"{model_name}_E{model_config.epochs}_C{case}of{model_config.number_of_cases}.keras"  # noqa: E501
    return f"./output/{model_name}_E{model_config.epochs}_C{case}of{model_config.number_of_cases}_K{kfold_case}of{model_config.kfold_splits}.keras"  # noqa: E501


def get_result_filename(model_name: str, model_config: ANNConfig) -> str:
    if model_config.kfold_splits <= 0:
        return f"./output/{model_name}_E{model_config.epochs}.pickle"
    return f"./output/{model_name}_E{model_config.epochs}_K{model_config.kfold_splits}.pickle"  # noqa: E501


@dataclass
class Trainer:
    model_class: Type[keras.Sequential]
    model_config: ANNConfig
    model_name: Optional[str] = None
    workers: int = multiprocessing.cpu_count()
    use_multiprocessing: bool = True

    def __post_init__(self) -> None:
        self._model_name = self.model_name or str(self.model_class.__name__)

    def train(
        self, case: int, hyper_params: Optional[dict[str, int | float]] = None
    ) -> dict[str, Any]:
        # Resets all state generated by Keras.
        hyper_params = hyper_params or {}
        model_config = self.model_config
        keras.backend.clear_session()
        callback = AccuracyPerEpoch(
            print_per_epoch=model_config.print_per_epoch
        )
        model = self.model_class(
            model_config,
            **{
                key: value
                for key, value in hyper_params.items()
                if key in signature(self.model_class.__init__).parameters
            },
        )

        output = {"case": case, **hyper_params}
        kfold_splits = model_config.kfold_splits
        path = Path("./output")
        path.mkdir(exist_ok=True, parents=True)

        logger.info(f"Start training: {output}")
        if kfold_splits > 0:
            kfold_histories: list = []
            for kfold_case, (x_train, y_train, x_test, y_test) in enumerate(
                dataset_kfold_iterator(
                    model_config.train_data,
                    model_config.train_label,
                    kfold_splits,
                ),
                start=1,
            ):
                logger.info(
                    f"Kfolds: {kfold_case}/{model_config.kfold_splits}"
                )
                hist = model.fit(
                    x_train,
                    y_train,
                    epochs=model_config.epochs,
                    verbose=0,  # type: ignore
                    callbacks=[callback],
                    batch_size=model_config.batch_size,
                    use_multiprocessing=self.use_multiprocessing,
                    validation_data=(x_test, y_test),
                    workers=self.workers,
                )
                model.save(
                    get_checkpoint_filename(
                        self._model_name, model_config, case, kfold_case
                    )
                )
                kfold_histories.append(hist.history)

            output.update(
                {
                    "kfold": {
                        kfold_case: kfold_history
                        for kfold_case, kfold_history in enumerate(
                            kfold_histories, start=1
                        )
                    }
                }
            )
            mean_last_history = {
                key: np.mean(kfold_histories[-1][key], axis=0)
                for key in kfold_histories[0].keys()
            }
            logger.info(
                f"End training: {json.dumps(mean_last_history, indent=2)}"
            )
        else:
            hist = model.fit(
                model_config.train_data,
                model_config.train_label,
                epochs=model_config.epochs,
                verbose=0,  # type: ignore
                callbacks=[callback],
                batch_size=model_config.batch_size,
                use_multiprocessing=self.use_multiprocessing,
                workers=self.workers,
            )
            model.save(
                get_checkpoint_filename(self._model_name, model_config, case)
            )
            history = hist.history  # type: dict[str, Any]
            if "mse" in history:
                history["rmse"] = np.sqrt(history["mse"])
                history.pop("mse")
            output.update(history)
            mean_history = {
                key: str(np.mean(history[key], axis=0))
                for key in history.keys()
            }
            logger.info(f"End training: {json.dumps(mean_history, indent=2)}")
        return output

    def hyper_train(
        self, hyper_params: Optional[dict[str, Iterable[int | float]]] = None
    ) -> None:
        hyper_params = hyper_params or {}
        product = tuple(itertools.product(*hyper_params.values()))
        logger.critical(
            f"model: {self._model_name} with {self.model_config.number_of_cases} cases"  # noqa: E501
        )
        buffer = []  # type: list[dict[str, Any]]
        for case, combined_hyper_params in enumerate(product, start=1):
            buffer.append(
                self.train(
                    case,
                    hyper_params=dict(
                        zip(hyper_params, combined_hyper_params)
                    ),
                )
            )
        dump_pickle(
            get_result_filename(self._model_name, self.model_config), buffer
        )
